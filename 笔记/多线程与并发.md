# volatile

## 特性

**可见性、禁止指令重排序（实现有序性）**

volatile通常被比喻成 "轻量级的Synchronized"，和Synchronized不同的是，volatile是一个变量修饰符，只能用来修饰变量（不包括局部变量）。无法修饰方法及代码块等。保证变量对所有线程可见性。

- 保证变量对所有线程的**可见性**：对 volatile 变量的写指令后会加入写屏障，对 volatile 变量的读指令前会加入读屏障。
  - 读屏障（lfence）保证在读屏障之后，对共享变量的读取，加载的是主存中最新数据；
  - 写屏障（sfence）保证在写屏障之前的，对共享变量的改动，都同步到主存当中；
- 禁止指令重排序（实现**有序性**），指令重排序是指编译器和处理器为了优化程序性能对指令进行排序的一种手段，需要遵守一定规则：
  - **顺序一致性保证**：对`volatile`变量本身的操作顺序维持程序顺序
  - **跨操作屏障**：
    - **写屏障**：保证`volatile`写前的所有操作不会被重排到写之后
    - **读屏障**：防止后续的任何操作被重排到`volatile`读之前
- 不保证原子性
  - 修改变量(赋值)实质上在`JVM`中分了好几步，而在这几步内(从装载变量到修改)，它是不安全的。`volatile` 只能保证对**单次独立操作的原子性**。

## 原理

<font color='red'>**内存屏障机制**</font>

- **Load屏障**：在每次volatile读操作（load、use）前插入，强制从主内存读取最新值并禁用读后重排序
- **Store屏障**：在每次volatile写操作（assign、store）后插入，强制将数据刷新到主内存并禁用写前重排序
- **StoreLoad屏障**：（开销最大的屏障）会在volatile写后插入，防止重排序至后续操作之前

## 使用场景与优缺点

> 对于一个变量，只有一个线程执行写操作，其它线程都是读操作，这时候可以用volatile修饰这个变量
>
> 常见应用示例
>
> - 状态标志（如线程安全的终止标志）
> - 双重检查锁定（DCL）中的单例模式
>
> **优缺点**：
>
> - **好处**：volatile是一种非锁机制，这种机制可以避免锁机制引起的线程上下文切换和调度问题。所以，volatile的执行成本比Synchronized更低。
> - **不足**：
>   - volatile关键字只能保证可见性，不能保证原子性操作
>   - 高频写的场景下，volatile会导致频繁的缓存一致性流量（MESI协议）和内存屏障开销
>   - L1缓存失效：每次volatile写都直接冲刷到L3缓存/主内存，增加总延迟

## `volatile` 与 `synchronized`区别

1. <font color='Magenta'>`volatile` 关键字：</font>
   - *作用：* 用于标记变量，确保多个线程对该变量的读取和写入操作都在主内存中进行，而不是在线程的本地缓存中操作。
   - 特点：
     - 保证了变量的可见性，即当一个线程修改了变量的值，其他线程能够立即看到最新的值，而不会使用本地缓存中的旧值。
     - 不能保证原子性，多个线程对该变量的操作仍然可能存在竞态条件问题。
   - <font color='Magenta'>适用场景：</font> 适用于对变量的读取和写入操作不依赖于当前值的情况，常用于标记某个变量是否被修改过。
2. <font color='Magenta'>`synchronized` 关键字：</font>
   - *作用：* 可以修饰类、方法、变量，用于实现同步，确保多个线程之间对同步块或方法的互斥访问，只允许一个线程执行同步代码块，其他线程必须等待。
   - 特点：
     - 提供了原子性和可见性，保证了同步代码块内对共享变量的操作是原子的，并且对其他线程可见。
     - 锁的释放由 JVM 自动管理，退出同步块或方法时自动释放锁。
   - <font color='Magenta'>适用场景：</font> 适用于需要保护共享资源的情况，确保多个线程在同一时间只能有一个线程访问共享资源，避免出现竞态条件和数据不一致等问题。

<font color='Magenta'>主要区别：</font>

- `volatile` 主要解决的是变量可见性的问题，保证线程在读取和修改变量时能够看到最新的值，且禁止指令重排序但不能保证原子性。只能用于变量，不会造成阻塞
- `synchronized` 主要用于实现线程之间的同步和互斥，确保同一时间只有一个线程能够访问共享资源，保证了原子性和可见性。用于类、变量、方法和代码块，会阻塞
- 性能：在资源竞争不激烈的情况下，`synchronized` 由于会阻塞线程所以性能损耗比较大，而`volatile` 不会引起线程阻塞，性能较好。

一般情况下，如果仅需保证变量的可见性而不需要原子性的操作，可以使用 `volatile`；如果需要保证原子性以及线程安全，通常使用 `synchronized` 或者更高级的并发工具如 `Lock`。

# 锁

## 分类

1. 按照**锁的获取方式**分为：隐式锁（Implicit Locks）和显式锁（Explicit Locks）。

   > <font color='RedOrange'>隐式锁</font>：也称为内置锁或 `synchronized` 锁，是Java语言级别提供的一种锁机制。通过在方法或代码块中使用synchronized关键字，Java编译器和JVM会自动在对象或类上添加锁，以实现对共享资源的同步访问。
   >
   > **特点**：
   >
   > - 自动获取和释放锁（进入同步代码块时加锁，退出时释放）。
   > - 支持可重入（同一线程多次获取同一锁不会死锁）。
   > - 无法中断等待锁的线程。
   > - 仅支持非公平锁（默认抢占式，可能导致线程饥饿）。
   >
   > <font color='RedOrange'>显式锁</font>：也称为外部锁，是通过 `Lock` 接口及其实现类来实现的（如`ReentrantLock`）。显式锁提供了更加灵活和精细的锁控制，如可重入性、条件变量、公平性等。
   >
   > **特点**：
   >
   > - 需手动调用`lock()`和`unlock()`方法。
   > - 支持可重入、公平性配置、锁中断、超时获取锁等。
   > - 更灵活，但容易因忘记释放锁导致死锁。

2. 按照**锁性质分类**：悲观锁、乐观锁

   > <font color='RedOrange'>乐观锁</font>：
   >
   > - 基本思想：乐观锁假设并发冲突少，因此不会立即加锁，而是在更新数据之前检查是否被其他线程修改过。
   > - 实现方式：通常使用版本号（Versioning）或时间戳（Timestamp）等机制来检测数据是否被修改，比如CAS（Compare and Swap）操作。Java原子类中广泛使用
   >   - **版本号方式**：一般是在数据表中加上一个数据版本号`version`字段，表示数据被修改的次数，当数据被修改时，`version`值会加一。当线程`A`要更新数据值时，在读取数据的同时也会读取`version`值，在提交更新时，若刚才读取到的`version`值为当前数据库中的`version`值相等时才更新，否则重试更新操作，直到更新成功。
   >   - **CAS操作方式：**即`Compare And Swap` （比较与交换），涉及到三个操作数，数据所在的内存值，预期值，新值。当需要更新时，判断当前内存值与之前取到的预期值是否相等，若相等，则用新值更新，若失败则重试，一般情况下是一个自旋操作，即不断的重试。
   >
   > - **特点：** 乐观锁不会阻塞其他线程，当检测到冲突时，会进行回滚或重试，适用于读操作频繁、写操作较少的场景，减少了锁的竞争和开销。
   >
   > <font color='RedOrange'>悲观锁</font>：
   >
   > - 基本思想： 悲观锁假设并发冲突频繁，因此每次访问前都会先加锁，防止其他线程同时修改数据。
   > - 实现方式： 通过使用互斥锁（例如 `Synchronized` 关键字、`ReentrantLock` 等）来保护共享资源，确保在任何时候只有一个线程能够访问资源。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
   > - 特点：悲观锁可能会导致多个线程等待锁释放，效率较低，但适用于写操作频繁的场景。
   >
   > ### 使用场景：
   >
   > - 悲观锁适合写操作频繁的场景，因为它会阻塞其他线程，保证数据的一致性。
   > - 乐观锁适合读操作频繁、写操作较少的场景，因为它不会阻塞其他线程，只在发生冲突时进行回滚或重试，提高了并发性能。
   > - 与悲观锁相比，乐观锁适用的场景受到了更多的限制，无论是CAS还是版本号机制。
   >   - 例如，CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。
   >   - 再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。

3. **按锁状态升级分类**（synchronized优化）：无锁、偏向锁、轻量级锁和重量级锁 是 HotSpot JVM 对 Synchronized 锁优化而引入的四种锁状态

   > **偏向锁**：
   >
   > - **目标**：减少同一线程多次获取锁的开销
   > - **原理**：当一个线程访问同步块时，会在对象头记录线程ID，后续该线程再次进入时无需CAS操作
   > - **条件**：只有一个线程访问同步块时发挥最大作用
   >
   > **轻量级锁**：
   >
   > - **触发条件**：当有其他线程竞争偏向锁时，锁会升级为轻量级锁
   > - **实现**：线程通过自旋（CAS）尝试获取锁，避免线程阻塞和唤醒的开销
   > - **性能**：适合追求响应时间、锁定时间短且竞争不激烈的场景
   >
   > **重量级锁**：
   >
   > - **特点**：若 CAS 失败，锁会升级为重量级锁，竞争线程会进入阻塞状态
   > - **实现**：基于操作系统互斥量(Mutex)，涉及线程上下文切换
   > - **适用场景**：锁竞争激烈或锁持有时间长的场景

4. **按共享性分类**

   > 1. **独占锁（排他锁）**
   >    - **特点**：同一时刻仅一个线程持有锁。
   >    - **实现**：`synchronized`、`ReentrantLock`、`ReentrantReadWriteLock.WriteLock`。
   >    - **适用场景**：适合写操作，保证数据修改的原子性[引用:1]
   > 2. **共享锁**
   >    - **特点**：允许多个线程同时访问资源。
   >    - **实现**：`ReentrantReadWriteLock.ReadLock`、`Semaphore`。
   >    - **适用场景**：读多写少的场景，如缓存读取。

5. **按公平性分类**

   > 1. **公平锁**
   >    - **特点**：多个线程按照申请锁的顺序获取锁，即先到先得
   >    - **优缺点**：公平性好，线程不会饿死，但整体吞吐量较低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。
   >    - **实现**：`ReentrantLock(true)`，通过队列来管理等待的线程，遵循FIFO原则。
   > 2. **非公平锁**
   >    - **特点**：允许线程插队获取锁，获取不到才会到等待队列的队尾等待。
   >    - **优缺点**：整体吞吐量高，但可能导致某些线程长时间等待（饥饿）。
   >    - **实现**：`Synchronized`、`ReentrantLock()`，线程尝试直接获取锁，获取不到才进入等待队列。

6. **按可重入性分离**

   > 可重入锁：指在同一线程在外层方法获取锁的时候，进入内层方法时会自动获取锁，不会因为之前已经获取过还没释放而阻塞。Java 中 ReentrantLock 和 Synchronized 都是可重入锁
   >
   > 1. ReentrantLock 主要通过 AQS 的 state 变量实现可重入性
   >
   >    **可重入锁 获取、释放锁**：
   >
   >    1. ReentrantLock 中，当线程尝试获取锁时，可重入锁先尝试获取并更新state值。
   >    2. 如果 state == 0 表示没有其他线程在执行同步代码，则把 state 置为1，当前线程开始执行。
   >    3. 如果 state != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行 state+1，且当前线程可以再次获取锁。
   >    4. 释放锁时，可重入锁同样先获取当前 state 的值，在当前线程是持有锁的线程的前提下。如果 state-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。
   >
   >    **非可重入锁 获取、释放锁**：
   >
   >    1. 非可重入锁是直接去获取并尝试更新当前 state 的值，如果 state != 0 的话会导致其获取锁失败，当前线程阻塞。
   >    2. 释放锁时，非可重入锁是在确定当前线程是持有锁的线程之后，直接将state置为 0，将锁释放
   >
   > 2. Synchronized 通过计数器（recursions变量）实现可重入性，它会记录线程获得几次锁.。在执行完同步代码块时，计数器的数量会 -1，直到计数器的数量为 0，就释放这个锁。

### 两种锁的底层实现

> Synchronized：底层使用指令码方式来控制锁的，映射成字节码指令就是增加了两个指令：`monitorenter`和`monitorexit`。当线程执行遇到`monitorenter`指令时会尝试获取内置锁，如果获取锁则锁计数器 `+1`，如果没有获取锁则阻塞；当遇到`monitorexit`指令时锁计数器 `-1`，如果计数器为`0`则释放锁。

> Lock：底层是CAS乐观锁，依赖`AbstractQueuedSynchronizer`类，把所有的请求线程构成一个同步队列（CLH）。而对该队列的操作均通过Lock-Free（CAS）操作。

### Synchronized和Lock比较

1. 实现方式及灵活性：

   - **Synchronized**：
     - Java语言内置的关键字，由JVM底层支持，属于**隐式锁**
     - 通过JVM内部实现（monitorenter/monitorexit字节码指令）
     - 加锁和释放过程由JVM自动完成，开发者无需显式控制
     - 使用方式简单：修饰方法或代码块，编译器自动进行加锁和释放锁的操作
     - 缺少一些高级特性，如可中断锁、定时锁、公平锁等。
   - **Lock**：
     - `java.util.concurrent.locks`包中的接口，属于**显式锁**
     - 基于AQS（AbstractQueuedSynchronizer）框架实现
     - 需要手动调用`lock()`获取锁，通过`unlock()`释放锁
     - 提供更多高级特性：可中断获取锁、非阻塞获取锁、超时获取锁等

2. 性能：

   - **Synchronized**：
     - Java 6之前，性能较差
     - Java 6及以后引入了**锁优化技术**：偏向锁、轻量级锁、自旋锁、锁消除、锁粗化等
     - 在**低竞争**场景下性能已接近显式锁
     - 无额外开销，不创建额外对象
   - **Lock**：
     - 在**高竞争、复杂场景**下具有更好的性能
     - 可以实现更细粒度的控制，提高吞吐量
     - ReentrantLock 在特定场景下提供更好的可伸缩性
     - 由于是API实现，存在一定的调用开销

3. 锁状态感知：

   - **Synchronized**：无法判断锁是否被持有，尝试获取锁时，要么成功获取，要么阻塞等待

   - **Lock**：
     - 提供`tryLock()`方法尝试非阻塞获取锁
     - 可以通过返回值判断是否获取到锁
     - 允许程序决定是否继续等待或执行替代逻辑

4. 锁释放机制

   - **Synchronized**：代码执行完毕或抛出异常时自动释放锁，避免了死锁的部分场景
   - **Lock**：异常时不会自动释放锁，所以需要在finally中显式释放锁，更灵活，但也更容易出错

5. 可中断性：

   - **Synchronized**：
     - 不响应中断请求
     - 线程一旦被阻塞，必须等待获取锁或被JVM中断
     - 无法主动退出等待状态

   - **Lock**：
     - 提供`lockInterruptibly()`方法，允许在等待锁期间响应中断
     - 可以实现更灵活的任务取消机制
     - 适合需要取消或超时的场景

6. 条件等待

   - **Synchronized**：
     - 使用`Object`类的`wait()`、`notify()`、`notifyAll()`方法
     - 每个对象只有一个等待队列
     - 唤醒时只能唤醒所有等待线程或随机一个
   - **Lock**：
     - 通过`newCondition()`创建**多个条件变量**（Condition）
     - 每个Condition维护独立的等待队列
     - 支持精确唤醒特定条件上等待的线程
     - 提高复杂并发场景的效率，如生产者消费者模式

7. 读写锁支持

   - **Synchronized**：不直接支持读写分离，所有操作都是互斥的，无法并发读取
   - **Lock**：
     - 提供`ReadWriteLock`接口和`ReentrantReadWriteLock`实现
     - 在读多写少场景下显著提高并发性能
     - 允许多个线程同时获取读锁
     - JDK 8后提供`StampedLock`，性能更优且支持乐观读

   > **总结：** 除非需要使用 `ReentrantLock` 的高级功能（如超时获取、可中断、公平性、多条件等待），否则优先使用 `Synchronized`。这是因为 `Synchronized` 是 `JVM` 实现的一种锁机制，`JVM` 原生地支持它，而 `ReentrantLock` 不是所有的 `JDK` 版本都支持。并且使用 `Synchronized` 不用担心没有释放锁而导致死锁问题，因为 `JVM` 会确保锁的释放。

## Synchronized

`Synchronized` 是由 `JVM`实现的一种互斥同步的方式，查看被 `Synchronized` 修饰过的程序块编译后的字节码会发现， 被 `Synchronized` 修饰过的程序块，在编译前后被编译器生成了`monitorenter` 和 `monitorexit` 两 个字节码指令。在虚拟机执行到 `monitorenter` 指令时，首先要尝试获取对象的锁: 如果这个对象没有锁定，或者当前线程已经拥有了这个对象的锁，把锁的计数器 `+1`;当执行 `monitorexit` 指令时将锁计数器 `-1`；当计数器 为 `0` 时，锁就被释放了。如果获取对象失败了，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。 `Synchronize` 通过在对象头设置标记，达到了获取锁和释放锁的目的。

“锁”的本质其实是 `monitorenter` 和 `monitorexit` 字节码指令的一 个 `Reference` 类型的参数，即要锁定和解锁的对象。

使用`Synchronized` 可以修饰不同的对象，因此，对应的对象锁可以这么确定：

1. 如果 `Synchronized` 明确指定了锁对象，比如 Synchronized(变量名)、Synchronized(this) 等，说明加解锁对象为该对象。
2. 如果没有明确指定:
   - 若 `Synchronized` 修饰的方法为非静态方法，表示此方法对应的对象为 锁对象;
   - 若 `Synchronized` 修饰的方法为静态方法，则表示此方法对应的类对象为 锁对象。

当一个对象被锁住时，对象里面所有用 `Synchronized` 修饰的方法都将产生堵塞，而对象里非 `Synchronized` 修饰的方法可正常被调用，不受锁影响。

### 使用方式

1. 修饰<font color='RedOrange'>实例方法</font>：当前实例加锁（<font color='Peach'>锁class的同一实例的此方法</font>），进入同步代码前要获得当前实例的锁；一个对象中的加锁方法只允许一个线程访问。这种情况下锁的是访问该方法的实例对象， 如果多个线程不同对象访问该方法，则无法保证同步。
2. 修饰<font color='RedOrange'>静态方法</font>：当前类加锁（<font color='Peach'>锁class的所有实例的此方法</font>），进去同步代码前要获得当前类对象的锁；由于静态方法是类方法， 所以这种情况下锁的是包含这个方法的类，也就是类对象；这样如果多个线程不同对象访问该静态方法，也是可以保证同步的。
3. 修饰<font color='RedOrange'>代码块</font>：这需要指定加锁的对象，对所给的指定对象加锁，进入同步代码前要获得指定对象的锁。
   1. 使用 `synchronized(Class)` 时，锁定的是整个类的对象，而不是实例对象。这意味着无论多少实例对象存在，它们都会竞争同一个锁。
   2. 使用 `synchronized(this) `时，锁定的是当前实例对象（this）。这意味着同一实例的不同方法调用会相互排斥，但不同实例之间的方法调用不会相互排斥。

### 原理

`Synchronized`底层原理是基于`JVM`的指令和对象的监视器（monitor）来实现的。当一个线程要执行一个被`Synchronized`修饰的方法或代码块时，它需要先获取该方法或代码块所属对象的监视器。如果获取成功，那么该线程就可以执行同步代码，并且监视器的计数器加一。如果获取失败，那么该线程就会阻塞，直到监视器被释放。当一个线程执行完同步代码后，它会释放监视器，并且监视器的计数器减一。如果计数器为零，那么说明没有线程持有该监视器，其他线程就可以竞争获取该监视器。

`Synchronized`修饰方法时，在字节码层面会有一个`ACC_SYNCHRONIZED`标志，用来表示该方法是同步的。`Synchronized`修饰代码块时，在字节码层面会有`monitorenter`和`monitorexit`两个指令，分别用来进入和退出监视器。

<font color='Apricot'>`Synchronized` 的底层实现原理可以概括为以下几点：</font>

- synchronized 通过监视器锁来实现线程同步。
- 每个 Java 对象都有一个监视器锁。
- 线程在获取了对象的监视器锁后，可以执行被修饰的代码。
- 线程在释放了对象的监视器锁后，其他线程可以尝试获取监视器锁。

### 特点

1. 互斥性（Mutual Exclusion）：同一时刻只有一个线程可以持有锁，其他线程无法获得锁，从而保证了对共享资源的互斥访问。
1. 可重入性（Reentrant）：Synchronized的锁对象中有一个计数器（recursions变量）会记录线程获得几次锁.。在执行完同步代码块时，计数器的数量会-1，直到计数器的数量为0，就释放这个锁。

   > 1. 可以避免死锁
   > 2. 可以更好的封装代码
1. 非公平性（Non-Fairness）：隐式锁默认是非公平锁，即不保证线程获取锁的顺序与其请求锁的顺序一致，可能导致某些线程长时间无法获取锁。
1. 释放锁的条件（Release Condition）：隐式锁是自动释放的，当线程退出同步代码块时会自动释放锁，也可以通过调用`wait()`、`notify()`、`notifyAll()`等方法显式地释放锁。

### 锁的升级

`Synchronized` 在 `JDK1.6` 之后进行了优化，引入了锁升级机制，包含以下四种状态，升级过程是不可逆的（不能降级），目的是减少锁的竞争开销，提高效率：

1. **无锁状态**

   > **核心特点：**
   >
   > - 对象未被任何线程锁定时的默认初始状态。
   > - 如果未开启偏向锁（通过 JVM 参数设置），对象直接被标记为无锁状态；若开启偏向锁，对象初始为“匿名偏向”状态（未绑定任何线程）。
   > - 无锁状态的哈希码会延迟到第一次调用 `hashCode()` 时生成并存储在对象头中。

2. **偏向锁**

   > **设计目标**：解决无竞争场景下的锁开销，通过绑定线程ID减少无竞态时的同步操作。
   >
   > **核心机制**：
   >
   > - 当第一个线程进入同步块时，对象头通过 CAS 标记为偏向该线程（会在对象头和栈帧中的锁记录里存储偏向的线程ID）
   >
   > - 后续该线程重入同步块时，无需重复执行锁获取操作，只需检查线程ID是否匹配。
   >
   > - 发生竞争时（其他线程尝试获取锁），偏向锁会被撤销：
   >
   >   - 若原持有偏向锁的线程仍在活动，升级为轻量级锁，原线程继续持有锁。
   >   - 若原线程已终止，直接允许新线程获取偏向锁。
   >
   >   **注意：** 偏向锁撤销会导致暂停线程（STW），但因发生在无竞态或低竞态场景，实际影响较小。
   >
   > - 偏向锁的解锁步骤中**并不会修改对象头中的线程ID**。
   >
   > **升级时机**：
   >
   > - 一般来说（批量重偏向除外），偏向锁升级的时机为：当锁已经发生偏向后，只要有另一个线程尝试获得偏向锁，则该偏向锁就会升级成轻量级锁。
   >
   > **撤销机制**：
   >
   > - 当有其他线程尝试竞争偏向锁时（例如线程 B 尝试获取锁），偏向锁会被撤销
   > - 撤销操作需要在全局安全点（Safe Point）进行，这可能会导致 Stop-The-World (STW)。JVM 会暂停拥有偏向锁的线程，检查持有锁的线程是否处于活动状态。
   > - 如果原持有锁的线程不活动，对象头会被设置为无锁状态。如果原持有锁的线程仍然活动，且还在同步块内，则锁会升级为轻量级锁。
   > - 如果对象所属的类在一段时间内发生了多次（通常是40次以上）偏向锁撤销，JVM 可能会禁用该类的偏向锁，或者将新创建的该类对象直接标记为不可偏向。
   >
   > **适用场景与注意事项**：
   >
   > - 偏向锁适用于绝大多数时间只有单一线程访问同步块的场景，可以大幅降低同步开销。
   > - 如果对象调用了 `hashCode()` 方法，则无法进入偏向锁状态（因为 Mark Word 需要存储哈希值）。
   > - 如果多线程频繁竞争，偏向锁的撤销成本可能会抵消其性能优势。可以通过 VM 参数 `-XX:-UseBiasedLocking` 禁用偏向锁，或通过 `-XX:BiasedLockingStartupDelay=0` 取消偏向锁的启动延迟（默认延迟4秒）。
   >
   > **批量重偏向和批量撤销**
   >
   > - 批量重偏向：当一个类的对象发生多次偏向锁撤销，但次数未达到禁用偏向锁的阈值（如 20 次），JVM 会认为这些对象存在轻度竞争。当撤销次数达到一定阈值时，后续新创建的该类对象会直接偏向至新的竞争线程。
   > - 批量撤销: 当撤销次数超过一定阈值 (40次)，JVM会禁用整个类的偏向锁功能.

3. **轻量级锁**

   > **适用场景**：低竞争环境（多个线程交替执行同步块，但无并发冲突）。当出现多个线程**同时竞争**锁时升级为重量级锁，如果不是**同时竞争**，轻量级锁依然可以实现线程交替运行。
   >
   > **核心机制**：
   >
   > - 加锁过程：
   >   1. 在当前线程栈帧中分配锁记录（Lock Record），复制对象头中的 Mark Word。
   >   2. 通过 CAS 将对象头替换为指向锁记录的指针。
   >   3. 成功则获取锁；失败说明存在竞争，触发锁膨胀。
   > - 解锁过程：
   >   1. 将锁记录中的 Mark Word 通过 CAS 写回对象头。
   >   2. 若对象未被膨胀（未升级为重量级锁），则解锁成功。
   > - **关键细节**：
   >   - 轻量级锁本身不自旋，仅通过 CAS 尝试一次获取锁。
   >   - 若 CAS 失败，直接进入锁膨胀流程升级为重量级锁，而非忙等。

4. **重量级锁**

   > **触发条件**：轻量级锁膨胀或线程自旋超过阈值后升级为重量级锁。
   >
   > - 重量级锁通过对象的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的互斥量（mutex） 实现的实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。这也是重量级锁效率不高的原因。
   >
   > **核心机制**：
   >
   > - 基于 OS 的互斥量（Mutex Lock）实现，线程竞争锁失败时直接进入阻塞状态，由内核调度唤醒。
   > - 重量级锁中仍存在自适应自旋优化：
   >   - JVM 根据历史竞争情况动态调整自旋次数，避免立即阻塞带来的上下文切换开销。
   > - 锁释放时会唤醒等待队列中的线程重新竞争。
   >
   > **线程阻塞机制**：
   >
   > - 在重量级锁状态下，未能获得锁的线程会被阻塞（从 RUNNABLE 状态变为 BLOCKED），进入等待队列。
   > - 当持有锁的线程释放锁时，JVM 会从等待队列中唤醒一个或多个线程。
   >
   > **优化措施**：
   >
   > - JDK 1.6 后，重量级锁引入了适应性自旋（Adaptive Spinning），根据持有锁线程的运行情况动态调整自旋次数，以减少不必要的线程阻塞和唤醒开销。
   >
   > **特点**：
   >
   > - 重量级锁适合竞争激烈或锁持有时间较长的场景。虽然涉及系统调用和线程切换，开销较大，但能确保线程安全和资源的合理利用。

#### 注意：

1. 轻量级锁没有自旋这回事，只有重量级锁获取失败才会自旋，轻量级锁的意义就是在没有线程争用锁时不用创建monitor。

2. 轻量级锁和偏向锁区别

   > - 轻量级锁只要存在竞争就会升级重量级。轻量级锁的存在就是用于线程之间交替获取锁的场景，但是和偏向锁是有区别的。
   > - 一个线程获取偏向锁之后，那么这个锁自然而然就属于这个线程（就算该线程释放了偏向锁也不会改变这把锁偏向这个线程的【也就是之前说的不会修改Thread ID】，这个前提是没有发生过批量重偏向。所以说偏向锁的场景是用于一个线程不断的获取锁
   > - 如果把它放在轻量级锁的场景下线程之间交替获取的话会发生偏向锁的撤销的。也就是说在偏向锁的情况下，线程1之前释放了锁，线程2再获取锁，即使此时没有同时锁竞争的情况，依然是要升级为轻量级锁的。而轻量级锁只要没有同时去获取锁，就可以不升级为重量级锁，也就代表可以不同线程交替获取这个锁。 

3. 效率上来看偏向锁只有在获取的时候进行一次CAS，以后的释放和获取只需要简单的一些判断操作。而轻量级锁的获取和释放都要都要CAS，单纯的看效率还是偏向锁效率高。

#### 小结

> **无锁**：无竞争
>
> **偏向锁**：长时间只有一个线程访问，就会获得偏向锁
>
> **轻量级锁**：当前锁是偏向锁并且被另外一个线程访问时，偏向锁就会升级为轻量级锁
>
> **重量级锁**：若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

#### 锁膨胀期间的自旋优化

在Java6之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，JDK中的锁可以根据历史性能数据来调整自旋等待的次数，以达到更好的性能，比较智能。自旋会占用CPU时间，单核CPU自旋就是浪费，多核CPU自旋才能发挥优势。Java7之后不能控制是否开启自旋功能
**自旋优化核心**: `重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁)，这时当前线程就可以避免阻塞。`

#### 锁状态对比

| 锁       | 优点                                                         | 缺点                                             | 适用场景                             |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ------------------------------------ |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 | 适用于只有一个线程访问同步块场景。   |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度。                   | 如果始终得不到锁竞争的线程使用自旋会消耗CPU。    | 追求响应时间。同步块执行速度非常快。 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU。                            | 线程阻塞，响应时间缓慢。                         | 追求吞吐量。同步块执行速度较长。     |

### 优缺点

<font color='Apricot'>优点：</font>

1. 简单易用：Synchronized关键字是Java语言提供的内置锁，使用简单且方便，不需要显式地创建锁对象或调用锁相关的方法。
1. 调试方便：隐式锁是Java语言提供的原生锁，可以方便地在代码中添加调试信息或日志，便于排查并发问题。
1. 支持可重入：隐式锁支持线程对同一把锁的重入，不会导致死锁。
1. 支持自动释放：隐式锁在同步代码块执行完成或异常退出时会自动释放锁，不需要手动释放。

<font color='Apricot'>缺点：</font>

1. 非公平性：隐式锁默认是非公平锁，可能导致某些线程长时间无法获取锁，从而影响系统的性能。
1. 粒度较大：隐式锁的粒度较大，可能导致多个线程之间无法并发执行，从而降低系统的吞吐量。
1. 锁的限制：隐式锁只能修饰方法、实例对象或类对象，无法对其他对象进行同步控制.

## ReentrantLock

显式锁是通过`Lock`接口及其实现类来实现的，`ReenTrantLock`的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。相比隐式锁有这些优点：

1. 公平性：与隐式锁不同，显式锁可以支持公平性，即按照线程的请求顺序来获取锁，避免某些线程长时间无法获取锁的问题。
2. 粒度可控：显式锁可以通过 `lock()` 和 `unlock()` 方法手动控制锁的获取和释放，从而可以更精细地控制锁的粒度，避免粒度过大或过小的问题。
3. 可中断：显式锁提供了可以中断等待锁的机制，通过 `lockInterruptibly()` 方法可以在等待锁的过程中响应中断，从而避免线程长时间阻塞。
4. 支持多条件：显式锁可以通过 `Condition` 对象支持多条件的等待和唤醒，从而可以实现更复杂的线程协作机制。
5. 高性能：显式锁在某些情况下可以比隐式锁具有更好的性能，因为它提供了更多的优化选项，如可重入锁、读写锁等。

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
public class LockExample {
    private Lock lock = new ReentrantLock(); // 创建显式锁

    public void doSomething() {
        lock.lock(); // 获取锁
        try {
            // 执行需要同步的代码
        } finally {
            lock.unlock(); // 释放锁
        }
    }
}
```

### 公平锁与非公平锁

**核心区别**

- **公平锁**：在尝试获取锁之前，会调用`hasQueuedPredecessors()`检查是否有线程已在等待队列中，确保按照FIFO原则分配锁。只有等待队列头部的线程能获取锁。新线程必须排队，即使锁空闲。
  - 优点：**防饥饿**，确保所有线程最终都能获取锁，适合对任务执行顺序敏感的场景。
  - 缺点：吞吐量低，不仅是因为线程切换开销，还包括**队列维护的额外操作**（如检查队列是否有等待线程）。
- **非公平锁**：直接尝试通过CAS获取锁，不考虑是否有其他线程已在等待，新到达的线程可能"插队"获取锁。
  - 优点：**吞吐量高**，减少线程挂起和唤醒次数，尤其在竞争激烈时，新线程可能直接获取锁，避免上下文切换。
  - **缺点**：可能导致“线程饥饿”，但实际场景中因线程执行完毕释放锁，饥饿概率较低

**公平锁效率低的根本原因**

1. **额外的队列检查开销**：每次获取锁时都需要检查等待队列
2. **更多的上下文切换**：线程更容易被挂起并加入等待队列
3. **严格的FIFO顺序**：即使锁可用，也需要遵循队列顺序

**非公平锁性能优势**

1. **减少线程挂起概率**：新到达的线程可以直接尝试获取锁
2. **降低上下文切换开销**：减少了线程挂起和唤醒操作
3. **提高吞吐量**：特别是在锁竞争不激烈、锁持有时间短的场景

**注意**

1. `ReentrantLock`使用`lock`和`unlock`来获得锁和释放锁
2. `unlock`要放在`finally`中，这样正常运行或者异常都会释放锁
3. 使用`condition`的`await`和`signal`方法之前，必须调用`lock`方法获得对象监视器

### 可重入性实现

`ReentrantLock `的可重入性实现依赖于 **AQS（AbstractQueuedSynchronizer）** 的 `state` 变量和线程持有者的状态检查。

1. **核心原理：state 计数器**
   - 作用：AQS 中的 `state` 变量记录锁的持有次数。
     - `state = 0`：锁未被占用。
     - `state ≥ 1`：锁被占用，数值表示当前线程重入的次数。
   - **获取锁**：线程首次获取锁时，`state` 通过 CAS 操作从 `0` 变为 `1`。同一线程再次获取时，`state` 递增。
   - **释放锁**：每次释放锁时 `state` 递减，直到 `state = 0` 时完全释放。
2. **当前持有线程记录**
   - AQS 通过 `exclusiveOwnerThread` 变量记录持有锁的线程。
   - **重入检查**：当线程尝试获取锁时，若 `state > 0`，会进一步检查 `exclusiveOwnerThread`是否为当前线程：
     - 若是，允许重入，`state` 递增。
     - 若否，线程进入等待队列。
3. **关键方法：tryAcquire 与 tryRelease**
   1. **获取锁（tryAcquire）**：在 `ReentrantLock.Sync` 类中，`tryAcquire` 方法实现如下逻辑：
      1. 检查当前线程是否持有锁：
         - 通过 `getExclusiveOwnerThread()` 获取当前持有锁的线程。
         - 如果是当前线程，则 **state++**（允许重入）。
      2. 首次获取锁：
         - 如果 `state = 0`（锁未被持有），尝试通过 CAS 将 `state` 设为 1，并设置当前线程为持有者。
      3. 非公平锁优化：
         - 非公平锁会直接尝试插队以 CAS 获取锁（减少线程切换开销），而公平锁会先检查等待队列。
   2. **释放锁（tryRelease）**：在 `ReentrantLock.Sync` 类中，`tryRelease` 方法实现如下逻辑：
      1. 计算释放后的state值：
         - `int c = getState() - releases`（通常releases = 1）
         - 表示当前重入次数减 1
      2. 线程身份检查：
         - 确保当前执行释放操作的线程是锁的持有者
         - 若不是，抛出`IllegalMonitorStateException`异常
      3. 判断锁是否完全释放：
         - 如果计算后的 `state` 值为0，表示锁完全释放：
           - 设置`free = true`（返回值，表示锁已完全释放）
           - 清除持有者记录：`setExclusiveOwnerThread(null)`
         - 如果state仍大于0，表示仍有重入锁未释放，`free = false`
      4. 更新state值：
         - 无论是否完全释放，都会更新state：`setState(c)`
         - 返回`free`值，通知AQS是否应唤醒后续等待线程
4. **总结**
   - **可重入性实现**：通过 `state` 记录重入次数，结合 `exclusiveOwnerThread` 验证线程身份。
   - **线程安全**：通过 CAS 和 AQS 内置的同步机制保证操作的原子性。
   - **设计优势**：避免同一线程因重复获取锁而自我阻塞，简化了递归或嵌套同步代码的编写。

## 死锁

线程 A 持有独占锁a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20240313135924" alt="img" style="zoom:50%;" />

代码示例：

~~~java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}
~~~

### 死锁的四个必要条件

1. 互斥条件：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放
2. 请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
3. 不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞

### 避免方法

只要破坏产生死锁的四个条件中的其中一个就可以了。

> 1. **破坏互斥条件**：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
> 2. **破坏请求与保持条件**：一次性申请所有的资源。
> 3. **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
> 4. **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。




## 锁优化

这里的锁优化主要是指 JVM 对 Synchronized 的优化。

### 自旋锁 && 适应性自旋

#### 自旋锁

互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。

自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，只适用于共享数据的锁定状态很短的场景。

自旋锁的**实现原理**同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20250314222531.jpg" alt="img" style="zoom:67%;" />

#### 适应性自旋

在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

### 锁消除

锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。

锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。

对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：

```java
public static String concatString(String s1, String s2, String s3) {
    return s1 + s2 + s3;
}
```

String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：

```java
public static String concatString(String s1, String s2, String s3) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。

### 锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。

上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。

### 偏向锁

偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。

当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。

当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

[<img src="https://gitee.com/qc_faith/picture/raw/master/image/202212131737412.jpeg" alt="img" style="zoom: 33%;" />](https://camo.githubusercontent.com/95d0ad9a48474178e9ab5fcfc994d768a904d1e53fce6c144a58340a6f71dc22/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33393063393133622d356633312d343434662d626264622d3262383862363838653763652e6a7067)



- 偏向锁(Biased Locking)
- 轻量级锁
- 重量级锁

这三种锁使得 JDK 得以优化 Synchronized 的运行，当 JVM 检测 到不同的竞争状况时，会自动切换到适合的锁实现，这就是锁的升级、 降级。

- 当没有竞争出现时，默认会使用偏向锁。JVM 会利用 CAS 操作，在对象头上的 Mark Word 部分设置线程ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁，因为在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定， 使用偏向锁可以降低无竞争开销。
- 如果有另一线程试图锁定某个被偏向过的对象，JVM 就撤销偏向锁， 切换到轻量级锁实现。
- 轻量级锁依赖 CAS 操作 Mark Word 来试图获取锁，如果重试成功， 就使用普通的轻量级锁;否则，进一步升级为重量级锁。

### 轻量级锁

如果偏向锁没能成功实现，就是因为不同线程竞争锁太频繁了，此时就会尝试采用轻量级锁的方式来加锁，就是将对象头的Mark Word里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一下是不是自己加的锁，如果是自己加的锁，那就执行代码就好了。如果不是自己加的锁，那就是加锁失败，说明有其他人加了锁，这个时候就是升级为重量级锁

以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。

[<img src="https://gitee.com/qc_faith/picture/raw/master/image/202212131737094.png" alt="img" style="zoom:67%;" />](https://camo.githubusercontent.com/244b36284e8af2b9991999bc998ce6ec787bc1d606d02fb3c480c078830af57e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62623661343962652d303066322d346632372d613063652d3465643736346263363035632e706e67)

轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。

如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。

### 适应性锁

如果各个线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。但是其他线程很快释放锁了，然后暂停的线程再次被唤醒。也就是说在这种情况下，线程会频繁的上下文切换，导致开销过大。所以对这种线程持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没竞争到锁，进入一个while循环不停等待，不会暂停不会发生线程上下文切换，等到机会获取锁就继续执行好了

### 多线程开发良好的实践

- 给线程起个有意义的名字，这样可以方便找 Bug。
- 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。
- 多用同步工具少用 wait() 和 notify()。首先，`CountDownLatch`, `CyclicBarrier`, `Semaphore `和 `Exchanger `这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。
- 使用 `BlockingQueue `实现生产者消费者问题。
- 多用并发集合少用同步集合，例如应该使用 `ConcurrentHashMap `而不是 `Hashtable`。
- 使用本地变量和不可变类来保证线程安全。
- 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。

### 总结

1. 当只有一个线程写，其它线程都是读的时候，可以用 `volatile `修饰变量

2. 当多个线程写，那么一般情况下并发不严重的话可以用 `Synchronized `，`Synchronized`并不是一开始就是重量级锁，在并发不严重的时候，比如只有一个线程访问的时候，是偏向锁；当多个线程访问，但不是同时访问，这时候锁升级为轻量级锁；当多个线程同时访问，这时候升级为重量级锁。所以在并发不是很严重的情况下，使用`Synchronized`是可以的。不过`Synchronized`有局限性，比如不能设置锁超时，不能通过代码释放锁。

3. `ReentranLock `可以通过代码释放锁，可以设置锁超时。

4. 高并发下，`Synchronized`、`ReentranLock `效率低，因为同一时刻只有一个线程能进入同步代码块，如果同时有很多线程访问，那么其它线程就都在等待锁。这个时候可以使用并发包下的数据结构，例如 `ConcurrentHashMap ， LinkBlockingQueue `，以及原子性的数据结构如： `AtomicInteger `。



# 多线程与线程安全

## 多线程场景需要考虑的问题

> 在 Java 多线程编程中，关键问题需围绕线程安全、资源管理、性能优化和协作机制展开：
>
> 1. **线程安全与共享资源**
>
>    **问题**：多线程访问共享数据导致竞态条件（Race Condition）或数据不一致。
>    **解决**：
>
>    - **同步机制**：使用 `synchronized` 或 `Lock`（如 `ReentrantLock`）保护临界区。
>    - **原子类**：利用 `AtomicInteger`、`AtomicReference` 实现无锁操作。
>    - **不可变对象**：设计不可变类（如 `String`）以天然避免同步。
>
> 2. **死锁/活锁/饥饿**
>
>    - 死锁：多个线程因相互等待对方释放锁而无限阻塞。
>
>      解决：
>
>      - 避免嵌套锁，按固定顺序获取锁。
>      - 使用 `tryLock` 带超时机制（`Lock.tryLock(timeout)`）。
>
>    - **活锁**：线程不断重试失败操作（如反复回退）。
>      **解决**：引入随机延迟或调整重试策略。
>
>    - **饥饿**：低优先级线程长期无法获取资源。
>      **解决**：公平锁（`ReentrantLock(true)`）或合理设计线程优先级。
>
> 3. **内存可见性与 JMM（Java 内存模型）**
>
>    **问题**：线程间变量修改不可见，导致数据不同步。
>     **解决**：
>
>    - **`volatile` 关键字**：强制变量读写直接操作主内存。
>    - **`synchronized`/`Lock`**：同步块内的修改对所有线程可见（内存屏障效应）。
>    - **`final` 字段**：初始化完成后对其他线程可见。
>
> 4. **性能与锁竞争**
>
>    **问题**：过度同步导致吞吐量下降。
>    **优化手段**：
>
>    - **缩小同步范围**：仅锁住必要代码块。
>    - **读写锁**：`ReentrantReadWriteLock` 区分读（共享）写（独占）锁。
>    - **无锁数据结构**：使用 `ConcurrentHashMap`、`CopyOnWriteArrayList`等。
>    - **分段锁**：如 `ConcurrentHashMap` 分段降低锁粒度。
>
> 5. **线程间通信与协作**
>
>    - **等待/通知机制**：lock.wait(); lock.notifyAll();
>    - 并发工具类：
>      - `CountDownLatch`：等待一组操作完成。
>      - `CyclicBarrier`：多个线程到达屏障后同步执行。
>      - `Semaphore`：控制并发访问资源数。
>      - `CompletableFuture`：异步任务链式处理。
>
> 6. **线程池管理**
>
>    **关键参数**：核心线程数、最大线程数、队列容量、拒绝策略。
>    **最佳实践**：
>
>    - 使用 `Executors` 工厂方法或自定义 `ThreadPoolExecutor`。
>    - 根据任务类型选择队列类型：
>      - CPU 密集型：队列长度小（如无界队列可能引发 OOM）。
>      - IO 密集型：适当增大线程数或使用缓存线程池。
>    - **拒绝策略**：记录日志、降级处理或自定义策略。
>
> 7. **资源管理与泄漏**
>
>    **问题**：线程未关闭或资源未释放（如数据库连接）。
>     **解决**：
>
>    - **显式关闭**：确保 `finally` 块中释放资源（如关闭文件、连接）。
>    - **线程复用**：用线程池代替频繁创建新线程。
>    - **清理 `ThreadLocal`**：调用 `remove()` 避免内存泄漏（尤其是线程池复用场景）。

## 多线程源头

1. 原子性

   > <font color='Magenta'>何为原子性：</font>
   >
   > 原子性的操作是不可被中断的一个或一系列操作。其他线程获取变量时稚嫩获取操作前的变量值和操作后的变量值，不能会去到操作过程中的中间值，在操作过程中其他操作需要获取变量值需要进入阻塞状态等待操作结束。
   >
   > <font color='Magenta'>保证原子性的方式</font>
   >
   > 1. 加锁 synchronized，保证同一时间只有一个线程操作变量，其他线程需要等待操作结束才能使用临界资源
   >2. `CAS`，变量计算前保留一份旧值 a，计算完成后结果值为 b，把 b 刷到内存之前先比较 a 是否与内存中的变量一致，如果一致就把内存中的变量赋值为 b，否则重新获取内存中变量值，重复操作直到 a 与内存中的一致，操作结束
   > 
   > `Lock` 和原子类（`AtomicInteger`）是通过 `unsafe` 的 `compareAndSwap` 方法实现 `CAS` 操作保证原子性的
   
2. 可见性

   线程变量的可见性问题需要从操作系统的 CPU、缓存、内存的矛盾开始说起。读写性能上 CPU > 缓存 > 内存 > I/O。在 CPU 和内存之间隔着缓存和 CPU 寄存器。缓存又分为一级、二级、三级缓存。==CPU 读写性能大于内存，为提高效率会先将数据取到缓存中（每个CPU都有自己的缓存叫做本地工作内存），CPU 处理完数据后会先放到缓存（本地工作内存）中，然后同步到内存==

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/20250314222551.webp" alt="img" style="zoom:50%;" />

   >  <font color='Magenta'>保证可见性的方式</font>
   >
   >  1. 加锁（加锁是万能的操作）synchronized和Lock都可以保证。线程在加锁时，会清空工作内存中共享变量的值，共享变量使用时需要从主内存中重新获取。线程解锁时，会把共享变量重新刷新到主内存中。
   >  1. 使用volatile修饰共享变量，volatile修饰的共享变量在修改后会立即被更新到内存中，其他线程使用共享变量会去内存中读取
   >
   >  优先使用volatile来解决可见性问题，加锁需要消耗的资源太多。

3. 有序性

   计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，重排过程中会遵循as-if-serial语义，即不影响单线程的运行结果。。

   >指令重排一般分为以下三种：
   >
   >- <font color='Magenta'>编译器优化重排</font>：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
   >- <font color='Magenta'>指令并行重排</font>：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。
   >- <font color='Magenta'>内存系统重排</font>：由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

   指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。

   >  <font color='Magenta'>保证有序性的方式</font>
   >
   >  1. 加锁：synchronized和Lock，保证同一时刻只有一个线程进行操作
   >     1. 使用volatile修饰变量，在 JMM 中 volatile 的读和写都会插入内存屏障来禁止处理器的重排



## 何为线程安全

> 当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，并且不需要额外的同步，或者在调用方代码不做其他的协调操作，这个对象的行为获取的结果仍然是正确的，那个称这个对象是线程安全的。
>
> 线程安全问题通常出现在多个线程同时访问和修改共享数据时。这些问题可能导致数据不一致、意外行为或程序崩溃等情况。一些常见的线程安全问题包括：
>
> 1. **竞态条件（Race Condition）：** 当多个线程试图同时访问和操作共享数据，且最终结果取决于线程执行顺序时，就会出现竞态条件。
> 2. **数据竞争（Data Race）：** 多个线程同时修改共享数据而没有同步机制，导致未定义的行为。

## 出现的原因

**对象的有状态和无状态性**

~~~markdown
Java中按照状态可以把对象分为 有状态 和 无状态两种。
1. 无状态对象（Stateless Bean）：无状态对象就是没有实例变量的对象，所以也无法保存数据，它不包含域也没有引用其他类的域。又因为无状态对象没有存储的数据那么这个对象也没有什么改变之说所以是不可变的，同样的多线程下对该对象的任意操作都不会改变对象的状态。所以“无状态的对象一定是线程安全的”
2. 有状态对象（Stateful Bean）：就是有实例变量的对象 ，可以保存数据。
~~~

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428145349.jpg" alt="img" style="zoom: 67%;" />

> 实例的数据是保存在堆中，而堆中的数据是可以被多个线程共享的
>
> 而在多线程同时访问相同堆中的数据进行读写操作时，就达到了竞态条件 导致多线程在竞争资源读写数据时最后的结果不会像我们预想的那样正确，出现线程不安全的情况。同时修改对象的数据对象的状态也被改变所以被称为有状态对象

**竞态条件**

> 竞态条件是由于当一个对象或者一个不同步的共享状态，被多个线程修改时，会出现由于不恰当的执行时序而出现不正确的结果所引起。

**指令重排和有序性**

> 其实除了竞态的时候会出现不恰当的执行时序外，指令重排也会导致代码执行的顺序并不是按照你书写顺序的意愿执行的。
>
> 代码运行一般步骤是这样的：
> 1、从主内存中获取指令解码
> 2、在线程内存中计算值
> 3、执行代码操作
> 4、把结果写入主内存（主内存所有线程共享）
>
> 而把结果写入主内存的操作比较耗时，CPU为了提高性能，可能不会等它完成，就进行对下一个指令解码计算，这就是指令重排了。定义如下：
> 指令重排：计算机为了性能优化会对汇编指令进行重新排序，以便充分利用硬件的处理性能。
>
> 指令重排会改变代码执行的顺序，但是因为最后执行的结果不变所以在单线程下是没有什么问题的。
>
> 而如果在多线程中，同时操作一个数据，如果一个读，一个写，当写的线程值已经改变了但是还没写入主内存时（也就是说值的改变其他线程还没有看到），另一个线程已经开始读取了，那么这个时候就会出现和预期不一致的结果。
>
> 其实现在对于多线程并发为什么会出现不安全的问题已经很清楚了，究其根本是因为多线程是不共享的，并且也无法准确的知道互相之间的状态，包括值的修改也无法可见才会导致修改数据出现问题，出现线程不安全的问题。

## 出现的地方

1. 修改共享数据
2. 未保证原子性

​	原子性就是 提供互斥访问，同一时刻只能有一个线程对数据进行操作，有时也把这个现象叫做同步互斥，表示操作是互相排斥的

​	不保证原子性就会导致 一个线程正在对一个变量操作，中途其他线程插入进来了，如果这个操作被打断了，结果就可能是错误的。 这点也和线程的抢占式调度密切相关. 如果线程不是 “抢占” 的, 就算没有原子性, 	也问题不大

## 线程安全实现方式

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170151155.png" alt="image-20241117015118056" style="zoom:67%;" />

### 不可变

不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。

不可变的类型：

- final 关键字修饰的基本数据类型
- String
- 枚举类型
- Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。

对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。

```java
public class ImmutableExample {
    public static void main(String[] args) {
        Map<String, Integer> map = new HashMap<>();
        Map<String, Integer> unmodifiableMap = Collections.unmodifiableMap(map);
        unmodifiableMap.put("a", 1);
    }
}
Exception in thread "main" java.lang.UnsupportedOperationException
    at java.util.Collections$UnmodifiableMap.put(Collections.java:1457)
    at ImmutableExample.main(ImmutableExample.java:9)
```

Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。

```java
public V put(K key, V value) {
    throw new UnsupportedOperationException();
}
```

### 互斥同步

Synchronized 和 ReentrantLock。

互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。属于一种**悲观的并发策略**，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

#### synchronized关键字

> 这是一个表现为原生语法层面的互斥锁，它是一种悲观锁（认为自己在使用数据的时候，一定有别的线程来修改数据，因此在获取数据的时候先加锁，确保数据不会被线程修改），使用它的时候我们一般需要一个监听对象 并且监听对象必须是唯一的，通常就是当前类的字节码对象。它是 `JVM `级别的，不会造成死锁的情况。使用 `synchronized `可以拿来修饰类，静态方法，普通方法和代码块。

~~~java
// Hashtable类就是使用synchronized来修饰方法的。 
public synchronized V put(K key, V value) {
        // Make sure the value is not null
        if (value == null) {
            throw new NullPointerException();
        } 
// ConcurrentHashMap类中就是使用synchronized来锁代码块的。putVal方法部分源码：
  else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
~~~

> - `synchronized`关键字底层实现主要是通过`monitorenter `与`monitorexit`计数 ，如果计数器不为 0，说明资源被占用，其他线程就不能访问了，但是可重入的除外。
>
>   可重入锁：指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响，执行对象中所有同步方法不用再次获得锁。避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。
>
> - 在使用`synchronized`时，存在一个锁升级原理。
>
>   1. 它是指在锁对象的对象头里面有一个 `threadid `字段，在第一次访问的时候 `threadid `为空，`jvm `让其持有偏向锁，并将 `threadid `设置为其线程 `id`，再次进入的时候会先判断 `threadid `是否与其线程 `id `一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 `synchronized `锁的升级。
>
>   2. 锁升级的目的是为了降低锁带来的性能消耗。在` Java 6` 之后优化 `synchronized `的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。
>
>   3. 偏向锁（无锁）：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后（线程的`id`会记录在对象的`Mark Word`中），消除这个线程锁重入（`CAS`）的开销，看起来让这个线程得到了偏护。
>
>   4. 轻量级锁（CAS）：就是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；轻量级锁的意图是在没有多线程竞争的情况下，通过`CAS`操作尝试将`MarkWord`更新为指向`LockRecord`的指针，减少了使用重量级锁的系统互斥量产生的性能消耗。
>
>   5. 重量级锁：虚拟机使用`CAS`操作尝试将`MarkWord`更新为指向`LockRecord`的指针，如果更新成功表示线程就拥有该对象的锁；如果失败，会检查`MarkWord`是否指向当前线程的栈帧，如果是，表示当前线程已经拥有这个锁；如果不是，说明这个锁被其他线程抢占，此时膨胀为重量级锁。

#### 使用Lock接口下的实现类

`Lock`是`juc（java.util.concurrent）`包下面的一个接口。常用的实现类就是`ReentrantLock `类，它其实也是一种悲观锁。一种表现为 `API `层面的互斥锁。通过`lock()` 和 `unlock() `方法配合使用。因此也可以说是一种手动锁，使用比较灵活。但是使用这个锁时一定**要注意要释放锁**，不然就会造成死锁。一般配合`try/finally` 语句块来完成。

```java
public class TicketThreadSafe extends Thread{
      private static int num = 5000;
      ReentrantLock lock = new ReentrantLock();
      @Override
      public void run() {
        while(num>0){
             try {
               lock.lock();
               if(num>0){
                 System.out.println(Thread.currentThread().getName()+"你的票号是"+num--);
               }
              } catch (Exception e) {
                 e.printStackTrace();
              }finally {
                 lock.unlock();
              }
            }
      }
}
```

相比 `synchronized`，`ReentrantLock `增加了一些高级功能，主要有以下 3 项：**等待可中断、可实现公平锁，以及锁可以绑定多个条件。**

​	等待可中断是指：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。

​	公平锁是指：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。`synchronized `中的锁是非公平的，`ReentrantLock `默认情况下是非公平的，可以通过带布尔值的构造函数要求使用公平锁。

```java 
public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
```

​	锁绑定多个条件是指：一个 `ReentrantLock `对象可以同时绑定多个 `Condition `对象，而在 `synchronized `中，锁对象的 `wait()` 和 `notify()` 或 `notifyAll()` 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就得额外地添加一个锁，而`ReentrantLock `则无须这样做，只需要多次调用` newCondition()` 方法即可。

```java
final ConditionObject newCondition() { //ConditionObject是Condition的实现类
            return new ConditionObject();
    } 
```

### 非阻塞同步

可以使用**基于冲突检测的乐观并发策略**：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步。

#### 1. CAS

`CAS` （比较与交换，Compare And Swap） 是一种**无锁算法**，是乐观锁的一种实现方式，是一种轻量级锁，`JUC `中很多工具类的实现就是基于 `CAS `的。

`CAS`有`3`个操作数

- **内存地址 V**
- **旧的预期值 A**
- **要修改的新值 B**

<span style="color:red">当且仅当预期值 A 和内存地址 V 处的值相同时，将内存值 V 修改为 B ，否则什么都不做</span>

##### CAS的缺点

1. **ABA问题——如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。**

   解决方式：

   J.U.C 包提供了一个带有标记的原子引用类 **AtomicStampedReference** 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。

   - 版本号：修改前去查询原来的值的时候带一个版本号，每次判断就连值和版本号一起判断，判断成功就给版本号加`1`。
   - 时间戳：查询的时候把时间戳一起查出来，对的上才修改并且更新值的时候一起修改更新时间，这样也能保证。

2. **高竞争下的开销问题——在并发冲突概率大的高竞争环境下，如果CAS一直失败，会一直重试，CPU开销较大。**

   > 针对这个问题的一个思路是引入退出机制，如重试次数超过一定阈值后失败退出。
   >
   > 当然，更重要的是避免在高竞争环境下使用乐观锁。

3. **功能限制——CAS的功能是比较受限的，例如CAS只能保证单个变量（或者说单个内存值）操作的原子性，这意味着：**

   > (1)原子性不一定能保证线程安全，例如在Java中需要与`volatile`配合来保证线程安全；
   >
   > (2)当涉及到多个变量(内存值)时，`CAS`也无能为力。
   >
   > 除此之外，`CAS`的实现需要硬件层面处理器的支持，在`Java`中普通用户无法直接使用，只能借助`atomic`包下的原子类使用，灵活性受到限制。

#### 2. AtomicInteger

J.U.C 包里面的整数原子类 AtomicInteger 的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。

以下代码使用了 AtomicInteger 执行了自增的操作。

```java
private AtomicInteger cnt = new AtomicInteger();
public void add() {
    cnt.incrementAndGet();
}
```

以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。

```java
public final int incrementAndGet() {
    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
}
```

以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。

可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。

```java
public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

    return var5;
}
```

### 无同步方案

要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。

#### 1. 栈封闭(使用局部变量)

多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。将变量限制在方法的作用域内，而不是使用共享的全局变量。线程之间无法共享局部变量，从而避免了同步问题。

```java
public class StackClosedExample {
    public void add100() {
        int cnt = 0;
        for (int i = 0; i < 100; i++) {
            cnt++;
        }
        System.out.println(cnt);
    }
}
public static void main(String[] args) {
    StackClosedExample example = new StackClosedExample();
    ExecutorService executorService = Executors.newCachedThreadPool();
    executorService.execute(() -> example.add100());
    executorService.execute(() -> example.add100());
    executorService.shutdown();
}
100
100
```

#### 2. 线程本地存储`ThreadLocal`

当多个线程**操作同一个变量且互不干扰**的场景下，可以使用`ThreadLocal`来解决。它会在每个线程中对该变量创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。在很多情况下，`ThreadLocal`比直接使用`synchronized`同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。通过`set(T value)`方法给线程的局部变量设置值；`get()`获取线程局部变量中的值。当给线程绑定一个 `Object `内容后，只要线程不变,就可以随时取出；改变线程,就无法取出内容

```java
public class ThreadLocalTest {
      private static int a = 500;
      public static void main(String[] args) {
            new Thread(()->{
                  ThreadLocal<Integer> local = new ThreadLocal<Integer>();
                  while(true){
                        local.set(++a);   //子线程对a的操作不会影响主线程中的a
                        try {
                              Thread.sleep(1000);
                        } catch (InterruptedException e) {
                              e.printStackTrace();
                        }
                        System.out.println("子线程："+local.get());
                  }
            }).start();
            a = 22;
            ThreadLocal<Integer> local = new ThreadLocal<Integer>();
            local.set(a);
            while(true){
                  try {
                        Thread.sleep(1000);
                  } catch (InterruptedException e) {
                        e.printStackTrace();
                  }
                  System.out.println("主线程："+local.get());
            }
      }
} 
```

`ThreadLocal`线程容器保存变量时，底层其实是通过`ThreadLocalMap`来实现的。它是以当前`ThreadLocal`变量为`key `，要存的变量为`value`。获取的时候就是以当前`ThreadLocal`变量去找到对应的`key`，然后获取到对应的值。

```java
// 源码
 public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
     ThreadLocalMap getMap(Thread t) {
        return t.threadLocals; //ThreadLocal.ThreadLocalMap threadLocals = null;Thread类中声明的
    }
    void createMap(Thread t, T firstValue) {
        t.threadLocals = new ThreadLocalMap(this, firstValue);
    }
```

其实每个线程`Thread`内部有一个`ThreadLocal.ThreadLocalMap`类型的成员变量`threadLocals`，这个`threadLocals`就是用来存储实际的变量副本的，键值为当前`ThreadLocal`变量，`value`为变量副本（即T类型的变量）。

初始时，在`Thread`里面，`threadLocals`为空，当通过`ThreadLocal`变量调用`get()`方法或者`set()`方法，就会对`Thread`类中的`threadLocals`进行初始化，并且以当前`ThreadLocal`变量为键值，以`ThreadLocal`要保存的副本变量为`value`，存到`threadLocals`。

然后在当前线程里面，如果要使用副本变量，就可以通过`get`方法在`threadLocals`里面查找即可。

#### 3. 可重入代码（Reentrant Code）

- 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。
- 可重入代码有一些共同的特征：例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。

## 线程池

线程池在多线程中起到什么作用

> **在什么情况下使用线程池？** 
>
> 1. 单个任务处理的时间比较短 
> 2. 将需处理的任务的数量大 
>
> **使用线程池的好处:** 
>
> 1. 减少在创建和销毁线程上所花的时间以及系统资源的开销 
> 2. 如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存以及”过度切换”。
>
> **线程池的作用:**
>
> 提升系统的性能以及使用率。
>
> 如果使用最简单的方式创建线程，如果用户量比较大，就会产生很多创建和销毁线程的动作，这会导致服务器在创建和销毁线程上消耗的性能可能要比处理实际业务花费的时间和性能更多。线程池就是为了解决这种这种问题而出现的。

### 线程池分类

~~~java
// 1. 固定大小线程池：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，适用执行长期的任务。
// 适用于负载较重的服务器
// 固定线程数，避免线程数量膨胀
// 任务队列无界，需要注意内存溢出风险
ExecutorService fixedThreadPool = Executors.newFixedThreadPool(10);

// 2. 缓存线程池
// 适用于执行大量短期异步任务
// 可灵活回收空闲线程
// 队列为SynchronousQueue，无容量
ExecutorService cachedThreadPool = Executors.newCachedThreadPool();

// 3. 单线程执行器:只有一个线程的线程池，任务是顺序执行，适用于一个一个任务执行的场景
ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();

// 4. 定时任务线程池：用来调度即将执行的任务的线程池
ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);

// 5. 推荐使用ThreadPoolExecutor自定义线程池
ThreadPoolExecutor executor = new ThreadPoolExecutor(
    5,                      // 核心线程数
    10,                    // 最大线程数
    60L,                   // 空闲线程存活时间
    TimeUnit.SECONDS,      // 时间单位
    new LinkedBlockingQueue<>(100),  // 工作队列
    new ThreadPoolExecutor.CallerRunsPolicy()  // 拒绝策略
);
~~~

### 线程池参数

线程池的构造函数有7个参数，分别是`corePoolSize、maximumPoolSize、keepAliveTime、unit、workQueue、threadFactory、handler`。

1. `corePoolSize ` 线程池核心线程大小

   线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了`allowCoreThreadTimeOut`。

2. `maximumPoolSize ` 线程池最大线程数量

   一个任务被提交到线程池以后，首先会找有没有空闲存活线程，如果有则直接将任务交给这个空闲线程来执行，如果没有则会缓存到工作队列中，如果工作队列满了，才会创建一个新线程，然后从工作队列的头部取出一个任务交由新线程来处理，而将刚提交的任务放入工作队列尾部。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即由`maximunPoolSize`指定。

3. `keepAliveTime ` 空闲线程存活时间

   当前线程池数量超过 `corePoolSize `时，当空闲时间达到 `keepAliveTime `值时， 多余空闲线程会被销毁直到只剩下 `corePoolSize `个线程为止

4. `unit ` 空闲线程存活时间单位

   `keepAliveTime`的计量单位

5. `workQueue ` 工作队列

   > 新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。`jdk`中提供了四种工作队列：
   >
   > ① `ArrayBlockingQueue`
   >
   > 基于数组的有界阻塞队列，按`FIFO`排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到`corePoolSize`后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到`maxPoolSize`，则会执行拒绝策略。
   >
   > ② `LinkedBlockingQuene`
   >
   > 基于链表的无界阻塞队列（其实最大容量为`Interger.MAX`），按照`FIFO`排序。由于该队列的近似无界性，当线程池中线程数量达到`corePoolSize`后，再有新任务进来，会一直存入该队列，而不会去创建新线程直到`maxPoolSize`，因此使用该工作队列时，参数`maxPoolSize`其实是不起作用的。
   >
   > ③ `SynchronousQuene`
   >
   > 一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到`maxPoolSize`，则执行拒绝策略。
   >
   > ④ `PriorityBlockingQueue`
   >
   > 具有优先级的无界阻塞队列，优先级通过参数`Comparator`实现。

6. `threadFactory ` 线程工厂

   创建一个新线程时使用的工厂，可以用来设定线程名、是否为`daemon`线程等等

7. `handler ` 拒绝策略

   当提交任务数量超过`maximumPoolSize `+ `workQueue`之和时，就需要拒绝策略来解决这个问题，`jdk`中提供了`4`种拒绝策略：

   > ① `CallerRunsPolicy`
   >
   > 在调用者线程中直接执行被拒绝任务的`run`方法，除非线程池已经`shutdown`，则直接抛弃任务。
   >
   > **② `AbortPolicy(默认)`**
   >
   > 直接丢弃任务，并抛出`RejectedExecutionException`异常。
   >
   > ③ `DiscardPolicy`
   >
   > 直接丢弃任务，不予任何处理也不抛出异常。
   >
   > ④ `DiscardOldestPolicy`
   >
   > 抛弃进入队列最早的那个任务，也就是即将被执行的任务，然后尝试把这次拒绝的任务放入队列

### 参数配置

1. CPU 密集型 意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行，CPU 密集任务只有在真正的多核 CPU 上才可能得到加速(通过多线程)。CPU 密集型任务配置尽可能少的线程数量

   一般公式 : <font color='Apricot'>CPU 核数 + 1个线程的线程池</font> = 最大线程数

2. IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程

   一般公式 : <font color='Apricot'>CPU 核数* 2</font>

# 进程与线程

**进程**

一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在`Windows`系统中，一个运行的`xx.exe`就是一个进程。

**线程**

进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。

## 区别

**根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位

**资源开销**：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

**包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

**内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

**影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

**执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

## 创建线程

创建线程有四种方式：

- 继承 `Thread `类；

  - 步骤
    1. 定义一个`Thread`类的子类，重写`run`方法，将相关逻辑实现，`run()`方法就是线程要执行的业务逻辑方法
    2. 创建自定义的线程子类对象
    3. 调用子类实例的`star()`方法来启动线程

- 实现 `Runnable `接口；

  - 步骤
    1. 定义`Runnable`接口实现类`MyRunnable`，并重写`run()`方法
    2. 创建`MyRunnable`实例`myRunnable`，以`myRunnable`作为`target`创建`Thead`对象，**该`Thread`对象才是真正的线程对象**
    3. 调用线程对象的`start()`方法

- 实现 `Callable `接口；

  - 步骤
    1. 创建实现`Callable`接口的类`myCallable`
    2. 以`myCallable`为参数创建`FutureTask`对象
    3. 将`FutureTask`作为参数创建`Thread`对象
    4. 调用线程对象的`start()`方法

- 使用 `Executors `工具类创建线程池

  - `Executors`提供了一系列工厂方法用于创先线程池，返回的线程池都实现了`ExecutorService`接口。

    主要有`newFixedThreadPool`，`newCachedThreadPool`，`newSingleThreadExecutor`，`newScheduledThreadPool`这四种线程池

### runnable 和 callable 区别？

**区别**

- Runnable接口是java1.1就有的，Callable接口是 java1.5才有的，可以认为 Callable 接口是升级版的 Runnable 接口；

- Runnable 接口线程任务是在 run 方法里写的，run 方法无返回值；Callable 接口 call 方法有返回值，是个泛型，和 Future、FutureTask 配合可以用来获取异步执行的结果

- Runnable 接口 run 方法只能抛出运行时异常，且无法被调用者捕获处理，只能由线程的默认异常处理器处理；Callable 接口 call 方法允许抛出异常，可以获取异常信息

- 加入线程池运行时

  - `execute` 方法只能接受 `Runnable` 类型的任务，并且不会返回结果。

  - `submit` 方法可以接受 `Runnable` 或 `Callable` 类型的任务，但如果传入 `Runnable`，返回的 `Future` 的 `get()` 方法结果为 `null`。

    > execute 只提交任务并由线程池执行，无法获取任务的执行结果或状态。
    >
    > submit 不仅提交任务，还返回一个 Future 对象，允许调用者通过 Future 获取任务状态或结果。

- 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。Future对象封装了检查计算是否完成、检索计算的结果的方法，而Runnable接口没有。

**注**：`Callalbe`接口支持返回执行结果，需要调用`FutureTask.get()`得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 

### 线程的 run()和 start()

**区别**

每个线程都是通过某个特定`Thread`对象所对应的方法`run()`来完成其操作的，`run()`方法称为线程体。通过调用`Thread`类的`start()`方法来启动一个线程。

`start() `方法用于启动线程，`run() `方法用于执行线程的运行时代码。`run()` 可以重复调用，而 `start() `只能调用一次。

`start()`方法来启动一个线程，真正实现了多线程运行。调用`start()`方法无需等待`run`方法体代码执行完毕，可以直接继续执行其他的代码； 此时线程是处于就绪状态，并没有运行。 然后通过此Thread类调用方法`run()`来完成其运行状态， `run()`方法运行结束， 此线程终止。然后`CPU`再调度其它线程。

`run()`方法是在本线程里的，只是线程里的一个函数，而不是多线程的。 如果直接调用`run()`，其实就相当于是调用了一个普通函数而已，直接调用`run()`方法必须等待`run()`方法执行完毕才能执行下面的代码，所以执行路径还是只有一条，根本就没有线程的特征，所以在多线程执行时要使用`start()`方法而不是`run()`方法。

**为什么调用 start() 方法时会执行 run() 方法，为什么不能直接调用 run() 方法？**

`new `一个 `Thread`，线程进入了新建状态。调用` start() `方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。` start() `会执行线程的相应准备工作，然后自动执行` run() `方法的内容，这是真正的多线程工作。

而直接执行` run() `方法，会把 `run `方法当成一个 `main `线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

<font color='Chestnut Red'>**总结：**</font> 调用 `start `方法方可启动线程并使线程进入就绪状态，而 `run `方法只是 `thread `的一个普通方法调用，还是在主线程里执行。

## sleep 和 wait？

两者都可以暂停线程的执行

- 类的不同：`sleep() `是 `Thread`线程类的静态方法，`wait()` 是 `Object`类的方法。
- 是否释放锁：`sleep() `不释放锁；`wait() `释放锁。
- 用途不同：`Wait `通常被用于线程间交互/通信，`sleep` 通常被用于暂停执行。
- 用法不同：`wait() `方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll() `方法。`sleep() `方法执行完成后，线程会自动苏醒。或者可以使用`wait(long timeout)`超时后线程会自动苏醒。

## 生命周期及五种状态

1. **新建`(New)`**：初始状态，`new Thread()`后线程被构建，但是还没有调用start()方法。
2. **可运行`(Runnable)`**：
   1. 调用线程的`start()`方法后，线程进入RUNNABLE状态

   2. 此状态包含两个子状态：
      - **Ready**（就绪）：线程已准备好运行，等待CPU分配时间片
      - **Running**（运行中）：线程正在执行，已获得CPU时间片

3. **阻塞`(Blocked)`**：
   1. 线程被阻塞，等待获取监视器锁（monitor lock）
   2. 只有在以下情况才会进入此状态：
      - 线程尝试进入synchronized方法/块
      - 目标锁已被其他线程持有

4. **等待（Waiting）**
   1. 线程无限期等待，直到被其他线程显式唤醒
   2. 进入此状态的方法：
      - `Object.wait()`：在synchronized代码块中调用
      - `Thread.join()`：等待指定线程结束
      - `LockSupport.park()`：低级别线程阻塞原语

5. **计时等待状态（Timed_Waiting）**
   1. 线程等待特定时间后自动唤醒
   2. 进入此状态的方法：
      - `Thread.sleep(timeout)`
      - `Object.wait(timeout)`
      - `Thread.join(timeout)`
      - `LockSupport.parkNanos()`
      - `LockSupport.parkUntil()`

6. **死亡(Terminated)**：
   1. 线程执行完成或因异常退出
   2. 线程一旦终止不能重新启动
   3. 终止原因：
      - `run()`方法执行完成正常返回
      - 线程内抛出未捕获的异常


## 状态切换

    +-------+                               +-------+
    |  NEW  |----(调用start()方法)---------->|RUNNABLE|
    +-------+                               +-------+
                                             ^  | |  ^
                                             |  | |  |
                                             |  | |  |
                                             |  v |  |
     +----------+                           +-------+
     |TERMINATED|<---------------------------|BLOCKED|
     +----------+                           +-------+
           ^                                   ^  |
           |                                   |  |
           |                                   |  v
      +-------+       +-------------+        +-------+
      |WAITING|<----->|TIMED_WAITING|<------>|RUNNABLE|
      +-------+       +-------------+        +-------+

![image-20250301232005472](https://gitee.com/qc_faith/picture/raw/master/image/20250301232008.png)

![image-20250301232038319](https://gitee.com/qc_faith/picture/raw/master/image/20250301232041.png)

# AtomicXXXFieldUpdater

## 使用场景

- 想让类的属性操作具备原子性，

- 但是不想使用锁。

- 大量需要原子类型修饰的对象，相比较比较耗费内存(比使用AtomicStampedReference<Node>节省内存，同时可以保证原子性)

  ~~~java
  public class AtomicIntegerFieldUpdaterTest {
  
      public static void main(String[] args) {
          AtomicIntegerFieldUpdater<Test> updater = AtomicIntegerFieldUpdater.newUpdater(Test.class, "value");
          Test ts = new Test();
  
          IntStream.rangeClosed(0, 2).forEach(item -> {            
          	new Thread(() -> {
                  int value = updater.getAndIncrement(ts);
                  System.out.println("oldV: " + value);
              }).start();
          });
      }
   }
  
  class Test {
      volatile int value;
  }
  ~~~

# CountDownLatch

- countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。
- 是通过一个 state（相当于计数器）的东西来实现的，计数器的初始值是 **线程的数量或者任务的数量**。
- 每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。
- CountDownLatch的方便之处在于，你可以在一个线程中使用， **也可以在多个线程上使用，一切只依据状态值**，这样便不会受限于任何的场景。

## 常用API

**构造方法只有一个**

- `CountDownLatch(int count)` ：构造一个以给定计数

**实例方法**

- ```java
  public void await()
  ```

  - **当前线程等到锁存器计数到零**
  - 可以被 **打断**

- ```java
  public boolean await(long timeout,TimeUnit unit)
  ```

  - 等待一段时间
  - **timeout** - 等待的最长时间 ， **unit** - timeout参数的时间单位
  - 如果 **指定的等待时间过去**，则返回值false
  - 如果 **计数达到零**，则方法返回值为true

- ```java
  public void countDown()
  ```

  - 减少锁存器的计数， **如果计数达到零，释放所有等待的线程**。

- ```java
  public long getCount()
  ```

  - 返回当前计数

## 使用场景

1. > - 可能刚从数据库读取了一批数据
   > - 利用并发处理这批数据
   > - 当所有的数据处理完成后，再去执行后面的操作

   ~~~java
   public class Video32 {
       public static void main(String[] args) throws InterruptedException {
           CountDownLatch countDownLatch = new CountDownLatch(6);
   
           for (int i = 0; i < 6; i++) {
                new Thread(() ->{
                   System.out.println("\t\t" + Thread.currentThread().getName() + "处理完毕~~~");
                   countDownLatch.countDown();
                   System.out.println("非调用者线程-" + Thread.currentThread().getName() + "-还可以干点其他事");
                }, Country.forEach_Country(i + 1).getCountryName()).start();
           }
           countDownLatch.await();
           System.out.println("-----------------------------");
           System.out.println("\t 所有任务都已经处理完毕，可以往后执行了！");
       }
   }
   
   enum Country{
       ONE(1,"1号任务"),
       TWO(2,"2号任务"),
       THREE(3,"3号任务"),
       FOUR(4,"4号任务"),
       FIVE(5,"5号任务"),
       SIX(6,"6号任务");
   
       private Integer index;
       private String countryName;
   
       public static Country forEach_Country(Integer index){
           Country[] values = Country.values();
           for (Country c: values) {
               if(c.getIndex() == index){
                   return c;
               }
           }
           return null;
       }
       Country(Integer index, String countryName) {
           this.index = index;
           this.countryName = countryName;
       }
       public Integer getIndex() {
           return index;
       }
       public String getCountryName() {
           return countryName;
       }
   }
   ~~~

   

2. >- 多个线程协同工作
   >- 多个线程需要等待其他线程的工作之后，再进行其后续工作。
   >- 被唤醒后继续执行其他操作

   ~~~java
   public class CountDownLatchExample {
   
       public static void main(String[] args) throws InterruptedException {
           final CountDownLatch latch = new CountDownLatch(1);
           new Thread(() -> {
               System.out.println(Thread.currentThread().getName() + " Do some initial working.");
               try {
                   Thread.sleep(1000);
                   latch.await();
                   System.out.println(Thread.currentThread().getName() + " Do other working.");
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }
           }).start();
   
           new Thread(() -> {
               System.out.println(Thread.currentThread().getName() + " Do some initial working.");
               try {
                   Thread.sleep(1000);
                   latch.await();
                   System.out.println(Thread.currentThread().getName() + " Do other working.");
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }
           }).start();
   
           new Thread(() -> {
               System.out.println("asyn prepare for some data.");
               try {
                   Thread.sleep(2000);
                   System.out.println("Data prepare for done.");
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }finally {
                   latch.countDown();
               }
           }).start();
       }
   }
   ~~~

# CyclicBarrier

## 引出

- 栅栏类似于闭锁（CountDownLatch），它能阻塞一组线程直到某个事件的发生。栅栏与闭锁的关键区别在于， **所有的线程必须同时到达栅栏位置，才能继续执行**。闭锁用于等待事件，而 **栅栏用于等待其他线程**。
- CyclicBarrier可以使一定数量的线程反复地在栅栏位置处汇集。 **当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程都到达栅栏位置。** 如果所有线程都到达栅栏位置，那么栅栏将打开，此时所有的线程都将被释放，而栅栏将被重置以便下次使用。

## API使用

### 构造方法

```java
public CyclicBarrier(int parties)
public CyclicBarrier(int parties, Runnable barrierAction)
```

- `parties` 是参与线程的个数
- 第二个构造方法有一个 `Runnable` 参数，这个参数的意思是 **最后一个到达线程要做的任务**

### 重要方法

```java
public int await() throws InterruptedException, BrokenBarrierException
public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException
```

- 线程调用 await() **表示自己已经到达栅栏**
- BrokenBarrierException 表示栅栏已经被破坏，破坏的原因可能是其中一个线程 await() 时被中断或者超时

### 其他方法

```java
public void reset()
```

- 将屏障重置为初始状态。 如果任何一方正在等待屏障，他们将返回 **BrokenBarrierException** 。
- 这样就可以重复利用这个屏障

## 代码示例

~~~java
public static void main(String[] args) {
        CyclicBarrier cyclicBarrier = new CyclicBarrier(7,() -> System.out.println("收集到7颗龙珠,召唤神龙"));

        for (int i = 0; i < 7; i++) {
             final int temp = i + 1;
             new Thread(() ->{
                System.out.println(Thread.currentThread().getName() + "\t收集到第" + temp + "颗龙珠");
                 try {
                     int await = cyclicBarrier.await();
                     System.out.println("还剩几个:" + await);
                 } catch (InterruptedException e) {
                     e.printStackTrace();
                 } catch (BrokenBarrierException e) {
                     e.printStackTrace();
                 }
             },"线程" + String.valueOf(i)).start();
        }
    }
~~~

## 与 CountDownLatch 区别

- CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行； CyclicBarrier：多个线程互相等待，直到到达同一个同步点，再继续一起执行。
- CountDownLatch是不能复用的，而CyclicLatch是可以复用的。
- 调用CountDownLatch的countDown方法后，当前线程并不会阻塞，会继续往下执行；而调用CyclicBarrier的await方法，会阻塞当前线程，直到CyclicBarrier指定的线程全部都到达了指定点的时候，才能继续往下执行；
- 对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。 而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须互相等待，然后继续一起执行。 CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。 

# Exchanger

## 简介

- 用于两个工作线程之间交换数据的封装工具类
- 简单说就是一个线程在完成一定的事务后想与另一个线程交换数据，则 **第一个先拿出数据的线程会一直等待第二个线程，直到第二个线程拿着数据到来时才能彼此交换对应数据**

`Exchanger<v>` 泛型类型，其中 **V 表示可交换的数据类型**

## 方法介绍

```java
public V exchange(V x) throws InterruptedException
```

- 等待另一个线程到达此交换点，然后将给定对象传输给它，接收其对象作为回报。
- 可以被打断
- 如果已经有个线程正在等待了，则直接交换数据

## 代码示例

~~~java
    public static void main(String[] args) {
        final Exchanger<String> exchanger = new Exchanger<>();

        new Thread(()->{
            System.out.println(Thread.currentThread().getName() + " start . ");
            try {

                /**
                 * 如果这里睡200ms的话，应该是B线程先拿出数据，然后B线程等待A线程。因为是B先给的数据，
                 * 所以最后A线程会先拿到B给的数据，也就是先打印
                 */
                TimeUnit.MILLISECONDS.sleep(200);
                String exchange = exchanger.exchange("I am come from T-A");
                System.out.println(Thread.currentThread().getName() + " get value : " + exchange);
                System.out.println(Thread.currentThread().getName() + " end . ");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        },"A").start();

        new Thread(()->{
            System.out.println(Thread.currentThread().getName() + " start . ");
            try {
                String exchange = exchanger.exchange("I am come from T-B");
                System.out.println(Thread.currentThread().getName() + " get value : " + exchange);
                System.out.println(Thread.currentThread().getName() + " end . ");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        },"B").start();
    }
~~~

# Semaphore

- Semaphore可以用来控制同时访问某个资源的线程数量，从而实现线程之间的同步。
- 它维护了一个许可证的计数器，有多少资源需要限制就维护多少许可证集合，线程需要获取许可证才能访问资源。当许可证计数器为0时，线程需要等待其他线程释放许可证。当一个线程完成对资源的访问后，需要释放许可证，以便其他线程可以访问资源。也是操作系统中用于**控制进程同步互斥的量**。
- 内部是基于AQS的共享模式。**它相当于给线程规定一个量从而控制允许活动的线程数**。
- 一个线程获取许可证就调用acquire方法，用完了释放资源就调用release方法。

除了JDK定义的锁，Semaphore也可以定义锁。Semaphore可以做的功能相当的多，比如秒杀限流

## 常用API

### 构造方法

```java
public Semaphore(int permits)
public Semaphore(int permits , boolean fair)
```

- `permits`：同一时间可以访问资源的线程数目
- `fair`：尽可能的保证公平

### 重要方法

```java
public void acquire() throws InterruptedException
public void release()
```

- `acquire()`：**获取一个许可证**，如果许可证用完了，则陷入阻塞。可以被打断。
- `release()`：**释放一个许可证**
- `acquire(int permits)` 
  - **acquire多个时，如果没有足够的许可证可用，那么当前线程将被禁用以进行线程调度**，并且处于休眠状态，直到发生两件事情之一：
    - 一些其他线程调用此信号量的一个release方法，当前线程旁边将分配许可证，并且可用许可证的数量满足此请求;
    - 要么一些其他线程interrupts当前线程。
- `public void release(int permits)`
  - **release多个时，会使许可证增多，最终可能超过初始值**

```java
public boolean tryAcquire(int permits)
public boolean tryAcquire(int permits,
                          long timeout,
                          TimeUnit unit)
                   throws InterruptedException
```

- 尝试去拿，**拿到返回true**

### 其他方法

- 返回此信号量中当前可用的许可数：`public int availablePermits()`
- 返回正在阻塞的线程集合：`getQueuedThreads()`
- 返回阻塞获取的线程数：`getQueueLength()`
- 可以`不被打断`获取许可证：`acquireUninterruptibly()`、`acquireUninterruptibly(int permits)`
- 获取当前全部的许可证目标：`drainPermits()`

## 代码示例

~~~java
public static void main(String[] args) {
        Semaphore semaphore = new Semaphore(3);

        for (int i = 0; i < 10; i++) {
             new Thread(() ->{
                 try {
                     semaphore.acquire();
                     System.out.println(Thread.currentThread().getName() + "\t 进入抢购秒杀页面，准备抢小米9");
                     //停3秒后离开
                     try {
                         TimeUnit.SECONDS.sleep(3);
                     } catch (InterruptedException e) {
                         e.printStackTrace();
                     }
                     System.out.println(Thread.currentThread().getName() + "\t 离开抢购秒杀页面，成功抢到小米9");
                 } catch (InterruptedException e) {
                     e.printStackTrace();
                 }finally {
                     semaphore.release();
                 }
             },"用户" + String.valueOf(i)).start();
        }
    }
~~~

# Condition

- Condition主要是用于线程通信的，也就是和Object类的wait，notify有同样的功能。不过Condition的功能更加多样，可以绑定锁，实现选择性唤醒。
- Condition和Lock搭配使用： condition必须使用`lock.newCondition();`来创建condition。必须存放在Lock中。否则抛出异常。
