# 常用的集合

`Map`接口和`Collection`接口是所有集合框架的父接口：

`Collection`集合主要有`List`和`Set`两大接口

- `List`：<span style="background:#f9eda6;">有序</span>（元素存入集合的顺序和取出的顺序一致），元素<span style="background:#f9eda6;">可以重复</span>，可以插入<span style="background:#f9eda6;">多个`null`</span>元素，元素都有索引。
  - 常用的实现类有 `ArrayList、LinkedList 和 Vector`。
- `Set`：<span style="background:#f9eda6;">无序</span>（存入和取出顺序有可能不一致）容器，<span style="background:#f9eda6;">不可以存储重复元素</span>，只允许存入<span style="background:#f9eda6;">一个`null`</span>元素，必须保证元素唯一性。
  - 常用实现类是` HashSet、LinkedHashSet 以及 TreeSet`。

`Map`是一个键值对集合，存储键、值和之间的映射。 `Key`无序，唯一；`value `不要求有序，允许重复。从`Map`集合中检索元素时，只要给出键对象，就会返回对应的值对象。

1. `Map`不是`Collection`的子接口或者实现类。`Map`是一个接口。

2. `Map` 的每个 `Entry` 都持有两个对象，一个键一个值，`Map` 可能会持有相同的值对象但键对象必须是唯一的。

3. `TreeMap` 也通过 `Comparator` 或者 `Comparable` 维护了一个排序顺序。

4. `Map` 里可以有随意个 `null` 值但最多只能有一个 `null` 键。

- 常用实现类：`HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap`

# List

> `List`在`Java`里边是一个接口，常见的实现类如下：
>
> （1）`ArrayList`：数组实现，查询快，增删慢，轻量级；(线程不安全)
> （2）`LinkedList`：双向链表实现，增删快，查询慢 (线程不安全)
> （3）`Vector`：数组实现，重量级 (线程安全、使用少)
>
> 在开发中用得最多的是`ArrayList`，因为遍历的需求比增删要多，即便是增删也是往往在`List`的尾部添加就OK了。像在尾部添加元素，`ArrayList`的时间复杂度也就`O(1)`，所以在开发中用得最多
>

> 如果是**集合类型**，有List和Set供我们选择。`List`的特点是**插入有序，元素可重复**。`Set`的特点是**插入无序，元素不可重复**。
>
> 如果是`Key-Value`型，选择`Map`。如果要保持插入顺序的，我们可以选择`LinkedHashMap`，如果不需要则选择`HashMap`，如果要排序则选择`TreeMap`。

## 遍历list

1. `for`循环，指定下标长度，使用`List`集合的`size()`方法，进行`for`循环遍历
2. 使用`foreach`遍历`List`，但不能对某一个元素进行操作（这种方法在遍历数组和`Map`集合的时候同样适用）
3. 适用迭代器`Iterator`遍历：直接根据`List`集合的自动遍历

## ArrayList

`ArrayList`是动态数组，可以动态增减元素，实现了`ICollection`和`IList`接口，可灵活设置数组大小。当装载的是基本类型的数据`int、long、boolean、short、byte...`的时候只能存储它们对应的包装类，底层实现是<span style="color:red">***数组***</span> `Object[] elementDate`

**特点：**查询效率高，增删效率比较低，线程不安全。使用频率很高。

1. **我们本身就有数组了，为什么要用`ArrayList`呢**

   > 由于原生的数组在使用的时候必须要为它创建大小，且不能动态扩容，故出现了`ArrayList`。

2. **为什么`ArrayList`不用创建大小**

   > 通过无参构造方法的方式 `ArrayList()` 初始化，则赋值底层数组 `Object[] elementData` 为一个**默认空数组** `Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}` 所以**数组容量为 0**，**只有真正对数据进行添加 `add` 时，才分配默认 DEFAULT_CAPACITY = 10 的初始容量**。

3. **怎么理解固定和可变？**

   > 假设我们给定数组的大小是`10`，要往这个数组里边填充元素，我们只能添加`10`个元素。而`ArrayList`不一样，因为`ArrayList`是实现了动态扩容的，`ArrayList`在使用的时候可以往里边添加`20`个，`30`个，甚至更多的元素。比如现在有一个长度为10的数组，在新增元素时发现已经满了，那第一步：重新定义一个长度为10+10/2的数组也就是新增一个长度为15的数组。然后把原数组的数据，原封不动的复制到新数组中，这个时候再把指向原数组的地址换到新数组。
   >
   > 在使用`ArrayList`时如果没设置初始值的大小，就使用默认的大小10。如果传入了初始值大小，就使用传入的参数。

5. **怎么扩容？一次扩多少**

   > 使用`ArrayList`在每一次`add`的时候，它都会先去计算这个数组的空间够不够，如果空间足够，那直接追加上去。如果不够，那就得扩容。
   >
   > 在源码里边，有个`grow`方法，每一次扩原来的`1.5`倍
   
   ~~~java
   int newCapacity = oldCapacity + (oldCapacity >> 1);
   ~~~
   
   > 比如说，初始化的值是10。在添加第11个元素时，发现数组空间不够了，会扩到15，空间扩完容之后，会调用`arraycopy`来对数组进行拷贝。另外，`ArrayList`的增删底层调用的`copyOf()`被优化过，现代`CPU`对内存可以**块操作**，`ArrayList`的增删一点儿也不会比`LinkedList`慢。

5. **ArrayList1.7和1.8版本初始化的时候的区别？**

   > 初始化的时候，1.7以前会调用`this(10)`才是真正的容量为10，1.7即本身以后是默认走了空数组，只有第一次add的时候容量会变成10。

6. **ArrayList在增删的时候是怎么做的么？主要说一下他为啥慢。**

   他有指定`index`新增，也有直接新增的。

   在这之前他会有一步校验长度的判断 **`ensureCapacityInternal`** 去检查一下数组的容量是否足够，如果足够则直接添加，长度不够，是需要扩容的。

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/image-20211113140243007.png" alt="image-20211113140243007" style="zoom:50%;" />

   在扩容的时候，老版本的 jdk 和 8 以后的版本是有区别的，8之后的效率更高了，采用了位运算，**右移**一位，扩容到原来的1.5倍

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193720468.png" alt="image-20211113193720468" style="zoom:50%;" />

   指定位置新增的时候，首先检查`index`是否越界，接着进行空间检查看是否需要扩容，最后就是数组的`copy`（复制指定待插入位置`(index a)`及之后的元素，将它们放在`index a+1`的位置上，为新增元素腾出位置)

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193734559.png" alt="image-20211113193734559" style="zoom:50%;" />

7. **ArrayList用来做队列合适么？**

   不适合；队列一般是`FIFO（先入先出）`的，如果用`ArrayList`做队列，就需要在数组尾部追加数据，数组头部删除数组，反过来也可以。但是无论如何总会有一个操作会涉及到数组的数据搬迁，这个是比较耗费性能的。

8. **数组适合用来做队列么？**

   数组是非常合适的。比如`ArrayBlockingQueue`内部实现就是一个环形队列，它是一个定长队列，内部是用一个定长数组来实现的。

   另外著名的`Disruptor`开源`Library`也是用环形数组来实现的超高性能队列。简单点说就是使用两个偏移量来标记数组的读位置和写位置，如果超过长度就折回到数组开头，前提是它们是定长数组。

### API详解

1. `get(int index)` 方法的时间复杂度为 O(1)，因为是直接从底层数组根据下标获取的，和数组长度无关。

   ~~~java
   public E get(int index) {
       Objects.checkIndex(index, size);
       return elementData(index);
   }
   ~~~

2. `add(E e)` 方法会默认将元素添加到数组末尾，但需要考虑到数组扩容的情况，如果不需要扩容，时间复杂度为 O(1)。

   ~~~java
   public boolean add(E e) {
       modCount++;
       add(e, elementData, size);
       return true;
   }
   
   private void add(E e, Object[] elementData, int s) {
       if (s == elementData.length)
           elementData = grow();
       elementData[s] = e;
       size = s + 1;
   }
   ~~~

   如果需要扩容的话，并且不是第一次（`oldCapacity > 0`）扩容的时候，**内部执行的 `Arrays.copyOf()` 方法是耗时的关键**，需要把原有数组中的元素复制到扩容后的新数组当中。

   ~~~java
   private Object[] grow(int minCapacity) {
       int oldCapacity = elementData.length;
       if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
           int newCapacity = ArraysSupport.newLength(oldCapacity,
                   minCapacity - oldCapacity, /* minimum growth */
                   oldCapacity >> 1           /* preferred growth */);
           return elementData = Arrays.copyOf(elementData, newCapacity);
       } else {
           return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];
       }
   }
   ~~~

3. `add(int index, E element)` 方法将新的元素插入到指定的位置，考虑到需要复制底层数组（根据之前的判断，扩容的话，数组可能要复制一次），根据最坏的打算（不管需要不需要扩容，`System.arraycopy()` 肯定要执行），所以时间复杂度为 O(n)。在数组中插入元素的时候，会把插入位置以后的元素依次往后复制

   ~~~java
   public void add(int index, E element) {
       rangeCheckForAdd(index);
       modCount++;
       final int s;
       Object[] elementData;
       if ((s = size) == (elementData = this.elementData).length)
           elementData = grow();
       System.arraycopy(elementData, index,
               elementData, index + 1,
               s - index);
       elementData[index] = element;
       size = s + 1;
   }
   ~~~

4. `remove(int index)` 方法将指定位置上的元素删除，考虑到需要复制底层数组，所以时间复杂度为 O(n)。

   ~~~java
   public E remove(int index) {
       Objects.checkIndex(index, size);
       final Object[] es = elementData;
   
       @SuppressWarnings("unchecked") E oldValue = (E) es[index];
       fastRemove(es, index);
   
       return oldValue;
   }
   private void fastRemove(Object[] es, int i) {
       modCount++;
       final int newSize;
       if ((newSize = size - 1) > i)
           System.arraycopy(es, i + 1, es, i, newSize - i);
       es[size = newSize] = null;
   }
   ~~~

### 与LinkedList相比：

> `ArrayList`的增删**未必**就是比`LinkedList`要慢。

- 如果增删都是在**末尾**来操作【每次调用的都是remove()和add()】，此时`ArrayList`就不需要移动和复制数组来进行操作了。如果数据量有百万级的时，**速度是会比`LinkedList`要快的**。
- 如果**删除操作**的位置是在**中间**。由于`LinkedList`的消耗主要是在遍历上，`ArrayList`的消耗主要是在移动和复制上(底层调用的是`arraycopy()`方法，是`native`方法)。
  - `LinkedList`的遍历速度是要慢于`ArrayList`的复制移动速度的
  - 如果数据量有百万级的时，**还是`ArrayList`要快**。
- `ArrayList`遍历要比`LinkedList`快得多，`ArrayList`遍历最大的优势在于内存的连续性，CPU的内部缓存结构会缓存连续的内存片段，可以大幅降低读取内存的性能开销。

#### 插入

##### 头插

<font color='Chestnut Red'>**LinkedList > ArrayList**</font>

1. `ArrayList `头插时，需要把数组元素通过`Arrays.copyOf`的方式把数组元素移位，如果容量不足还需要扩容。

2. `LinkedList `头插时，则不需要考虑扩容以及移位问题，直接把元素定位到首位，节点链条链接上即可。

   ![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928170956.png)

   分别验证，10万、100万、1000万的数据量，在头插时的一个耗时情况：`ArrayList`需要做大量的位移和复制操作，而`LinkedList`的耗时只是在于实例化一个Node（插入时候会创建新的节点元素，`new Node<>(null, e, f)`）对象。

##### 尾插

<font color='Chestnut Red'>**ArrayList > LinkedList**</font>

1. `ArrayList `尾插时，是不需要数据位移的，比较耗时的是数据的扩容时，需要拷贝迁移。

2. `LinkedList `尾插时，与头插相比耗时点会在对象的实例化上

   ![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928170915.png)

   分别验证，10万、100万、1000万的数据量，在尾插时的一个耗时情况：`ArrayList` 不需要做位移拷贝也就不那么耗时了，而`LinkedList`则需要创建大量的对象。*所以这里`ArrayList`尾插的效果更好一些。*

##### 中间插

<font color='Chestnut Red'>**ArrayList > LinkedList**</font>

1. `ArrayList `中间插入，首先我们知道他的定位时间复杂度是O(1)，比较耗时的点在于数据迁移和容量不足的时候扩容。

2. `LinkedList `中间插入，链表的数据实际插入时候并不会怎么耗时，但是它定位的元素（需要进行遍历）的时间复杂度是O(n)，所以这部分以及元素的实例化比较耗时。

   ![img](https://bugstack.cn/assets/images/2020/interview/interview-9-10.png)

   分别验证，10万、100万、1000万的数据量，在中间插时的一个耗时情况：`Linkedlist`在中间插入时，遍历寻找插入位置非常耗时。

#### 删除

与`ArrayList`不同，`LinkedList`删除不需要拷贝元素，只需找到元素位置，把元素前后链连接上

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928171904.png)

- 确定出要删除的元素 x，把前后的链接进行替换。
- 如果是删除首尾元素，操作起来会更加容易，这也就是为什么说插入和删除快。但中间位置删除，需要遍历找到对应位置

## Vector

`Vector`底层结构是数组，现在已经很少用了，被`ArrayList`替代，原因有两个：

- `Vector`所有方法都被synchronized关键字修饰，**性能相对较低**。

- `Vector`初始`length`是`10 `超过`length`时 以`100%`比率增长，**相比于`ArrayList`更多消耗内存**。

相对于`ArrayList`，它是线程安全的，在扩容的时候它是直接扩容两倍的，比如现在有`10`个元素，要扩容的时候，就会将数组的大小增长到`20`。

## 线程安全List

除了Vector，线程安全的List还有这两种：

> 1. 用`Collections`将`ArrayList`包装一下，变成线程安全。`Collections.synchronizedList(list);`
> 2. 在`java.util.concurrent`包下有一个类叫做`CopyOnWriteArrayList`，适用于读多写少的场景

`CopyOnWriteArrayList`是一个线程安全的`List`，底层是通过**复制数组**的方式来实现的。在`add()`方法它会加`lock`锁，然后会复制出一个新的数组，往新的数组里边`add`真正的元素，最后把`array`的指向改变为新的数组，其实`get()`方法又或是`size()`方法只是获取`array`所指向的数组的元素或者大小。读不加锁，写加锁。

缺点：

> 1. <span style="color:red">很耗费内存</span>：每次`set()/add()`都会复制一个数组出来。
> 2. <span style="color:red">只能保证数据的**最终一致性，不能保证数据的实时一致性**</span>：假设两个线程，线程`A`去读取`CopyOnWriteArrayList`的数据，还没读完，现在线程`B`把这个`List`给清空了，线程`A`此时还是可以把剩余的数据给读出来。

## LinkedList

`LinkedList`既是`List`的实现类，也是`Queue`的实现类，所以`LinkedList`也可以当作队列使用 ，底层是**双向链表**（方便实现往前遍历）。

 `LinkedList `还实现了 `Deque `这个队列接口，可以作为双向队列的实现。

 `LinkedList `实现了一个倒序迭代器 `DescendingIterator`，游标直接在迭代器尾部，实际是向前遍历；还实现了一个 `ListIterator `，名叫 `ListItr`，`ListItr`操作基本都是调用的内部关键方法

`LinkedList `的迭代器都是` fail-fast` 的: 如果在并发环境下，其他线程使用迭代器以外的方法修改数据，会导致 `ConcurrentModificationException`.

特点：

- 基于双端链表，添加/删除元素只会影响周围的两个节点，开销很低；
- 只能顺序遍历，无法按照索引获得元素，因此查询效率不高；
- 没有固定容量，不需要扩容；
- 需要更多的内存，每个节点中需要多存储前后节点的信息，占用空间更多些。

`LinkedList `访问元素时一般是通过 循环遍历获取到这个元素所在位置，然后返回这个元素，时间复杂度为 `O(n)`。删除或者插入一个给定指针指向的结点（例如头尾节点）时间复杂度为` O(1)`，否则为`O(n)`。

### 适用场景

在<font color='Chestnut Red'>**集合的首位有大量的插入、删除、获取操作**</font>时，那么`LinkedList`效率更高，因为它都有相应的方法；`addFirst`、`addLast`、`removeFirst`、`removeLast`、`getFirst`、`getLast`，这些操作的时间复杂度都是O(1)，非常高效。

### 详解

1. `get(int index)` 方法的时间复杂度为 O(n)，因为需要循环遍历整个链表。

   ~~~java
   public E get(int index) {
       checkElementIndex(index);
       return node(index).item;
   }
   
   LinkedList.Node<E> node(int index) {
       // assert isElementIndex(index);
   
       if (index < (size >> 1)) {
           LinkedList.Node<E> x = first;
           for (int i = 0; i < index; i++)
               x = x.next;
           return x;
       } else {
           LinkedList.Node<E> x = last;
           for (int i = size - 1; i > index; i--)
               x = x.prev;
           return x;
       }
   }
   ~~~

   下标小于链表长度的一半时，从前往后遍历；否则从后往前遍历，这样从理论上说，就节省了一半的时间。

   如果下标为 0 或者 `list.size() - 1` 的话，时间复杂度为 O(1)。这种情况下，可以使用 `getFirst()` 和 `getLast()` 方法。

   ~~~java
   public E getFirst() {
       final LinkedList.Node<E> f = first;
       if (f == null)
           throw new NoSuchElementException();
       return f.item;
   }
   
   public E getLast() {
       final LinkedList.Node<E> l = last;
       if (l == null)
           throw new NoSuchElementException();
       return l.item;
   }
   ~~~

   first 和 last 在链表中是直接存储的，所以时间复杂度为 O(1)。

2. `add(E e)` 方法默认将元素添加到链表末尾，所以时间复杂度为 O(1)。

   ~~~java
   public boolean add(E e) {
       linkLast(e);
       return true;
   }
   void linkLast(E e) {
       final LinkedList.Node<E> l = last;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(l, e, null);
       last = newNode;
       if (l == null)
           first = newNode;
       else
           l.next = newNode;
       size++;
       modCount++;
   }
   ~~~

3. `add(int index, E element)` 方法将新的元素插入到指定的位置，需要先通过遍历查找这个元素，然后再进行插入，所以时间复杂度为 O(n)。

   ~~~java
   public void add(int index, E element) {
       checkPositionIndex(index);
   
       if (index == size)
           linkLast(element);
       else
           linkBefore(element, node(index));
   }
   ~~~

   如果下标为 0 或者 `list.size() - 1` 的话，时间复杂度为 O(1)。这种情况下，可以使用 `addFirst()` 和 `addLast()` 方法。

   ~~~java
   public void addFirst(E e) {
       linkFirst(e);
   }
   private void linkFirst(E e) {
       final LinkedList.Node<E> f = first;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(null, e, f);
       first = newNode;
       if (f == null)
           last = newNode;
       else
           f.prev = newNode;
       size++;
       modCount++;
   }
   ~~~

   `linkFirst()` 只需要对 first 进行更新即可。

   ~~~java
   public void addLast(E e) {
       linkLast(e);
   }
   
   void linkLast(E e) {
       final LinkedList.Node<E> l = last;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(l, e, null);
       last = newNode;
       if (l == null)
           first = newNode;
       else
           l.next = newNode;
       size++;
       modCount++;
   }
   ~~~

   `linkLast()` 只需要对 last 进行更新即可。

   需要注意的是，有些文章里面说，LinkedList 插入元素的时间复杂度近似 O(1)，其实是有问题的，因为 `add(int index, E element)` 方法在插入元素的时候会调用 `node(index)` 查找元素，该方法之前我们之间已经确认过了，时间复杂度为 O(n)，即便随后调用 `linkBefore()` 方法进行插入的时间复杂度为 O(1)，总体上的时间复杂度仍然为 O(n) 才对。

   ~~~java
   void linkBefore(E e, LinkedList.Node<E> succ) {
       // assert succ != null;
       final LinkedList.Node<E> pred = succ.prev;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(pred, e, succ);
       succ.prev = newNode;
       if (pred == null)
           first = newNode;
       else
           pred.next = newNode;
       size++;
       modCount++;
   }
   ~~~

4. `remove(int index)` 方法将指定位置上的元素删除，考虑到需要调用 `node(index)` 方法查找元素，所以时间复杂度为 O(n)。

   ~~~java
   public E remove(int index) {
       checkElementIndex(index);
       return unlink(node(index));
   }
   
   E unlink(LinkedList.Node<E> x) {
       // assert x != null;
       final E element = x.item;
       final LinkedList.Node<E> next = x.next;
       final LinkedList.Node<E> prev = x.prev;
       if (prev == null) {
           first = next;
       } else {
           prev.next = next;
           x.prev = null;
       }
       if (next == null) {
           last = prev;
       } else {
           next.prev = prev;
           x.next = null;
       }
       x.item = null;
       size--;
       modCount++;
       return element;
   }
   ~~~



## CopyOnWriteArrayList(Set)

`CopyOnWriteArrayList`是同步`List`的替代品，`CopyOnWriteArraySet`是同步`Set`的替代品。

无论是`Hashtable --> ConcurrentHashMap`，还是说`Vector --> CopyOnWriteArrayList`。`JUC`下支持并发的容器与老一代的线程安全类相比，总结起来就是加锁<span style="background:yellow;color:black">**粒度**</span>的问题

- `Hashtable、Vector`加锁的粒度大(直接在方法声明处使用`synchronized`)
- `ConcurrentHashMap、CopyOnWriteArrayList`加锁粒度小(`ConcurrentHashMap`用`CAS `操作、 `Synchronized `、`volatile`等方式来实现线程安全；`CopyOnWriteArrayList`的 add() 方法添加了`ReentrantLock`，修改操作时用创建副本（Copy）的方式来实现线程安全)
- `JUC`下的线程安全容器在遍历的时候**不会**抛出`ConcurrentModificationException`异常

所以一般来说，我们都会**使用JUC包下给我们提供的线程安全容器**。

下面我们来看看`CopyOnWriteArrayList`是怎么实现的，为什么使用**迭代器遍历**的时候**不用额外加锁**，也不会抛出`ConcurrentModificationException`异常。

回顾一下`COW`：

> 如果有多个调用者（`callers`）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取**相同的指针指向相同的资源**，直到某个调用者**试图修改**资源的内容时，系统才会**真正复制一份专用副本**（`private copy`）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。**优点**是如果调用者**没有修改该资源，就不会有副本**（`private copy`）被建立，因此多个调用者只是读取操作时可以**共享同一份资源**。

- `CopyOnWriteArrayList`是线程安全容器，底层通过**复制数组**的方式来实现。
- `CopyOnWriteArrayList`在遍历的时候不会抛出`ConcurrentModificationException`异常，因为该集合在进行写操作（添加、删除等）时，并不直接在原始数据上进行修改，而是先创建一个原集合的拷贝，然后在拷贝上进行修改，最后将拷贝赋值给原始集合。故遍历的时候就不用额外加锁
- 元素可以为`null`

### 基本结构

``` JAVA
 /** 可重入锁对象 */
    final transient ReentrantLock lock = new ReentrantLock();

    /** CopyOnWriteArrayList底层由数组实现，volatile修饰 */
    private transient volatile Object[] array;

    /**
     * 得到数组
     */
    final Object[] getArray() {
        return array;
    }

    /**
     * 设置数组
     */
    final void setArray(Object[] a) {
        array = a;
    }

    /**
     * 初始化CopyOnWriteArrayList相当于初始化数组
     */
    public CopyOnWriteArrayList() {
        setArray(new Object[0]);
    }
```

`CopyOnWriteArrayList`底层就是数组，加锁交由`ReentrantLock`来完成。使用迭代器遍历时不需要显示加锁。

如果遍历`Vector/SynchronizedList`是需要自己手动加锁的。

- **在写操作（添加、删除等）时，复制出一个新数组，写操作在新数组中完成，最后将新数组交由array变量指向**。
- **写加锁，读不加锁**

`CopyOnWriteArrayList`在使用迭代器遍历的时候，操作的都是**原数组**（所以遍历时得到的是“旧”数据）！所以能够在容器遍历的时候对其进行修改而不抛出异常

``` java
  // 1. 返回的迭代器是COWIterator
  public Iterator<E> iterator() {
        return new COWIterator<E>(getArray(), 0);
    }

  // 2. 迭代器的成员属性
    private final Object[] snapshot;
    private int cursor;

  // 3. 迭代器的构造方法
  private COWIterator(Object[] elements, int initialCursor) {
        cursor = initialCursor;
        snapshot = elements;
    }

  // 4. 迭代器的方法...
  public E next() {
        if (! hasNext())
            throw new NoSuchElementException();
        return (E) snapshot[cursor++];
    }

  //.... 可以发现的是，迭代器所有的操作都基于snapshot数组，而snapshot是传递进来的array数组

```

### 缺点

- **内存占用**：如果`CopyOnWriteArrayList`经常要增删改（执行`add()、set()、remove()`）里面的数据，那是比较耗费内存的。因为每次增删改操作都要**复制一个数组**出来。
- **数据一致性**：`CopyOnWrite`容器**只能保证数据的最终一致性，不能保证数据的实时一致性**。比如线程`A`在迭代`CopyOnWriteArrayList`容器的数据。线程`B`在线程`A`迭代的间隙中将`CopyOnWriteArrayList`部分的数据修改了(已经调用`setArray()`了)。但是线程`A`迭代出来的是原有的数据。

# Map

> `Map`在`Java`里边是一个接口，常见的实现类有`HashMap`、`LinkedHashMap`、`TreeMap`和`ConcurrentHashMap`
>
> 在`Java`里边，哈希表的结构是`数组+链表`的方式
>
> `HashMap`、`ConcurrentHashMap`底层数据结构是`数组+链表/红黑树`
>
> `LinkedHashMap`底层数据结构是`数组+链表+双向链表`
>
> `TreeMap`底层数据结构是红黑树
>
> **`LinkedHashMap `和 `TreeMap`是有序的Map**

## HashMap

1.8版本之后数据结构为<font color='Apricot'>数组+链表/红黑树</font>。`Key-Value`都可以为 null

1. **当`new`一个HashMap的时候，会发生什么？**

   > - `HashMap`的构造方法中最主要的就是指定初始值大小和负载因子的大小。如果不指定，默认`HashMap`的大小为`16`，负载因子的大小为`0.75`
   > - `HashMap`的大小只能是**`2`次幂**的，所以扩容的时候时候默认是扩原来的`2`倍。假设传一个`10`进去，实际上最终`HashMap`的大小是`16`，传一个7进去，`HashMap`最终的大小是`8`，具体的实现在`tableSizeFor`方法可以看到。我们把元素放进`HashMap`的时候，需要算出这个元素所在的位置（hash）。在`HashMap`里用的是**位运算**来代替取模，能够更加**高效**地算出该元素所在的位置。`HashMap`的大小只能是`2`次幂的原因是只有大小为`2`次幂时，**才能合理用位运算替代取模**
   > - 负载因子的大小决定着哈希表的**扩容**和**哈希冲突**。比如默认的`HashMap`大小为`16`，负载因子为`0.75`，这意味着数组最多只能放`16 * 0.75 = 12`个元素，一旦超过`12`个元素，哈希表需要扩容。每次`put`元素进去的时候，都会检查`HashMap`的大小有没有超过这个阈值，如果有，就要扩容；扩容操作是耗时的，但是也不推荐调高负载因子。负载因子调高了，这意味着**哈希冲突的概率**会增高，哈希冲突概率增高，查找的速度变慢了同样会耗时。

2. **在 put 元素的时候，传递的 key 是怎样计算哈希值的**

   ~~~java
   (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
   ~~~

   实现就在`hash`方法上，它是先算出正常的哈希值，然后与**高16位**做异或运算，产生最终的哈希值。这样做的好处可以**增加了随机性**，减少了碰撞冲突的可能性。

3. **HashMap 的 put / get 方法的实现**

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/1bc8b49a4d3948e9992b23f8af586603~tplv-k3u1fbpfcp-zoom-1.image" style="zoom: 67%;" />

   在**`put`**的时候，首先对`key`做`hash`运算，计算出该`key`所在的`index`。如果没碰撞，直接放到数组中，如果碰撞了，需要判断目前数据结构是链表还是红黑树，根据不同的情况来进行插入。假设`key`是相同的，则替换到原来的值。最后判断哈希表是否满了(当前哈希表大小`*`负载因子），如果满了，则扩容。

   在**`get`**的时候，还是对`key`做`hash`运算，计算出该`key`所在的`index`，然后判断是否有`hash`冲突，如果没有直接返回，如果有则判断当前数据结构是链表还是红黑树，分别从不同的数据结构中取出。

4. **在HashMap中，怎样判断一个元素是否相同**

   首先会比较`hash`值，随后会用`==`运算符和`equals()`来判断该元素是否相同。说白了就是：如果只有`hash`值相同，那说明该元素哈希冲突了，如果`hash`值和`equals() || ==` 都相同，那说明该元素是同一个。

5. **什么情况会用到链表和红黑树**

   > - 数组长度是有限的，在有限的长度里面使用哈希可能出现哈希冲突，对于哈希冲突的元素放在链表上。
   >
   >   `HashMap`通过`key`的`hashCode`经过 扰动函数 `(hashcode的高16位和低16位进行异或操作)`处理后得到`hash`值，然后通过`(n-1)&hash`判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存入的元素`hash`值以及`key`是否相同，如果相同直接覆盖，不相同就通过**拉链法**解决冲突。
   >
   > - 当数组的大小大于**`64`**且链表的大小大于**`8`**的时候会将链表改为红黑树，当红黑树大小为**`6`**时，会退化为链表。这里转红黑树退化为链表的操作主要出于**查询和插入时对性能的考量**。链表查询时间复杂度`O(N)`，插入时间复杂度`O(1)`，红黑树查询和插入时间复杂度`O(logN)`

6. **Java中HashMap的key值要是为类对象则该类需要满足什么条件？**

   <span style="background:#f9eda6;">**需要同时重写该类的`hashCode()`方法和它的`equals()`方法**。</span>

   一般来说，我们会认为：**只要两个对象的成员变量的值是相等的，那么我们就认为这两个对象是相等的**！但是`Object`底层比较的是两个对象的地址，而对我们开发来说这样的意义并不大~这也就为什么我们要重写`equals()`方法

   重写了`equals()`方法，就要重写`hashCode()`的方法。因为**`equals()`认定了这两个对象相同**，而**同一个对象调用`hashCode()`方法时**，是应该返回相同的值的！

   > 因为在java中，所有的对象都是继承于 `Object` 类。`Ojbect` 类中有两个方法`equals、hashCode`，这两个方法都是用来比较两个对象是否相等的。未重写 `equals `方法时我们是继承了`object`的` equals` 方法，**那里的 `equals`是比较两个对象的内存地址**，显然new了2个对象内存地址肯定不一样。
   >
   > `HashMap` 是通过`key`的` hashCode` 去寻找` index` 的，`index`一样就会形成链表，假如A、B在一个链表上，`index `都为2。我们`get`的时候，是根据 `key` 去 `hash` 然后计算出 `index`，找到`index`为`2`处，这就没法分辨`到底是要 A 还是 B` ,所以如果对`equals`方法进行了重写，一定要对` hashCode `方法重写，以保证相同的对象返回相同的`hash值`，不同的对象返回不同的`hash值`。不然一个链表的对象，发现 `hashCode` 都一样，就无法知道要找的是哪个。

   > - 从源码可以得知，在插入元素的时候是**先算出该对象的`hashCode`**。如果`hashcode`相等话的。那么表明该对象是存储在同一个位置上的。
   > - 如果调用`equals()`方法，**两个`key`相同**，则**替换元素**
   > - 如果调用`equals()`方法，**两个`key`不相同**，则说明该**`hashCode`仅仅是碰巧相同**，此时是散列冲突，将新增的元素放在桶子上

7. **新的Entry节点是怎么插入的链表**

   <span style="color:red">`java8`之前是头插法</span>，就是说新来的值会取代原有的值，原有的值就顺推到链表中去，因为写这个代码的作者认为新加的值被查找的可能性更大一点，能够提升查找的效率。但是，<span style="color:red">在`java8`之后，都是使用尾部插入了</span>

   > 为啥改为尾部插入
   >
   > 1. 头插法会改变链表中元素原本的顺序，导致链表成环的问题，而尾插法，链表元素顺序不变，不会出现链表成环的问题
   >
   > 2. 能够更好的利用 CPU 缓存的局部性原理，提高性能
   >
   >    > 尾插法对 CPU 缓存的局部性原理有利的主要原因是它减少了链表节点的随机访问，提高了连续访问节点的可能性，从而更好地利用了 CPU 缓存的特性，提高了性能。
   >    >
   >    > CPU 缓存通常由三级结构组成：L1 Cache（一级缓存）、L2 Cache（二级缓存）、L3 Cache（三级缓存），以及主存。缓存系统在处理数据时具有局部性原理，分为两种：
   >    >
   >    > 1. **时间局部性（Temporal Locality）：** 如果一个数据被访问，那么在不久之后它很可能再次被访问。
   >    > 2. **空间局部性（Spatial Locality）：** 如果一个数据被访问，那么在接下来的一段时间内，与它相邻的数据也可能会被访问。
   >    >
   >    > 尾插法在 HashMap 中应用，将新的节点插入到链表的尾部。这样做有利于提高空间局部性，因为新插入的节点会被放在链表末尾，节点之间是连续存储的。当程序遍历链表时，由于节点是顺序存储的，它们更有可能被缓存在CPU的缓存层次结构中，这就利用了 CPU 缓存的局部性原理。
   >    >
   >    > 相反，如果使用头插法，新节点总是插入链表的头部，这会破坏空间局部性，因为新节点插入后，链表中的节点在内存中可能不是连续存储的，这样会导致节点之间的跳跃式访问，降低了 CPU 缓存的利用率，增加了缓存的失效率。
   >    >
   >    > 因此，尾插法利用了空间局部性的特性，有助于提高节点的连续性存储，减少了随机访问，更好地利用了 CPU 缓存的局部性原理，提高了性能。

8. **扩容方式**

   扩容的时候1.7需要对原数组中的元素进行重新`hash`定位在新数组的位置

   1.8采用更简单的判断逻辑，原哈希值与扩容新增出来的长度`16`进行`&`运算，若值等于 0 ，下标位置不变，若不为 0 ，新的位置为原来位置加16；

   > 扩容的时候为什么1.8 不用重新`hash`就可以直接定位原节点在新数据的位置呢? 
   >
   > 这是由于扩容是扩大为原数组大小的`2`倍，用于计算数组位置的掩码仅仅只是高位多了一个`1`，怎么理解呢？ 扩容前长度为`16`，用于计算`(n-1) & hash` 的二进制`n-1`为`0000 1111`，扩容为`32`后的二进制就高位多了`1`，为`0001 1111`。 因为是`&` 运算，`1`和任何数` & `都是它本身，那就分两种情况，原数据`hashcode`高位第`4`位为`0`和高位为`1`的情况； 第四位高位为`0`，重新`hash`数值不变，第四位为`1`，重新`hash`数值比旧数组的容量大`16`


### 扰动函数

**HashMap的哈希函数怎么设计的? 为什么这么设计**

~~~java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
~~~

`hash`函数是先拿到`key `的`hashcode`，是`32`位的`int`值，然后让`hashcode`的高`16`位和低`16`位进行异或操作。

这个也叫扰动函数，这么设计有二点原因：

1. 一定要尽可能降低`hash`碰撞，越分散越好；
2. 算法一定要尽可能高效，因为这是高频操作, 因此采用位运算；

**为什么采用hashcode的高16位和低16位异或能降低hash碰撞？hash函数能不能直接用key的hashcode？**

1. 把哈希值右移`16`位，正好是自己长度的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。
2. 不能，因为`key.hashCode()`函数调用的是`key`键值类型自带的哈希函数，返回`int`型散列值。`int`值范围为**`-2147483648~2147483647`**，前后加起来大概`40`亿的映射空间。只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个`40`亿长度的数组，内存是放不下的。如果HashMap数组的初始大小才16，用之前需要对数组的长度取模运算，得到的余数才能用来访问数组下标。

~~~markdown
1. ThreadLocal 是基于数组的开放寻址数据结构，采用的斐波那契散列，因为它在有限空间内，对线程内的元素计算索引位置更加分散。HashMap 为了降低元素的碰撞采用的是扰动函数
2. HashMap 为了解决元素的碰撞，采用哈希桶 + 链表/红黑树的数据结构，也称为拉链寻址。开放寻址是 ThreadLocal 解决元素的碰撞使用的数据结构
~~~

### 1.8的优化

1. 数组 + 链表改成了数组+链表或红黑树；

   > 防止发生`hash`冲突，链表长度过长，将时间复杂度由`O(n)`降为`O(logn)`;

2. 链表的插入方式从头插法改成了尾插法，简单说就是插入时，如果数组位置上已经有元素，1.7将新元素放到数组中，原始节点作为新节点的后继节点，1.8遍历链表，将元素放置到链表的最后；

   > 因为1.7头插法扩容时，头插法会使链表发生反转，多线程环境下会产生环； A线程在插入节点B，B线程也在插入，遇到容量不够开始扩容，重新`hash`，放置元素，采用头插法，后遍历到的B节点放入了头部，这样形成了环

3. 扩容的时候1.7需要对原数组中的元素进行重新`hash`定位在新数组的位置，1.8采用更简单的判断逻辑，原哈希值与扩容新增出来的长度进行`&`运算，若值等于 0 ，下标位置不变，若不为 0 ，新的位置为原来位置加原数组长度；

   > 扩容的时候为什么1.8 不用重新`hash`就可以直接定位原节点在新数据的位置呢? 这是由于扩容是扩大为原数组大小的`2`倍，用于计算数组位置的掩码仅仅只是高位多了一个`1`，假设扩容前长度为`16`，用于计算`(n-1) & hash` 的二进制`n-1`为`0000 1111`，扩容为`32`后的二进制就高位多了`1`，为`0001 1111`。 因为是`&` 运算，`1`和任何数` & `都是它本身，那就分二种情况，原数据`hashcode`高位第`4`位为`0`和高位为`1`的情况； 第四位高位为`0`，重新`hash`数值不变，第四位为`1`，重新`hash`数值比旧数组的容量大`16`

4. 在插入时，1.7先判断是否需要扩容，再插入，1.8先进行插入，插入完成再判断是否需要扩容

### 最大容量

`HashMap`的最大容量规定为：

```java
// 最大容量（必须是2的幂且小于2的30次方，传入容量过大将被这个值替换）
static final int MAXIMUM_CAPACITY = 1 << 30;
```

"<<"为左移运算符，1表示十进制中的“1”，30表示十进制数字1转化为二进制后向左移动30位。在数值上等同于2的30次幂。

首先：`JAVA`规定了该`static final `类型的静态变量为`int`类型，至于为什么不是`byte`、`long`等类型，原因是由于考虑到`HashMap`的性能问题而作的折中处理！

由于`int`类型限制了该变量的长度为`4`个字节共`32`个二进制位，按理说可以向左移动`31`位即`2`的`31`次幂。但是事实上由于二进制数字中最高的一位也就是最左边的一位是符号位，用来表示正负之分（0为正，1为负），所以只能向左移动`30`位，而不能移动到处在最高位的符号位！



## HashMap与HashTable

> 从**存储结构**和**实现**来讲基本上都是相同的。它和`HashMap`的最大的不同是<span style="background:#f9eda6;">它是线程安全</span>的，另外`HashTable`<span style="background:#f9eda6;">不允许`key`和`value`为`null`</span>。`Hashtable`是个过时的集合类，不建议在新代码中使用，不需要线程安全的场合可以用`HashMap`替换，需要线程安全的场合可以用`ConcurrentHashMap`替换

**相同点:**

1. `HashMap`和`Hashtable`都实现了`Map`、`Cloneable`（可克隆）、`Serializable`（可序列化）这三个接口

**不同点:**

1. 底层数据结构不同：jdk1.7 底层都是数组+链表，但 jdk1.8 HashMap 加入了红黑树
2. `Hashtable `是不允许键或值为 null 的，HashMap 的键值则都可以为 null。
3. 添加 key-value 的 hash 值算法不同：HashMap添加元素时，是使用自定义的哈希算法,而 `HashTable `是直接采用 key 的 `hashCode()`
4. 实现方式不同：`Hashtable `继承的是 `Dictionary`类，而 `HashMap `继承的是 `AbstractMap `类。
5. 初始化容量不同：`HashMap `的初始容量为：16，`Hashtable `初始容量为：11，两者的负载因子默认都是：0.75。
6. 扩容机制不同：当已用容量>总容量 * 负载因子时，`HashMap `扩容规则为当前容量翻倍，`Hashtable `扩容规则为当前容量翻倍 +1。
7. 支持的遍历种类不同：`HashMap`只支持`Iterator`遍历,而`HashTable`支持`Iterator`和`Enumeration`两种方式遍历
8. 迭代器不同：`HashMap`的迭代器(Iterator)是fail-fast迭代器，而`Hashtable`的`Enumeration`迭代器不是fail-fast的。所以当有其它线程改变了`HashMap`的结构（增加或者移除元素），将会抛出`ConcurrentModificationException`，但迭代器本身的`remove()`方法移除元素则不会抛出`ConcurrentModificationException`异常。但这并不是一个一定发生的行为，要看JVM。而Hashtable 则不会。
9. 部分API不同：`HashMap`不支持`contains(Object value)`方法，没有重写`toString()`方法,而`HashTable`支持`contains(Object value)`方法，而且重写了`toString()`方法
10. 同步性不同: `Hashtable`是同步(synchronized)的，适用于多线程环境,而`HashMap`不是同步的，适用于单线程环境。多个线程可以共享一个`Hashtable`；而如果没有正确的同步的话，多个线程是不能共享HashMap的。

## LinkedHashMap

它**继承**了`HashMap`，在`HashMap`的基础上维护了一个**双向链表** ，有头尾节点，同时`LinkedHashMap`节点`Entry`内部除了继承`HashMap`的`Node`属性，还有`before `和 `after`用于标识前置节点和后置节点。可以实现按插入的顺序或访问顺序排序。

- **底层结构是`数组+链表+双向链表`**

- 允许为null，不同步
- 插入的顺序是有序的(底层链表致使有序)
- 装载因子和初始容量对`LinkedHashMap`影响是很大的~

`LinkedHashMap`在遍历的时候实际用的是双向链表来遍历的，所以`LinkedHashMap`的大小不会影响到遍历的性能。

## TreeMap

`TreeMap`是按照`Key`的自然顺序或者`Comparator`的顺序进行排序，底层数据结构是**红黑树**。所以要么`key`所属的类实现Comparable接口，或者自定义一个实现了`Comparator`接口的比较器，传给`TreeMap`用于`key`的比较。`Comparator`维护了一个变量，**如果该变量为`null`，那么就使用自然顺序**

- `TreeMap`实现了`NavigableMap`接口，而`NavigableMap`接口继承着`SortedMap`接口，使**`TreeMap`是有序的**！
- `TreeMap`底层是红黑树，它方法的时间复杂度都不会太高:`log(n)`
- `key`不能为`null`，为`null`为抛出`NullPointException`的
- `TreeMap`是非线程安全的，想要同步可以使用`Collections`来进行封装
- 使用`Comparator`或者`Comparable`来比较`key`是否相等与排序的问题

## 线程安全Map

1. 什么是线程安全？

> **线程安全**就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。
>
> **线程不安全**就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据

`HashMap`不是线程安全的，在多线程环境下，`HashMap`有可能会有数据丢失和获取不了最新数据的问题，比如说：线程`A` `put`进去了，线程`B` `get`不出来。

**线程安全的Map**

一般在多线程的场景，会使用这几种不同的方式去代替：

- 使用`Collections.synchronizedMap(Map)`创建线程安全的`map`集合；
- `Hashtable`
- `ConcurrentHashMap`

不过因为前两个是直接在外层套`synchronize`，导致线程并发度不高，`ConcurrentHashMap`的性能和效率明显高于前两者。

## ConcurrentHashMap

- JDK1.8底层是**数组 + 链表/红黑树**

  在`1.7`中：**`segments`+`HashEntry`数组**

- `ConCurrentHashMap`支持**高并发**的访问和更新，它是通过**`Node + CAS + synchronized`来实现线程安全的**。synchronized锁定的是每个桶（bucket）的首节点（即链表或红黑树的头节点），这样只要hash不冲突，就不会产生并发

- 检索操作不用加锁，`get`方法是非阻塞的，`Node`都用了`volatile`给修饰

- `key`和`value`都不允许为`null`

- 在扩容时，会给每个线程分配对应的**区间**，并且为了防止`putVal`导致数据不一致，会给线程的所负责的区间加锁。

> <font color='Apricot'>**为啥不允许键值为 null**</font>
>
> 因为`ConcurrentHashMap`的`put `方法会判断键值，如果为空抛`NullPointerException`，但是`HashMap`却做了特殊处理。
>
> ```java
> static final int hash(Object key) { 
> 	int h;
> 	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
> }
> ```
>
> 因为`ConCurrentHashMap`使用的是安全失败机制（fail-safe），这种机制会使此次读到的数据不一定是最新的数据。如果使用`null`值，就会使得其无法判断对应的`key`是不存在还是为空，因为你无法再调用一次`contain(key）`来对`key`是否存在进行判断，`ConcurrentHashMap`同理。
>
> `fail-safe` 是 `Java `中的一种 `安全失败` 机制，它表示的是在遍历时不是直接在原集合上进行访问，而是先复制原有集合内容，在拷贝的集合上进行遍历。 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发 `ConcurrentModificationException`。`java.util.concurrent` 包下的容器都是安全失败的，可以在多线程条件下使用，并发修改

1. **fail-fast**

> fail—fast是`java`集合中的一种`快速失败`机制，`java.util` 包下所有的集合都是快速失败的，快速失败会抛出 `ConcurrentModificationException` 异常。它只能用来检测错误，不会对错误进行恢复，`fail-fast` 不一定只在`多线程`环境下存在，`ArrayList `也会抛出这个异常，主要原因是由于 **`modCount` 不等于 `expectedModCount`**。
>
> <span style="color:red">原理</span>：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 `modCount` 变量。集合在被遍历期间如果内容发生变化，就会改变`modCount`的值。
>
> 每当迭代器使用`hashNext()/next()`遍历下一个元素之前，都会检测`modCount`变量是否为`expectedmodCount`值，是的话就返回遍历；否则抛出异常，终止遍历。
>
> <span style="color:red">注意</span>：这里异常的抛出条件是检测到 `modCount！=expectedmodCount` 这个条件。如果集合发生变化时修改`modCount`值刚好又设置为了`expectedmodCount`值，则异常不会抛出。
>
> 因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的`bug`。
>
> <span style="color:red">场景</span>：`java.util`包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）算是一种安全机制吧。 

2. **ConcurrentHashMap的数据结构**

   在`1.7`中：**`segments`+`HashEntry`数组**

   > `Segment` 是 `ConcurrentHashMap` 的一个内部类，**继承了ReentrantLock**，每个片段都有一个锁，叫做“**锁分段**”。`HashEntry`跟`HashMap`差不多，不同点是，它使用`volatile`去修饰了它的数据`Value`还有下一个节点`next`。
   >
   > 因为基本上还是数组加链表的方式，查询的时候，还得遍历链表，会导致效率很低，这个跟`jdk1.7`的`HashMap`是存在的一样问题。

   `1.8`是基于 **数组 + 链表/红黑树** 组成的

   > `JDK1.8`抛弃了原有的 `Segment` 分段锁，而采用了 `Node + CAS + synchronized` 来保证并发安全性。
   >
   > 跟`HashMap`很像，也把之前的`HashEntry`改成了`Node`，但是作用不变，把值和`next`采用了`volatile`去修饰，保证了可见性，并且也引入了红黑树，在链表大于一定值的时候会转换（默认是`8`）。

3. **为啥ConcurrentHashMap并发度高？**

   > 1. **Node + CAS + Synchronized**： 当发生并发插入或更新操作时，如果两个线程需要修改同一个桶中的节点，它们会先尝试使用CAS（Compare and Swap）操作来进行节点的插入或更新，如果CAS操作失败，即有其他线程正在对该桶进行修改，那么这两个线程将会进入`Synchronized`块，其中一个线程会获得锁，进行链表或红黑树的修改，而另一个线程则会等待，直到锁释放后再尝试操作。通过这种机制，`ConcurrentHashMap`在保证线程安全的同时，减小了锁的粒度，提高了并发性能。<font color='Peach'>Synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发。</font>
   > 2. **扩容优化：** 在JDK 1.8中，`ConcurrentHashMap`的扩容机制进行了优化，采用了一种分段锁扩容的方式，只对需要扩容的段进行操作，减少了扩容时的锁竞争，提高了扩容的效率。
   > 3. **优化的put操作：** 在put操作中进行了一些优化，比如通过先尝试非阻塞方式写入数据，如果失败再使用阻塞方式写入，避免了不必要的阻塞，提高了并发性能。

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/20240313134116" alt="img" style="zoom:67%;" />

## 遍历map

1. 在`for-each`循环中使用`entries`来遍历

**在键值都需要时使用**。

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
for (Map.Entry<Integer, Integer> entry : map.entrySet()) {
    System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue());
}
```

2. 在`for-each`循环中遍历`keys`或`values`。

如果**只需要`map`中的键或者值**，可通过`keySet`或`values`来实现遍历，而不是用`entrySet`。该方法比`entrySet`遍历在性能上稍好（快了10%），而且代码更加干净。

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();

//遍历map中的键
for (Integer key : map.keySet()) {
    System.out.println("Key = " + key);
}
//遍历map中的值
for (Integer value : map.values()) {
    System.out.println("Value = " + value);
}
```

3. 使用`Iterator`遍历

使用泛型：

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
Iterator<Map.Entry<Integer, Integer>> entries = map.entrySet().iterator();
 
while (entries.hasNext()) {
    Map.Entry<Integer, Integer> entry = entries.next();
    System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue());
 
}
```

不使用泛型：

```java
Map map = new HashMap();
Iterator entries = map.entrySet().iterator();
while (entries.hasNext()) {
    Map.Entry entry = (Map.Entry) entries.next();
    Integer key = (Integer)entry.getKey();
    Integer value = (Integer)entry.getValue();
    System.out.println("Key = " + key + ", Value = " + value);
}
```

首先，在老版本`java`中这是唯一遍历`map`的方式。另一个好处是，可以在遍历时调用`iterator.remove()`来删除`entries`，另两个方法则不能。根据`javadoc`的说明，如果在`for-each`遍历中尝试使用此方法，结果是不可预测的。

从性能方面看，该方法类同于`for-each`遍历（方法二）的性能。

4. 通过键找值遍历（效率低）

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
 
for (Integer key : map.keySet()) {
    Integer value = map.get(key);
    System.out.println("Key = " + key + ", Value = " + value);
}
```

作为方法一的替代，这个代码看上去更加干净；但实际上它相当慢且无效率。因为从键取值是耗时的操作（与方法一相比，在不同的`Map`实现中该方法慢了`20%~200%`）。如果你安装了`FindBugs`，它会做出检查并警告你关于哪些是低效率的遍历。所以尽量避免使用。

# Set

> List和Set都是集合，一般来说：**如果我们需要保证集合的元素是唯一的，就应该想到用Set集合**
>
> Set集合实际**大都使用的是Map集合的put方法来添加元素**。

## 遍历set

1.迭代遍历

2.for循环遍历

## HashSet

**特点**

基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的

- 继承于 `AbstractSet `接口，实现了 `Set、Cloneable,、java.io.Serializable` 接口。

- 不保证迭代顺序， 不允许集合中出现重复的值。
- 允许元素为null
- **底层实际上是一个`HashMap`实例**
- 非同步
- 初始容量非常影响迭代性能
- 存储取出都比较快；
- 线程不安全，运行速度快；

`HashSet`实际上就是封装了`HashMap`，**操作`HashSet`元素实际上就是操作`HashMap`**。这也是面向对象的一种体现，**重用性非常高**！

>  `HashSet`是如何判断`Key`是重复的 ？

`HashSet`不能添加重复的元素，当调用`add(Object)`方法时候，首先会调用`Object`的`hashCode`方法判`hashCode`是否已经存在，如不存在则直接插入元素；

如果已存在则调用`Object`对象的`equals`方法判断是否返回`true`，如果为`true`则说明元素已经存在，如为`false`则插入元素。

> `HashSet`里的元素不能重复，在源码(`HashMap`)是这样体现的：

```java
// 1. 如果key 相等  
    if (p.hash == hash &&
        ((k = p.key) == key || (key != null && key.equals(k))))
        e = p;
  // 2. 修改对应的value
     if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
       }
```

添加元素的时候，如果`key`(也对应的`Set`集合的元素)相等，那么则修改`value`值。而在`Set`集合中，`value`值仅仅是一个`Object`对象罢了(**该对象对`Set`本身而言是无用的**)。

也就是说：`Set`集合如果添加的元素相同时，**是根本没有插入的(仅修改了一个无用的`value`值)**！从源码(`HashMap`)中也看出来，**==和equals()方法都有使用**！

## TreeSet

基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。

- 实现`NavigableSet`接口
- 可以实现排序功能
- **底层实际上是一个`TreeMap`实例**
- 不允许元素为null
- 非同步

## LinkedHashSet

具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。

- 迭代是有序的
- 允许为`null`
- **底层实际上是一个`HashMap+双向链表实例`(其实就是`LinkedHashMap`)...**
- 非同步
- 性能比`HashSet`差一丢丢，因为要维护一个双向链表
- 初始容量与迭代无关，`LinkedHashSet`迭代的是双向链表

# 区别

##ArrayList、Vector区别

**共同点：**

- 这两个类都实现了`List`接口，它们都是**有序**的集合(存储有序)，**底层是数组**。我们可以按位置索引号取出某个元素，**允许元素重复和为`null`**。

**区别：**

- **同步性：**
  - `ArrayList`是非同步的
  - `Vector`是同步的
  - 即便需要同步的时候，我们可以使用`Collections`工具类来构建出同步的`ArrayList`而不用`Vector`
- **扩容大小：**
  - `Vector`增长原来的一倍，`ArrayList`增长原来的`0.5`倍



## ArrayList,LinkedList区别

1. `LinkedList`和`ArrayList`的差别主要是由于数据结构的不同。`ArrayList`是基于数组实现的，`LinkedList`是基于双链表实现的。另外`LinkedList`类不仅是`List`接口的实现类，可以根据索引来随机访问集合中的元素，还实现了`Deque`接口，`Deque`接口是`Queue`接口的子接口，它代表一个双向队列，因此`LinkedList`可以作为双向队列 ，栈和`List`集合使用，功能强大。

2. 因为`Array`是基于索引`(index)`的数据结构，它使用索引在数组中搜索和读取数据是很快的，可以直接返回数组中`index`位置的元素，因此在随机访问集合元素上有较好的性能。`Array`获取数据的时间复杂度是`O(1)`,但是要插入、删除数据开销很大，因为这需要移动数组中插入位置之后的的所有元素。

3. 相对于`ArrayList`，`LinkedList`的随机访问集合元素时性能较差，因为需要在双向列表中找到`index`的位置，再返回；但在插入，删除操作是更快的。因为`LinkedList`不需要改变数组的大小，也不需要在数组装满的时候要将所有的数据重新装入一个新的数组，这是`ArrayList`最坏的一种情况，时间复杂度是`O(n)`，而`LinkedList`中插入或删除的时间复杂度仅为`O(1)`。`ArrayList`在插入数据时还需要更新索引（除了插入数组的尾部）。

4. `LinkedList`需要更多的内存，因为`ArrayList`的每个索引的位置是实际的数据，而`LinkedList`中的每个节点中存储的是实际的数据和前后节点的位置。

**使用场景：**

1. 如果<font color='Apricot'>**随机访问较多**</font>，`ArrayList`对象要优于`LinkedList`对象；
2. 如果<font color='Apricot'>**集合的首位有大量的插入、删除、获取操作，随机访问较少**</font>，`LinkedList`对象要优于`ArrayList`对象；

## HashMap、Hashtable区别

**共同点：**

- 都是基于哈希表实现的，其内部每个元素都是 `key-value` 键值对
- 都实现了` Map、Cloneable、Serializable `接口。

**区别：**

- **线程安全性：**
  
  - `HashMap `不是线程安全的，如果多个外部操作同时修改 `HashMap `的数据结构比如 `add `或者是 `delete`，必须进行同步操作，仅仅对 `key `或者 `value `的修改不是改变数据结构的操作。而 `HashTable `本身就是线程安全的容器。
  
  - 需要线程安全时，可以选择 `Collections.synchronizedMap` 或者是 `ConcurrentHashMap`。[ConcurrentHashMap基于JDK1.8源码剖析](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484161&idx=1&sn=6f52fb1f714f3ffd2f96a5ee4ebab146&chksm=ebd74200dca0cb16288db11f566cb53cafc580e08fe1c570e0200058e78676f527c014ffef41#rd)
  
- **是否允许为`null`：**
  - `HashMap`允许`key `和 `value`为`null`，`HashMap `会把 `Null key` 当做普通的 `key `对待。不允许 `null key` 重复。
  - `Hashtable`不允许`key `和 `value`为`null`
  
- **contains方法**
  - `Hashtable`有`contains`方法
  - `HashMap`把`Hashtable`的`contains`方法去掉了，改成了`containsValue`和`containsKey`
  
- **父类不同：**

  - `HashMap `继承了 `AbstractMap` 类，而 `HashTable `继承了 `Dictionary` 类

    ```java
    HashMap<K,V> extends AbstractMap<K,V>
    public class Hashtable<K,V> extends Dictionary<K,V>
    ```

- **性能方面：**
  - 虽然 `HashMap `和 `HashTable `都是基于`单链表`的，但是 `HashMap `进行 `put `或者 `get`操作，可以达到常数时间的性能；
  -  `HashTable `的 `put `和 `get `操作都是加了 `synchronized` 锁的，所以效率很差。

- **初始容量不同：**
  - `HashTable `的初始长度是`11`，之后每次扩充容量变为之前的 `2n+1`（`n`为上一次的长度）
  - `HashMap `的初始长度为`16`，之后每次扩充变为原来的两倍。
  - 创建时，如果给定了容量初始值，那么`HashTable `会直接使用你给定的大小，而 `HashMap `会将其扩充为`2`的幂次方大小。



## List、Map区别

**共同点：**

- 都是`Java`常用的容器，都是接口

**不同点：**

- **存储结构不同**：
  - `List`是存储单列的集合
  - `Map`存储的是key-value键值对的集合
- **元素是否可重复**：
  - `List`允许元素重复
  - `Map`不允许`key`重复
- **是否有序**：
  - `List`集合是<span style="background:yellow;">有序</span>的(存储有序)
  - `Map`集合是<span style="background:yellow;">无序</span>的(存储无序)



## Collection、Collections区别

1. `Collection`是集合的上级**接口**，继承它的有`Set`和`List`接口
2. `Collections`是集合的**工具类**，提供了一系列的静态方法对集合的搜索、查找、同步等操作



## Enumeration和Iterator接口的区别

`Iterator`替代了`Enumeration`，`Enumeration`是一个旧的迭代器了。

与`Enumeration`相比，`Iterator`更加安全，**因为当一个集合正在被遍历的时候，它会阻止其它线程去修改集合**。

**区别有三点：**

- `Iterator`的方法名比`Enumeration`更科学
- `Iterator`有`fail-fast机制`，比`Enumeration`更安全
- `Iterator`能够删除元素，`Enumeration`并不能删除元素

## 并发集合类是什么？

`Java1.5`并发包（`java.util.concurrent`）**包含线程安全集合类，允许在迭代时修改集合**。

- `Utils`包下的集合迭代器被设计为`fail-fast`的，会抛出`ConcurrentModificationException`。但`java.util.concurrent`的并不会
- 一部分类为：
  - `CopyOnWriteArrayList`
  - `ConcurrentHashMap`
  - `CopyOnWriteArraySet`