# 1. `SQL`慢查询（优化）

### `explain`查看执行计划

其中最重要的是`type`（`join`类型）、`rows`、`filtered`、`key`列（最终使用的索引）和`extra`列（额外的信息）。

- **type**

  > - ALL：全表扫描
  > - index：索引物理文件全扫描，速度非常慢
  > - range：索引范围扫描，常用语<,<=,>=,between,in等操作
  > - ref：使用非唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中
  > - eq_ref：类似ref，区别在于使用的是唯一索引，使用主键的关联查询
  > - const/system：单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。，系统会把匹配行中的其他列作为常数处理，如主键或唯一索引查询
  > - null：MySQL不访问任何表或索引，直接返回结果
  >
  > 虽然上至下，效率越来越高，但是根据cost模型，假设有两个索引`idx1(a, b, c)`,`idx2(a, c)`，SQL为`select * from t where a = 1 and b in (1, 2) order by c;`如果走idx1，那么是type为range，如果走idx2，那么type是ref；当需要扫描的行数，使用idx2大约是idx1的5倍以上时，会用idx1，否则会用idx2
  >
  > 
  >
  > SQL性能优化的目标：**至少要达到 range 级别**，要求是ref级别，如果可以是 const 最好。 

- **rows**

  > 如果查询优化器决定使用**全表扫描**的方式对某个表执行查询时，执行计划的`rows`列就代表预计需要扫描的**行数**，如果使用**索引**来执行查询时，执行计划的`rows`列就代表预计扫描的**索引记录行数**

- **filtered**

  >如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要估计出满足搜索条件的记录到底有多少条。
  >
  >如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。

- **extra**

  <font color='Chestnut Red'>**Extra中出现`Using filesort`、`Using temporary`代表MySQL根本不能使用索引，效率会受到严重影响，应当尽可能的去优化。**</font>

  > - **Using index**：使用了覆盖索引
  >
  >   使用了覆盖索引，直接从索引中就能获取到结果。查询列表和查询条件只包含了某个索引中的列，直接通过索引就能获取到结果，不需要进行回表。如果同时出现 using where，意味着无法直接通过索引查找来查询到符合条件的数据。
  >
  > - **Using index condition**：
  >
  >   MySQL5.6之后新增的ICP，using index condtion就是使用了ICP（索引下推），在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据。
  >
  > - **Using where**：使用了where子句来过滤结果集
  >
  >   在查找使用索引的情况下，索引并不能覆盖到需要查询的所有列，需要回表去查询所需的数据。(where条件中除了索引包含的列外，还有索引未包含的列)
  >
  >   当我们使用全表扫描来执行对某个表的查询，并且该语句的WHERE子句中有针对该表的搜索条件时，在Extra列中会提示上述额外信息
  >
  >   当使用索引访问来执行对某个表的查询，并且该语句的WHERE子句中有除了该索引包含的列之外的其他搜索条件时，在Extra列中也会提示上述额外信息。
  >
  > - **Using filesort**：使用文件排序，当查询语句包含ORDER BY时如果无法使用索引来完成排序时出现，非常消耗性能，尽量优化。
  >
  >   MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。
  >
  > - **Using temporary**：
  >
  >   使用临时表来保存中间结果，用于完成排序、去重等操作。比如我们在执行许多包含 DISTINCT 、 GROUP BY 、ORDER BY、 UNION 等子句的查询过程中，如果不能有效利用索引来完成查询， 就需要建立内部的临时表来执行查询。性能特别差，需要重点优化

### 使用`show profile`查询`SQL`执行细节

`Show Profile`是`MySQL`提供的可以用来分析当前会话中`sql`语句执行的资源消耗情况的工具，可用于`sql`调优的测量

```sql
show profile cpu,block io for query Query_ID;
```

需要注意以下几种`status`:

> ①converting HEAP to MyISAM：查询结果太大，内存不够，数据往磁盘上搬了。
>
> ②Creating tmp table：创建临时表。先拷贝数据到临时表，用完后再删除临时表。
>
> ③Copying to tmp table on disk：把内存中临时表复制到磁盘上，危险！！！
>
> ④locked。
> 如果在show profile诊断结果中出现了以上4条结果中的任何一条，则`sql`语句需要优化。

## 慢SQL的原因

### 没有命中索引及索引失效

```markdown
首先分析一下为什么没有命中索引会导致慢查询。
	索引本质就是通过列数据构建成的B+树结构。构建索引的目的是将无序的数据有序化，尽量避免全文扫描，提高检索效率。
	没有命中索引意味着在查询的过程中没有方向，全文检索，效率极差。
	而判断出sql使用了索引，但是仍然慢则需要进行索引优化了。
```
- 造成索引失效的可能原因

```markdown
1、如果条件中有or，即使其中有部分条件带索引也不会使用(这也是为什么尽量少用or的原因)，要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引
2、联合索引不满足最左匹配原则。
3、模糊查询时（like语句），模糊匹配的占位符位于条件的首部
4、存在索引列的数据类型隐形转换，则用不上索引，比如列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引
5、索引列上有数学运算，用不上索引
6、索引列使用函数，用不上索引
7、如果mysql估计使用全表扫描要比使用索引快,则不使用索引（比如数据量少的表）
8、避免在 where 子句中使用 != 或 <> 操作符
```
总结下来，索引会失效大部分原因都是**由于破坏了索引本身的连续性所导致的**。对于单索引而言，采用like以%开头，无法找到索引字段前缀元素，因此无法使用到索引，而对于联合索引而言，or / where 中带有运算&函数等，均是破坏了联合索引字段中的连续性，导致后续索引找不到。

- 索引优化场景

  - 对于单索引且索引字段内容很长时的优化

  > **1、构建前缀索引（使用短索引）**：
  > 默认索引是选择字符列的全部，那可以只选择索引开始的部分字符，例如，如果有一个CHAR(255)的 列，如果在前10 个或20 个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。这样就减少了索引的空间，从而提高索引效率。**如何选择前缀长度**， 这里涉及到索引选择性的问题。在选择前缀长度时要考虑选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）,最后还要考虑数据分布。一般，选择索引长度的方式，先计算出完整列的选择性，再选择出合适的前缀长度。
  >
  > **2、加入伪hash字段**
  > 新建一列用于存储该字符列的hash值（哈希函数不要使用SHA1(),MD5(),因为会产生很长的字符串，浪费空间，比较也慢，最好是返回整数的hash函数），在该列建立索引，查询时必须在where子句中包含常量值，以避免hash冲突。

  - 对于联合索引，需要特别注意索引顺序

  > **最左前缀原则**：索引的最左前缀和和B+Tree中的“最左前缀原理”有关，举例来说就是如果设置了组合索引<col1,col2,col3>那么以下3中情况可以使用索引：col1，<col1,col2>，<col1,col2,col3>，其它的列，比如<col2,col3>，<col1,col3>，col2，col3等等都是不能使用索引的。
  > 根据最左前缀原则，我们一般把排序分组频率最高的列放在最左边，以此类推。

  - 带索引的模糊查询优化

  > 使用LIKE进行模糊查询的时候，’%aaa%'不会使用索引，也就是索引会失效。如果是这种情况，只能使用全文索引来进行优化。
  > 解决方案：
  > **覆盖索引**，所谓覆盖索引，简单理解，就是每次select出来的字段仅从索引列就可以找到，不需要回表查询。比如select (主键ID)。
  > **改造写法（翻转）**
  > 将前模糊进行反转，转化成走后模糊的语句（注意逻辑变化）。


### 超大分页的处理方法

> 一般的查询分页通常使用的是limit，但是limit的实现原理是，假设给定了limit 1000，10，即从第1000条后取出之后的10条数据，那么该条语句将会从表中查询 offset:1000开始之后的10条数据，也就是第1001条到第1010条数据（ 1001<=id<=1010）。这种方式本质上还是会从数据库第一条记录开始扫描，所以越往后，查询速度越慢，而且查询的数据越多，也会拖慢总查询速度。
> **解决方案：子查询优化**
> 这种方式先定位偏移位置的 id，然后往后查询，这种方式适用于 id 递增的情况。

### 单表数据量过大

> - 分页查询(在索引上完成排序分页操作、借助主键进行关联)
> - 单表数据过大，进行分库分表
> - 考虑使用非关系型数据库提高查询效率
> - 全文索引场景较多，考虑使用 ElasticSearch、solr

## 加了索引依旧慢

<font color='Magenta'>索引优化的过程，实质上是减少扫描行数的过程</font>

慢查询归纳起来大概有这么几种情况：

- 全表扫描
- 全索引扫描
- 索引过滤性不好
- 频繁回表的开销

首先SQL判断一个语句是不是慢查询语句，用的是语句的执行时间。他把语句执行时间跟long_query_time这个系统参数作比较，如果语句执行时间比它还大，就会把这个语句记录到慢查询日志里面

<font color='RedOrange'>是否使用索引和是否进入慢查询之间并没有必然的联系。使用索引只是表示了一个SQL语句的执行过程，而是否进入到慢查询是由它的执行时间决定的，而这个执行时间，可能会受各种外部因素的影响。换句话来说，使用了索引你的语句可能依然会很慢。</font>

`InnoDB`是索引组织表，所有的数据都是存储在索引树上面的。`InnoDB`里面只有一种情况叫做没有使用索引，那就是从主键索引的最左边的叶节点开始，向右扫描整个索引树。

- 可以用全表扫描来表示一个查询遍历了整个主键索引树；
- 也可以用全索引扫描，来说明他扫描了整个普通索引树；

我们平时说的使用了索引。他表示的意思是，我们使用了索引的快速搜索功能，并且有效的减少了扫描行数。<font color='RedOrange'>对于一个大表，在设计表结构的时候，不止要有索引，索引的过滤性还要足够好。</font>

减少频繁回表的开销

// TODO 补充索引执行器执行流程 面试加分项

## 执行流程

MySQL一共六个组件

- <font color='RedOrange'>连接器</font>：连接mysql服务器，进行权限验证
- <font color='RedOrange'>缓存</font>：保存上次查询的结果，提高性能
- <font color='RedOrange'>分析器</font>：词法与语法分析
- <font color='RedOrange'>优化器</font>：对你的查询语句做出适当的优化
- <font color='RedOrange'>执行器</font>：操作存储引擎，读写数据
- <font color='RedOrange'>存储引擎</font>：存储数据

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502230440.png" alt="image-20220502230341754" style="zoom: 50%;" />

MySQL执行一个查询操作的完整流程为：<font color='Peach'>客户端通过连接器建立连接，这个操作进行权限验证，通过之后会先前往缓存，根据 SQL 作为 key 去查询，查到直接返回，否则前往分析器，经过分析器对 SQL 语句的分析、解析，得到一个MySQL可以理解的语法，随后进入优化器，MySQL会根据查询的条件进行适当的优化，之后在经过执行器，这就真正的开始前往存储引擎查询数据，最后将查询到的数据返回给客户端，顺便写入缓存（不一定）。</font>

MySQL基本分为两大组件，一个是Server层、一个是存储引擎，存储引擎是可以随场景变化的

### 连接器

位于Server层中，主要用于连接和权限验证，校验通过之后MySQL会返回当前登录用户所拥有的权限，用于后续操作。

若客户端一段时间没有使用则会被置为空闲（Sleep）状态，如果客户端长时间没有操作，服务器就会自动将连接断开，**默认时长 8 小时**，可以通过 **wait_timeout** 参数设置。

超过时长，连接被断开之后，客户端发起请求，那么该客户端将会收到一个：`Lost connection to MySQL server during query`，这个时候就只能通过重新建立连接进行操作。

连接分为两种类型，一个为长连接，一个为短连接，建立连接之后，客户端发送持续请求，如果一直在同一个连接中，那么这个就是长连接，如果每个请求一个连接，则是短连接，我们知道连接会有用户信息的校验，权限的验证，比较麻烦，所以推荐使用长连接进行操作，但是长连接过多会导致MySQL占用的内存过多，导致内存紧张，极端情况可能导致内存泄漏（OOM），所以需要定时清除长连接。通过执行 `mysql_reset_connection` 来重新初始化连接资源，不过要求MySQL版本在5.7或之上。

### 缓存

连接完成之后，下一步就会进入缓存，MySQL会在缓存中检测之前是否执行过这条语句，如果被执行过，那么查询的结果将会以`key-value`的形式存储在缓存中，这个时候下一次的查询直接命中缓存，直接返回相对应的数据，如果缓存中不存在当前`key`（SQL语句），就会进入下一个阶段 -- 分析器。

MySQL判断缓存是否命中的方式很简单，MySQL将缓存存放在一个引用表中，通过`hash`值方式应用，`hash`值包括：查询的SQL、查询的数据库、客户端协议版本等等，MySQL在判断是否命中缓存的时候不会提前解析SQL的语法，而是直接使用SQL语句和客户端的基本信息（协议）等等，进行`hash`算法，这里需要特别注意：**在编写SQL的时候，需要与上一次执行的SQL保持完全一致，空格、注释、编码或者有其他的任何不同的地方都会导致hash出来的结果不同，从而无法命中缓存**，所以在操作时需要保持一个统一的编码规范。

除了这个还有很多情况也会导致查询的数据无法缓存，比如聚合函数、自定义函数、存储过、用户变量、临时表、MySQL库中的系统表、权限表。

MySQL的缓存虽然能提升查询的性能，但是也会在其他方面造成额外的消耗，具体如下：

> 查询之前必须先检查是否命中缓存，对于缓存中没有的SQL多了一次缓存的查询。第一次查询或者表中的数据被修改时，当前查询需要将结果写入到缓存中，带来了额外的系统消耗。MySQL在写操作时会将关于当前相关缓存的数据全部清空，如果缓存的数据过大，或者缓存的SQL语句过多，可能会导致很大的系统消耗。

所以，缓存的好处可以提升查询的效率，弊端可能给系统带来额外的系统消耗，尤其是在`InnoDB`中的事务中，所以在使用的时候需要慎重，不可为了查询效率二盲目的使用缓存，使用不当，可能适得其反。

那MySQL开启缓存只需要将参数 **query_cache_type 设置成 DEMAND** 即可，这样会导致整个MySQL都是使用缓存，这是不被推荐的，所以还有一种方式，那就是按需指定，就是在你需要缓存的SQL语句加上 **SQL_CACHE** 指定使用缓存即可，代码如下：

```SQL
select SQL_CACHE * from sys_user where id = 1;
```

在这里有两点需要特别注意，一：MySQL在8.0版本直接将缓存模块删除，也就是说，MySQL8.0所有的查询都不会走向缓存了，而是直接前往磁盘；二：查询缓存的返回直接也会校验权限信息的，如果没有权限，就算使用了缓存，也无法查询。

### 分析(解析)器

MySQL在缓存中没有命中之后将会进入流程的下一步，但这里并不会直接进入解析器，而是需要先将查询的SQL转换成一个执行计划，在经过这个执行计划和存储引擎进行交互，这里就包括了**：解析器、预处理、优化器、执行器**。

生成完执行计划之后，MySQL会对SQL的关键字进行解析，生成一棵对应的 “**解析树**”，在这个解析过程中，MySQL解析器会使用语法规则对SQL进行解析和校验，第一步做的是词法分析，MySQL执行的并不是你写的SQL语句，而是将你写的SQL语句解析成MySQL可以执行的语句。

生成“解析树“之前还需要校验你的SQL语句写的是否有问题，是否满足MySQL的语法，如果你输入的SQL语句存在问题，这个时候程序将会抛出异常，结束查询。

先解析SQL语法，然后再预处理的时候再校验表名、字段名等是否合法。下一步预处理还会验证权限，这里的验证一般情况下都比较快，除非权限配置相当复杂。

### 优化器

分析器完成之后，语法树已经是合法的了，这个时候优化器就登场了，优化器将这条语法树**转化成执行计划**。MySQL官方也是很为我们开发人员着想，设置了这个优化器，在开发过程中，我们想要查询一条SQL语句，执行的方式有很多，比如是否走索引、走哪条索引、关联查询哪张表做主表等等，这些都是可变的，而优化器的作用就是根据程序员写的SQL语句找到一条它认为最好的执行计划。

并非经过优化器优化的SQL就是最优的执行计划，会导致优化器生成的执行计划效果更差的有以下七点：

1. 统计信息不完整或者不准确，比如 `InnoDB `的`MVCC`多版本并发控制会导致表数据行的统计不准确。
2. 执行计划中的成本并不等同于实际执行的成本，这个时候即使统计的信息很准确，优化器给出的执行计划也有可能不是最优的。举个例子，有些时候某个执行计划虽然需要读取更多的页面或者数据，但是它的实际成本可能会很小，为什么呢？原因很简单，如果读取的页面都是有序的或者这些页面(数据)已经被加载到内存中了，这个时候的访问成本比执行计划估计的成本小得多，MySQL并不知道哪些数据存在内存，哪些数据存在磁盘中，所以IO的次数也是未知数。
3. MySQL的最优可能和你想得不一样，你可能希望执行时间越短越好，但是MySQL只是基于成本模型选择最优的执行计划，而有些时候这并不是最快的执行方式。所以这里我们看到的根据执行计划成本来选择执行计划并不是完美的模型。
4. MySQL从不考虑其他并发执行的查询，这可能影响到当前查询的速度。
5. MySQL并不是完全基于成本优化，有时候也会给予一些固定的规则，例如存在全文索引的`match()`子句，则在存在全文索引的时候就是用全文索引，即使有时候使用别的索引和`where`条件可以远比全文索引的方式要快很多，但是MySQL也会选择使用全文索引。
6. MySQL不会考虑不受其控制的操作成本，例如存储过程或者用户自定义函数的成本。
7. 优化器有时候无法估算所有可能的执行计划，所以它可能错过实际上最优的执行计划。

MySQL的优化器是一个非常复杂的组件，算法很多优化的策略也有很多，它会通过自己的优化策略选择出优化器认为最优的一个执行计划，优化策略大致可以分为两种：**静态优化、动态优化**。

**静态优化**：可以直接对解析树进行分析、优化。优化器可以通过代数变换将`where`条件转换为另外一种等价形态，这个转换不依赖条件的具体数值，即使`where`条件中的数值发生改变，静态优化也仍然有效。可以理解为”**编译时优化**“。

**动态优化**：它与查询的上下文相关，影响动态优化的因素有很多，比如索引对应的数量行数、where条件中的值等等，这些都会让优化器在执行SQL的时候重新进行优化。可以理解为”**运行时优化**“。

所以优化器对SQL进行优化的时候是选择静态优化还是动态优化取决于SQL语句，静态优化只需要做一次，而动态优化在每次执行的时候都需要重新评估。

### 执行器

分析器将我们写的SQL语句解析成了语法树、优化器将语法树转成了它认为最优的一条执行计划，这个时候就需要真正的去读数据了，执行器就是那个执行者，前面的工作都是准备，分析器、优化器让MySQL知道了你要干什么、通过什么方式最简单有效，执行器就是拿着这些准备好的方案实施。

执行器在执行SQL之前还需要做一件事情：**权限验证**，执行器根据库名、表名、操作类型等等查看当前用户是否具备权限操作，如果发现当前用户并不具备此权限，那么直接终端执行，直接结束。

权限验证通过之后，执行器就会打开进入存储引擎，打开数据表进行数据读取，执行器也是通过存储引擎提供的API进行的操作。MySQL会重复执行计划中的每个操作，直到执行器查询完所有的数据为止，执行器没有分析器、优化器那么的复杂，它的主要功能就是执行。

### 存储引擎

MySQL中的数据用各种不同的技术存储在文件（或者内存）中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。

我们常用的存储引擎一般有一下几种：

> MyISAM：拥有较高的插入，查询速度，但不支持事务
> InnoDB：支持事务的存储引擎，mysql5.5以后将它设置为默认存储引擎。
> BDB：事务型数据库的另一种选择，支持COMMIT和ROLLBACK等其他事务特性
> Memory：基于内存的存储引擎，将所有的数据都置于内存中，查询、插入、删除效率极高，是一种空间换时间的思想，不过服务重启会导致数据丢失。
> Merge：将一部分的MyISAM表联合成的一个整体，适用于大数据存储。

存储引擎五花八门，所以MySQL将它设置成了插拔式结构，提高了MySQL的整体灵活性。

// TODO列举回表的情况 面试会经常问到

未发生索引覆盖，查询时查询条件不是主键

# 2. `Redis`高并发

```markdown
1. Redis是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在IO上，所以读取速度快
	
2. Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。
	Redis 单线程主要指的是网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求的时候包括获取(Socket)，解析，执行，内容返回(Socket写)等由一个顺序串行的主线程处理，这即为单线程 但Redis的其它功能，比如持久化，异步删除，集群数据同步等等，都是由额外的线程执行的，是多线程 
	
	即Redis工作线程是单线程的，但是，整个Redis来说是多线程的

3. Redis使用多路复用技术，可以处理并发的连接。非阻塞 IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。

4. Redis使用的是非阻塞IO，IO多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。

5. Redis全程使用hash结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。

6. Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。
```



#  3. `Redis`高可用

在 `Web` 服务器中，**高可用** 是指服务器可以 **正常访问** 的时间，衡量的标准是在 **多长时间** 内可以提供正常服务（`99.9%`、`99.99%`、`99.999%` 等等）。在 `Redis` 层面，**高可用** 的含义要宽泛一些，除了保证提供 **正常服务**（如 **主从分离**、**快速容灾技术** 等），还需要考虑 **数据容量扩展**、**数据安全** 等等。

在 `Redis` 中，实现 **高可用** 的技术主要包括 **持久化**、**复制**、**哨兵** 和 **集群**

- **持久化**：持久化是 **最简单的** 高可用方法。它的主要作用是 **数据备份**，即将数据存储在 **硬盘**，保证数据不会因进程退出而丢失。
- **复制**：复制是高可用 `Redis` 的基础，**哨兵** 和 **集群** 都是在 **复制基础** 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。
- **哨兵**：在复制的基础上，哨兵实现了 **自动化** 的 **故障恢复**。缺陷是 **写操作** 无法 **负载均衡**，**存储能力** 受到 **单机** 的限制。
- **集群**：通过集群，`Redis` 解决了 **写操作** 无法 **负载均衡** 以及 **存储能力** 受到 **单机限制** 的问题，实现了较为 **完善** 的 **高可用方案**。

## 持久化

~~~markdown
持久化功能是 Redis 和 Memcached 的主要区别之一，因为只有 Redis 提供了此功能。

在 Redis 4.0 之前数据持久化方式有两种：AOF 方式和 RDB 方式。

	RDB（Redis DataBase，快照方式）是将某一个时刻的内存数据，以二进制的方式写入磁盘。AOF（Append Only File，文件追加方式）是指将所有的操作命令，以文本的形式追加到文件中。
	RDB 默认的保存文件为 dump.rdb，优点是以二进制存储的，因此占用的空间更小、数据存储更紧凑，并且与 AOF 相比，RDB 具备更快的重启恢复能力。

	AOF 默认的保存文件为 appendonly.aof，它的优点是存储频率更高，因此丢失数据的风险就越低，并且 AOF 并不是以二进制存储的，所以它的存储信息更易懂。缺点是占用空间大，重启之后的数据恢复速度比较慢。

可以看出 RDB 和 AOF 各有利弊，RDB 具备更快速的数据重启恢复能力，并且占用更小的磁盘空间，但有数据丢失的风险；而 AOF 文件的可读性更高，但却占用了更大的空间，且重启之后的恢复速度更慢，于是在 Redis 4.0 就推出了混合持久化的功能。

- 混合持久化的功能指的是 Redis 可以使用 RDB + AOF 两种格式来进行数据持久化，这样就可以做到扬长避短物尽其用了。 可以使用config get aof-use-rdb-preamble的命令来查询 Redis 混合持久化的功能是否开启
	Redis 混合持久化的存储模式是，开始的数据以 RDB 的格式进行存储，因此只会占用少量的空间，并且之后的命令会以 AOF 的方式进行数据追加，这样就可以减低数据丢失的风险，同时可以提高数据恢复的速度。
~~~

## 主从同步

~~~markdown
主从同步是 Redis 多机运行中最基础的功能，它是把多个 Redis 节点组成一个 Redis 集群，在这个集群当中有一个主节点用来进行数据的操作，其他从节点用于同步主节点的内容，并且提供给客户端进行数据查询。

Redis 主从同步分为：主从模式和从从模式。
	主从模式就是一个主节点和多个一级从节点,而从从模式是指一级从节点下面还可以拥有更多的从节点。 主从模式可以提高 Redis 的整体运行速度，因为使用主从模式就可以实现数据的读写分离，把写操作的请求分发到主节点上，把其他的读操作请	  求分发到从节点上，这样就减轻了 Redis 主节点的运行压力，并且提高了 Redis 的整体运行速度。
~~~

- `Redis` **主从复制** 可将 **主节点** 数据同步给 **从节点**，从节点此时有两个作用：
1. 一旦 **主节点宕机**，**从节点** 作为 **主节点** 的 **备份** 可以随时顶上来。
  
2. 扩展 **主节点** 的 **读能力**，分担主节点读压力。

### 实现方式

~~~Markdown
1. Redis 2.8 以前使用 SYNC 命令同步复制。
Redis的同步功能分为同步(sync)和命令传播(command propagate)。
1）同步操作：
	1. 通过从服务器发送到SYNC命令给主服务器；
	2. 主服务器生成RDB文件并发送给从服务器，同时发送保存所有写命令给从服务器；
	3. 从服务器清空之前数据并执行解释RDB文件；
	4. 保持数据一致（还需要命令传播过程才能保持一致）。
2）命令传播操作：
同步操作完成后，主服务器执行写命令，该命令发送给从服务器并执行，使主从保存一致。

缺陷：没有全量同步和增量同步的概念，从服务器在同步时，会清空所有数据。主从服务器断线后重复制，主服务器会重新生成RDB文件和重新记录缓冲区的所有命令，并全量同步到从服务器上。

2. 在Redis 2.8之后使用PSYNC命令，具备完整重同步和部分重同步模式。
	1. Redis 的主从同步，分为全量同步和增量同步；
	2. 只有从机第一次连接上主机是全量同步；
	3. 断线重连有可能触发全量同步也有可能是增量同步（ master 判断runid 是否一致）；
	4. 除此之外的情况都是增量同步；

3. 全量同步
Redis 的全量同步过程主要分三个阶段：
	1. 同步快照阶段： Master 创建并发送快照RDB给Slave ， Slave 载入并解析快照。Master 同时将此阶段所产生的新的写命令存储到缓冲区。
	2. 同步写缓冲阶段： Master 向Slave 同步存储在缓冲区的写操作命令；
	3. 同步增量阶段： Master 向Slave 同步写操作命令。

4. 增量同步
	1、Redis增量同步主要指Slave完成初始化后开始正常工作时， Master 发生的写操作同步到Slave 的过程；
	2、通常情况下， Master 每执行一个写命令就会向Slave 发送相同的写命令，然后Slave 接收并执行；

5. 命令传播
当同步数据完成后，主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令。

6. 心跳检测
在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送命令。
	作用：
	1. 检测主从的连接状态。检测主从服务器的网络连接状态通过向主服务器发送INFO replication命令，可以列出从服务器列表，可以看出从最后一次向主发送命令距离现在过了多少秒。lag的值应该在0或1之间跳动，如果超过1则说明主从之间的连接有故障。
	2. 辅助实现min-slaves：
		Redis可以通过配置防止主服务器在不安全的情况下执行写命令；
		min-slaves-to-write 3 （min-replicas-to-write 3 ）；
		min-slaves-max-lag 10 （min-replicas-max-lag 10）；
	上面的配置表示：从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令。这里的延迟值就是上面INFOreplication命令的lag值。
	3. 检测命令丢失
		如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发送REPLCONF ACK命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量，然后主服务器就会根据从服务器提交的复制偏移	量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。
~~~



- **主从复制** 同时存在以下几个问题：

  1. 一旦 **主节点宕机**，**从节点** 晋升成 **主节点**，同时需要修改 **应用方** 的 **主节点地址**，还需要命令所有 **从节点** 去 **复制** 新的主节点，整个过程需要 **人工干预**。

  2. **主节点** 的 **写能力** 受到 **单机的限制**。
  3. **主节点** 的 **存储能力** 受到 **单机的限制**。
  4. **原生复制** 的弊端在早期的版本中也会比较突出，比如：`Redis` **复制中断** 后，**从节点** 会发起 `psync`。此时如果 **同步不成功**，则会进行 **全量同步**，**主库** 执行 **全量备份** 的同时，可能会造成毫秒或秒级的 **卡顿**。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421180241.png" alt="image-20220421180239093" style="zoom:50%;" />

## 哨兵模式

在主从模式下，`redis`同时提供了哨兵命令`redis-sentinel`，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵进程向所有的`redis`机器发送命令，等待`Redis`服务器响应，从而监控运行的多个`Redis`实例。

哨兵可以有多个，一般为了便于决策选举，使用奇数个哨兵。哨兵可以和`redis`机器部署在一起，也可以部署在其他的机器上。多个哨兵构成一个哨兵集群，哨兵之间也会相互通信，检查哨兵是否正常运行，同时发现`master`宕机哨兵之间会进行决策选举新的`master`

### 哨兵模式的作用:

- 通过发送命令，让`Redis`服务器返回监控其运行状态，包括主服务器和从服务器;
- 当哨兵监测到`master`宕机，会自动将`slave`切换到`master`，然后通过 *发布订阅模式*  通过其他的从服务器，修改配置文件，让它们切换主机;
- 然而一个哨兵进程对`Redis`服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

哨兵很像`kafka`集群中的`zookeeper`的功能。

### 哨兵模式的工作

每个 `Sentinel` 节点都需要 **定期执行** 以下任务：

1. 每个 `Sentinel` 以 **每秒钟** 一次的频率，向它所知的 **主服务器**、**从服务器** 以及其他 `Sentinel` **实例** 发送一个 `PING` 命令。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421201207.awebp" alt="img" style="zoom:50%;" />



2. 如果一个 **实例**（`instance`）距离 **最后一次** 有效回复 `PING` 命令的时间超过 `down-after-milliseconds` 所指定的值，那么这个实例会被 `Sentinel` 标记为 **主观下线**。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421201201.awebp" alt="img" style="zoom:50%;" />

3. 如果一个 **主服务器** 被标记为 **主观下线**，那么正在 **监视** 这个 **主服务器** 的所有 `Sentinel` 节点，要以 **每秒一次** 的频率确认 **主服务器** 的确进入了 **主观下线** 状态。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162727.awebp" alt="img" style="zoom: 50%;" />



4. 如果一个 **主服务器** 被标记为 **主观下线**，并且有 **足够数量** 的 `Sentinel`（至少要达到 **配置文件** 指定的数量）在指定的 **时间范围** 内同意这一判断，那么这个 **主服务器** 被标记为 **客观下线**。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162728.awebp" alt="img" style="zoom:50%;" />

5. 在一般情况下， 每个 `Sentinel` 会以每 `10` 秒一次的频率，向它已知的所有 **主服务器** 和 **从服务器** 发送 `INFO` 命令。当一个 **主服务器** 被 `Sentinel` 标记为 **客观下线** 时，`Sentinel` 向 **下线主服务器** 的所有 **从服务器** 发送 `INFO` 命令的频率，会从 `10` 秒一次改为 **每秒一次**。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162732.awebp" alt="img" style="zoom:50%;" />



6. `Sentinel` 和其他 `Sentinel` 协商 **主节点** 的状态，如果 **主节点** 处于 `SDOWN` 状态，则投票自动选出新的 **主节点**。将剩余的 **从节点** 指向 **新的主节点** 进行 **数据复制**。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421201134.awebp" alt="img" style="zoom:50%;" />

7. 当没有足够数量的 `Sentinel` 同意 **主服务器** 下线时， **主服务器** 的 **客观下线状态** 就会被移除。当 **主服务器** 重新向 `Sentinel` 的 `PING` 命令返回 **有效回复** 时，**主服务器** 的 **主观下线状态** 就会被移除。



<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421201140.awebp" alt="img" style="zoom:50%;" />

> 注意：一个有效的 `PING` 回复可以是：`+PONG`、`-LOADING` 或者 `-MASTERDOWN`。如果 **服务器** 返回除以上三种回复之外的其他回复，又或者在 **指定时间** 内没有回复 `PING` 命令， 那么 `Sentinel` 认为服务器返回的回复 **无效**（`non-valid`）。

- 每个`Sentinel`（哨兵）进程以每秒钟一次的频率向整个集群中的`Master`主服务器，`Slave`从服务器以及其他`Sentinel`（哨兵）进程发送一个 `PING `命令。
- 如果一个实例（instance）距离最后一次有效回复 `PING `命令的时间超过 `down-after-milliseconds` 选项所指定的值， 则这个实例会被 `Sentinel`（哨兵）进程标记为主观下线（SDOWN）
- 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个`Master`主服务器的所有 `Sentinel`（哨兵）进程要以每秒一次的频率确认`Master`主服务器的确进入了主观下线状态
- 当有足够数量的 `Sentinel`（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认`Master`主服务器进入了主观下线状态（SDOWN）， 则`Master`主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 `Sentinel`（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、`Slave`从服务器发送 `INFO `命令。
- 当Master主服务器被 `Sentinel`（哨兵）进程标记为客观下线（ODOWN）时，`Sentinel`（哨兵）进程向下线的 `Master`主服务器的所有 `Slave`从服务器发送 `INFO `命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 `Sentinel`（哨兵）进程同意 `Master`主服务器下线， `Master`主服务器的客观下线状态就会被移除。若 `Master`主服务器重新向 `Sentinel`（哨兵）进程发送 `PING `命令返回有效回复，`Master`主服务器的主观下线状态就会被移除。

~~~markdown
假设`master`宕机，`sentinel 1`先检测到这个结果，系统并不会马上进行 `failover`(故障转移)选出新的`master`，仅仅是`sentinel 1`主观的认为`master`不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由`sentinel 1`发起，进行 `failover `操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。
~~~

### 哨兵模式的优缺点

#### 优点

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
- 主从可以自动切换，系统更健壮，可用性更高。

#### 缺点

- 具有主从模式的缺点，每台机器上的数据是一样的，内存的可用性较低。
- `Redis`较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

## 集群与分区

> **分区的概念**：分区是将数据分布在多个Redis实例（Redis主机）上，以至于每个实例只包含一部分数据。
>
> **分区的意义**：
> 1、**性能的提升**：单机Redis的网络I/O能力和计算资源是有限的，将请求分散到多台机器，充分利用多台机器的计算能力可网络带宽，有助于提高Redis总体的服务能力；
> 2、**存储能力的横向扩展**：随着存储数据的增加，单台机器受限于机器本身的存储容量，将数据分散到多台机器上存储使得Redis服务可以横向扩展。

### client端分区

>  对于一个给定的key，客户端直接选择正确的节点来进行读写。许多Redis客户端都实现了客户端分区(JedisPool)，也可以自行编程实现。
>
> **分区算法（hash）**
>
> 1. **普通hash**：hash(key)%N，其中hash可以使用hash算法比如CRC32、CRC16等，N是rerdis的节点数
>      **优点**：实现简单，热点数据分布均匀
>      **缺点**：节点数固定，扩展的话需要重新计算查询时必须用分片的key来查，一旦key改变，数据就查不出了，所以要使用不易改变的key进行分片。
>
> 2. **一致性hash**
>
>    我们把2^32^想象成一个圆，hash（服务器的IP地址） % 2^32^，通过上述公式算出的结果一定是一个0到2^32-1^，之间的一个整数，我们就用算出的这个整数，代表服务器A、服务器B、服务器C，既然这个整数肯定处于0到2^32-1^之间，那么，上图中的hash环上必定有一个点与这个整数对应，也就是服务器A、服务器B、服务C就可以映射到这个环上，当我们对一个key做hash运算之后hash（key） % 2^32^得到的值也必然在这个环上，按照顺时针旋转，如果找到的第一个节点就是数据需要存储的节点。
>
>    **优点**：添加或移除节点时，数据只需要做部分的迁移，比如上图中把C服务器移除，则数据4迁移到服务器A中，而其他的数据保持不变。添加效果是一样的。
>    **缺点**：可能会出现hash环偏移（数据倾斜）。解决方案：增加虚拟节点，实现复杂。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421204357.png" alt="image-20220421204356596" style="zoom:50%;" />

### 官方cluster分区

> Redis3.0之后，Redis官方提供了完整的集群解决方案，方案采用去中心化的方式，包括：sharding（分区）、replication（复制）、failover（故障转移），称为`RedisCluster`。`Redis5.0`可以直接使用`Redis-cli`进行集群的创建和管理
>
> **集群部署**
>
> **Gossip协议**：Gossip协议是一个通信协议，一种传播消息的方式。通过gossip协议，cluster可以提供集群间状态同步更新、选举自助failover等重要的集群功能。
> **Gossip协议基本思想**：一个节点周期性(每秒)随机选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。信息会周期性的传递给N个目标节点。这个N被称为fanout（扇出）

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421204536.png" alt="image-20220421204535595" style="zoom:50%;" />

**Gossip的消息种类**：

| 命令    | 说明                                                         |
| ------- | ------------------------------------------------------------ |
| meet    | sender 向 receiver发出，请求 receiver 加入 sender 的集群     |
| ping    | 节点检测其他节点是否在线                                     |
| pong    | receiver 收到 meet 或 ping 后的回复信息，在 failover 后新的 master 也会广播 pong |
| fail    | 节点 A 判断节点 B 下线后，A 节点广播 B节点的 fail 信息，其他受到节点会将 B 节点标记为下线 |
| publish | 节点 A 收到 publish 命令，节点 A 执行改命令，并向集群广播 publish 命令，收到 publish 命令的节点都会执行相同的 publish 命令 |

> **slot**：redis-cluster把所有的物理节点映射到[0-16383]个slot上，集群中的节点基本上采用平均分配和连续分配的方式。cluster 负责维护节点和slot槽的对应关系
> value------>slot-------->节点
> 当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。slot槽必须在节点上连续分配，如果出现不连续的情况，则RedisCluster不能工作

### RedisCluster的优势

~~~markdown
1、高性能：Redis Cluster 的性能与单节点部署是同级别的。可实现多主节点、负载均衡、读写分离。
2、高可用：Redis Cluster 支持标准的 主从复制配置来保障高可用和高可靠。可以做到故障转移，并且也实现了一个类似 Raft 的共识方式，来保障整个集群的可用性。
3、易扩展：向 Redis Cluster 中添加新节点，或者移除节点，都是透明的，不需要停机。
4、原生态：部署 Redis Cluster 不需要其他的代理或者工具，而且 Redis Cluster 和单机 Redis 几乎完全兼容。

集群配置：在redis.conf中配置cluster-enable yes即可。
创建集群命令：./redis-cli --cluster create ipList --cluster-replicas 1

分片：不同节点分组服务于相互无交集的分片（sharding），Redis Cluster 不存在单独的proxy或配置服务器，所以需要将客户端路由到目标的分片。
客户端路由：Redis Cluster的客户端相比单机Redis 需要具备路由语义的识别能力，且具备一定的路由缓存能力。
~~~

### moved重定向

~~~markdown
1. 每个节点通过通信都会共享Redis Cluster中槽和集群中对应节点的关系；
2. 客户端向Redis Cluster的任意节点发送命令，接收命令的节点会根据CRC16规则进行hash运算与16384取余，计算自己的槽和对应节点；
3. 如果保存数据的槽被分配给当前节点，则去槽中执行命令，并把命令执行结果返回给客户端；
4. 如果保存数据的槽不在当前节点的管理范围内，则向客户端返回moved重定向异常；
5. 客户端接收到节点返回的结果，如果是moved异常，则从moved异常中获取目标节点的信息；
6. 客户端向目标节点发送命令，获取命令执行结果。
~~~

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421205828.png" alt="image-20220421205827032" style="zoom: 67%;" />

### ask重定向

~~~markdown
在对集群进行扩容和缩容时，需要对槽及槽中数据进行迁移。当客户端向某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应的槽的节点信息，如果此时正在进行集群扩展或者缩空操作，当客户端向正确的节点发送命令时，槽及槽中数据已经被迁移到别的节点了，就会返回ask，这就是ask重定向机制
1.客户端向目标节点发送命令，目标节点中的槽已经迁移支别的节点上了，此时目标节点会返回ask转向给客户端；
2.客户端向新的节点发送Asking命令给新的节点，然后再次向新节点发送命令；
3.新节点执行命令，把命令执行结果返回给客户端。
~~~

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220421205927.png" alt="image-20220421205926172" style="zoom:67%;" />

~~~
moved和ask的区别：

1、moved：槽已确认转移；
2、ask：槽还在转移过程中。
~~~

### 迁移

~~~markdown
在RedisCluster中每个slot 对应的节点在初始化后就是确定的。已下情况，节点和分片需要变更：
1. master加入；
2. 某个节点分组需要下线；
3. 负载不均衡需要调整slot 分布。

此时需要进行分片的迁移，迁移的触发和过程控制由外部系统完成，主要分为两大部位：
1. 节点迁移状态设置：迁移前标记源/目标节点；
2. key迁移的原子化命令：数据迁移。
~~~

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162730.png" alt="image-20220421210220096" style="zoom:67%;" />

~~~markdown
数据迁移又分为4个步骤：
1. 向节点B发送状态变更命令，将B的对应slot 状态置为importing；
2. 向节点A发送状态变更命令，将A对应的slot 状态置为migrating；
3. 向A 发送migrate 命令，告知A 将要迁移的slot对应的key 迁移到B；
4. 当所有key 迁移完成后，cluster setslot 重新设置槽位。

**扩容步骤：**
1、添加需要加入的redis的master节点；
2、使用--cluster add-node命令将刚添加的redis节点加入到集群中；
3、使用--cluster reshard命令给新加入集群的节点分配hash槽（指定从哪个节点分配多少个槽给新节点）；

**缩容步骤：**
1、先确定需要删除的节点是否还有槽被使用，如果在使用，应先分配出去。
2、使用--cluster del-node命令删除节点；
~~~

### 容灾

> **故障检测**
> 集群中的每个节点都会定期地（每秒）向集群中的其他节点发送PING消息，如果在一定时间内(cluster-node-timeout)，发送ping的节点A没有收到某节点B的pong回应，则A将B标识为pfail。A在后续发送ping时，会带上B的pfail信息， 通知给其他节点。如果B被标记为pfail的个数大于集群主节点个数的一半（N/2 + 1）时，B会被标记为fail，A向整个集群广播，该节点已经下线，其他节点收到广播，标记B为fail。
>
> **从节点选举（自动切换主从）**
>
> 选举使用raft算法，每个从节点都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。slave将currentEpoch 自增并 通过向其他master发送FAILVOER_AUTH_REQUEST 消息发起竞选，master 收到后回复FAILOVER_AUTH_ACK 消息告知是否同意，，如果自己未投过票，则回复同意，否则回复拒绝。
> 所有的Master开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 +1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master。
>
> **RedisCluster失效的判定**：
> 1、集群中半数以上的主节点都宕机（无法投票）；
> 2、宕机的主节点的从节点也宕机了（slot槽分配不连续）。
>
> **变更通知**
>
> 当slave 收到过半的master 同意时，会成为新的master。此时会以最新的Epoch 通过PONG 消息广播自己成为master，让Cluster 的其他节点尽快的更新拓扑结构(node.conf)。
>
> **手动主从切换**
>
> 人工故障切换是预期的操作，而非发生了真正的故障，目的是以一种安全的方式(数据无丢失)将当前master节点和其中一个slave节点(执行cluster-failover的节点)交换角色
>
> 手动主从切换分两种情况：**master还在线
> **1、向从节点发送cluster failover 命令（slaveof no one）；
> 2、从节点告知其主节点要进行手动切换（CLUSTERMSG_TYPE_MFSTART）；
> 3、主节点会阻塞所有客户端命令的执行（10s）；
> 4、从节点从主节点的ping包中获得主节点的复制偏移量；
> 5、从节点复制达到偏移量，发起选举、统计选票、赢得选举、升级为主节点并更新配置；
> 6、切换完成后，原主节点向所有客户端发送moved指令重定向到新的主节点。
>
> **master已经离线**：
> 如果主节点下线了，则采用cluster failover force或cluster failover takeover 进行强制切换。

### 副本漂移

> 在集群中，如果某个master没有slave了，可以自动从集群中的slave多的master，选择其中一台slave作为新master的slave
>
> 在集群中如果有的master的slave多，有的master的slave少（比如只有一台slave），这时候如果只有一台slave的master挂掉了，经过主从切换之后，新的master就没有slave了，这时候是比较不安全的，如果新的master挂了，整个集群就不完整了。这时候可以使用副本漂移；

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162731.png" alt="image-20220421210532048" style="zoom:50%;" />

> 如图：
> 如果master1宕机，则slave11会成为新的master，但是这时候他没有slave则可以使用副本漂移策略：
>
> 1. 将Slaver31的从机记录从Master3中删除；
>
> 2. 将Slaver31的的主机改为Master1；
>
> 3. 在Master1中添加Slaver31为从节点；
>
> 4. 将Slaver31的复制源改为Master1；
>
> 5. 通过ping包将信息同步到集群的其他节点。

### 优缺点

> ### **优点**
>
> 采用去中心化思想，数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布;
>
> 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除;
>
> 高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升;
>
> 降低运维成本，提高系统的扩展性和可用性。
>
> ### **缺点**
>
> 1.Redis Cluster是无中心节点的集群架构，依靠Goss协议(谣言传播)协同自动化修复集群的状态
>
> ​	但 GosSIp有消息延时和消息冗余的问题，在集群节点数量过多的时候，节点之间需要不断进行 PING/PANG通讯，不必须要的流量占用了大量的网络资源。虽然Reds4.0对此进行了优化，但这个问题仍然存在
>
> 2.数据迁移问题
>
> ​	Redis Cluster可以进行节点的动态扩容缩容，这一过程，在目前实现中，还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。
>
> ​	而 Redis为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦Key的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。

## 总结

主从模式：master节点挂掉后，需要手动指定新的master，可用性不高，基本不用。

哨兵模式：master节点挂掉后，哨兵进程会主动选举新的master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。

集群模式：数据量比较大，QPS要求较高的时候使用。 **Redis Cluster是Redis 3.0以后才正式推出，时间较晚，目前能证明在大规模生产环境下成功的案例还不是很多，需要时间检验。**



//TODO 补充redis数据结构 包含跳跃链表+bigmap 加分项

## 数据结构

### 一、String（字符串）

在`Redis`中`String`是可以修改的，称为`动态字符串`(`Simple Dynamic String` 简称 `SDS`)，说是字符串但它的内部结构更像是一个 `ArrayList`，内部维护着一个字节数组，并且在其内部预分配了一定的空间，以减少内存的频繁分配。

`Redis`的内存分配机制是这样：

- 当字符串的长度小于 1MB时，每次扩容都是加倍现有的空间。
- 如果字符串长度超过 1MB时，每次扩容时只会扩展 1MB 的空间。

这样既保证了内存空间够用，还不至于造成内存的浪费，**字符串最大长度为** **`512MB`.**。

`String`的数据结构

```java
struct SDS{
  T capacity;       //数组容量
  T len;            //实际长度
  byte flages;  //标志位,低三位表示类型
  byte[] content;   //数组内容
}
```

`capacity` 和 `len`两个属性都是泛型，为更合理的使用内存，不同长度的字符串采用不同的数据类型表示，且在创建字符串的时候 `len` 会和 `capacity` 一样大，不产生冗余的空间，所以`String`值可以是字符串、数字（整数、浮点数) 或者 二进制。

**应用场景：**存储key-value键值对

### 二、list(列表)

`Redis`中的`list`和`Java`中的`LinkedList`很像，底层都是一种链表结构， `list`的插入和删除操作非常快，时间复杂度为 0(1)，不像数组结构插入、删除操作需要移动数据。

像归像，但是`redis`中的`list`底层可不是一个双向链表那么简单。

当数据量较少的时候它的底层存储结构为一块连续内存，称之为`ziplist(压缩列表)`，它将所有的元素紧挨着一起存储，分配的是一块连续的内存；当数据量较多的时候将会变成`quicklist(快速链表)`结构。

可单纯的链表也是有缺陷的，链表的前后指针 `prev` 和 `next` 会占用较多的内存，会比较浪费空间，而且会加重内存的碎片化。在redis 3.2之后就都改用`ziplist+链表`的混合结构，称之为 `quicklist(快速链表)`。

下面具体介绍下两种链表

#### ziplist(压缩列表)

`ziplist`的数据结构

```java
struct ziplist<T>{
    int32 zlbytes;            //压缩列表占用字节数
    int32 zltail_offset;    //最后一个元素距离起始位置的偏移量,用于快速定位到最后一个节点
    int16 zllength;            //元素个数
    T[] entries;            //元素内容
    int8 zlend;                //结束位 0xFF
}
```

压缩列表为了支持双向遍历，所以才会有 `ztail_offset` 这个字段，用来快速定位到最后一个元素，然后倒着遍历

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162733.jpg" alt="img" style="zoom:67%;" />

`entry`的数据结构：

```js
struct entry{
    int<var> prevlen;            //前一个 entry 的长度
    int<var> encoding;            //元素类型编码
    optional byte[] content;    //元素内容
}
```

`entry`它的 `prevlen` 字段表示前一个 `entry` 的字节长度，当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。

**1、应用场景：**

由于`list`它是一个按照插入顺序排序的列表，所以应用场景相对还较多的，例如：

- 消息队列：`lpop`和`rpush`（或者反过来，`lpush`和`rpop`）能实现队列的功能
- 朋友圈的点赞列表、评论列表、排行榜：`lpush`命令和`lrange`命令能实现最新列表的功能，每次通过`lpush`命令往列表里插入新的元素，然后通过`lrange`命令读取最新的元素列表。

### 三、hash （字典）

`Redis` 中的 `Hash`和 `Java`的 `HashMap` 更加相似，都是 `数组+链表` 的结构，当发生 hash 碰撞时将会把元素追加到链表上，值得注意的是在 `Redis` 的 `Hash` 中 `value` 只能是字符串.

```sql
hset books java "Effective java" (integer) 1
hset books golang "concurrency in go" (integer) 1
hget books java "Effective java"
hset user age 17 (integer) 1
hincrby user age 1    #单个 key 可以进行计数 和 incr 命令基本一致 (integer) 18
```

`Hash` 和`String`都可以用来存储用户信息 ，但不同的是`Hash`可以对用户信息的每个字段单独存储；`String`存的是用户全部信息经过序列化后的字符串，如果想要修改某个用户字段必须将用户信息字符串全部查询出来，解析成相应的用户信息对象，修改完后在序列化成字符串存入。而 hash可以只对某个字段修改，从而节约网络流量，不过hash内存占用要大于 `String`，这是 `hash` 的缺点。

**1、应用场景：**

- 购物车：`hset [key] [field] [value]` 命令， 可以实现以`用户Id`，`商品Id`为`field`，商品数量为`value`，恰好构成了购物车的3个要素。
- 存储对象：`hash`类型的`(key, field, value)`的结构与对象的`(对象id, 属性, 值)`的结构相似，也可以用来存储对象。

### 四、set(集合)

`Redis` 中的 `set`和`Java`中的`HashSet` 有些类似，它内部的键值对是无序的、唯一 的。它的内部实现相当于一个特殊的字典，字典中所有的`value`都是一个值 `NULL`。当集合中最后一个元素被移除之后，数据结构被自动删除，内存被回收。

**1、应用场景：**

- 好友、关注、粉丝、感兴趣的人集合：
  1. `sinter`命令可以获得A和B两个用户的共同好友；
  2. `sismember`命令可以判断A是否是B的好友；
  3. `scard`命令可以获取好友数量；
  4. 关注时，`smove`命令可以将B从A的粉丝集合转移到A的好友集合
- 首页展示随机：美团首页有很多推荐商家，但是并不能全部展示，set类型适合存放所有需要展示的内容，而`srandmember`命令则可以从中随机获取几个。
- 存储某活动中中奖的用户ID ，因为有去重功能，可以保证同一个用户不会中奖两次。

### 五、zset(有序集合)

`zset`也叫`SortedSet`一方面它是个 `set` ，保证了内部 value 的唯一性，另方面它可以给每个 value 赋予一个`score`，代表这个`value`的排序权重。它的内部实现为`zipList`和`dict+skipList`

当`zset`满足以下两个条件的时候，使用`ziplist`：

1. 保存的元素少于128个
2. 保存的所有元素大小都小于64字节

**不满足这两个条件则使用skiplist。**（这两个数值可以通过`redis.conf`的`zset-max-ziplist-entries` 和 `zset-max-ziplist-value`选项 进行修改。）

#### ziplist

- 当`ziplist`作为`zset`的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。其实质是一个双向链表；虽然元素是按 `score` 有序排序的， 但对 `ziplist` 的节点指针只能线性地移动，所以查找给定元素的复杂度是 `O(N)`

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202312212347092.png" alt="img" style="zoom:67%;" />

- `ziplist`内存结构

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202312212349611.png" alt="img" style="zoom: 50%;" />

各个部分在内存上是前后相邻的并连续的，每一部分作用如下：

- `zlbytes`： 存储一个无符号整数，固定四个字节（32bit），用于存储压缩列表所占用的字节（也包括`zlbytes`本身占用的4个字节），当重新分配内存的时候使用，不需要遍历整个列表来计算内存大小。

- `zltail`： 存储一个无符号整数，固定四个字节（32bit），表示`ziplist`表中最后一项（`entry`）在ziplist中的偏移字节数。`zltail`的存在，使得我们可以很方便地找到最后一项（不用遍历整个`ziplist`），从而可以在`ziplist`尾端快速地执行`push`或`pop`操作。

- `zllen`： 压缩列表包含的节点个数，固定两个字节（16bit），表示`ziplist`中数据项（`entry`）的个数。由于`zllen`字段只有`16bit`，所以可以表达的最大值为2^16-1^。

  <font color=VioletRed>**注意**</font>：如果`ziplist`中数据项个数超过了`16bit`能表达的最大值，`ziplist`仍然可以表示。`ziplist`是如何做到的？

  如果`zllen`小于等于2^16-2^（也就是不等于2^16-1^），那么`zllen`就表示`ziplist`中数据项的个数；否则，也就是`zllen`等于`16bit`全为`1`的情况，那么`zllen`就不表示数据项个数了，这时候要想知道`ziplist`中数据项总数，那么必须对`ziplist`从头到尾遍历各个数据项，才能计数出来。

- `entry`，表示真正存放数据的数据项，长度不定。一个数据项（`entry`）也有它自己的内部结构。

- `zlend`， `ziplist`最后1个字节，值固定等于255，其是一个结束标记。

​	<font color=Rhodamine>**优缺点**</font>：当数据小的时候，由一段连续的内存组成,最大的优点就是节省内存，但这种结构不善于修改

#### skiplist

包含`一个dict + 一个skiplist`。字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 `object` 属性保存元素的成员，跳跃表节点的 `score` 属性保存元素的分值。查找单个`key`的时间复杂度为`O(log n)`

这两种数据结构会<font color='each'>通过指针来共享相同元素的成员和分值</font>，所以不会产生重复成员和分值，造成内存的浪费。

>其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以<font color='orange'>每次进行范围操作的时候都要进行排序</font>；假如我们单独使用跳跃表来实现，虽然能执行范围操作，<font color='orange'>但是查找操作由 O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。</font>

字典中的键是唯一的，可以通过`key`来查找值

- 字典底层实现是哈希表，字典有两个哈希表，一个在扩容时使用，哈希表扩容使用渐进式扩容，发送扩容时需要在两个哈希表中进行搜索。
- 发生哈希冲突时使用链地址法解决

<font color='VioletRed'>skiplist与平衡树、哈希表的比较</font>

- <font color='Peach'>有序性</font>：`skiplist`和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个`key`的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
- <font color='Peach'>范围查找</font>：平衡树比`skiplist`操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在`skiplist`上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
- <font color='Peach'>插入和删除</font>：平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而`skiplist`的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- <font color='Peach'>内存占用</font>：`skiplist`比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而`skiplist`每个节点包含的指针数目平均为`1/(1-p)`，具体取决于参数`p`的大小。如果像`Redis`里的实现一样，取`p=1/4`，那么平均每个节点包含`1.33`个指针，比平衡树更有优势。
- <font color='Peach'>查找单个`key`</font>：`skiplist`和平衡树的时间复杂度都为`O(log n)`，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近`O(1)`，性能更高一些。所以我们平常使用的各种`Map`或`dictionary`结构，大都是基于哈希表实现的。
- <font color='Peach'>算法实现难度上</font>：`skiplist`比平衡树要简单得多。

**zset应用场景：**

`zset` 可以用做排行榜，但是和`list`不同的是`zset`它能够实现动态的排序，例如： 可以用来存储粉丝列表，value 值是粉丝的用户 ID，score 是关注时间，我们可以对粉丝列表按关注时间进行排序。

`zset` 还可以用来存储学生的成绩， `value` 值是学生的 ID, `score` 是他的考试成绩。 我们对成绩按分数进行排序就可以得到他的名次。

### 跳跃链表

**有序列表 zset** 它的内部实现就依赖了一种叫做 **「跳跃列表」** 的数据结构。

==为什么用跳跃列表？==

首先，因为 `zset `要支持随机的插入和删除，所以它 **不宜使用数组来实现**，关于排序问题，出于 **性能 **和 **实现** 考虑使用的是跳跃列表而不是 **红黑树/ 平衡树** 这样的树形结构

1. **性能考虑：** 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 *(下面详细说)*；
2. **实现考虑：** 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；

==本质是解决查找问题==

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105147.png" alt="image-20220502105145786" style="zoom:50%;" />

我们需要这个链表按照 score 值进行排序，这也就意味着，当我们需要添加新的元素时，我们需要定位到插入点，这样才可以继续保证链表是有序的，通常我们会使用 **二分查找法**，但二分查找是有序数组的，链表没办法进行位置定位，我们除了遍历整个找到第一个比给定数据大的节点为止 *（时间复杂度 O(n))* 似乎没有更好的办法。

但假如我们每相邻两个节点之间就增加一个指针，让指针指向下一个节点，这样所有新增的指针连成了一个新的链表，但它包含的数据却只有原来的一半 。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105257.png" alt="image-20220502105255807" style="zoom:50%;" />

现在假设我们想要查找数据时，可以根据这条新的链表查找，如果碰到比待查找数据大的节点时，再回到原来的链表中进行查找，比如，我们想要查找 7，查找的路径则是沿着下图中标注出的红色指针所指向的方向进行的：

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105401.png" alt="image-20220502105400335" style="zoom:50%;" />

这是一个略微极端的例子，但我们仍然可以看到，通过新增加的指针查找，我们不再需要与链表上的每一个节点逐一进行比较，这样改进之后需要比较的节点数大概只有原来的一半。

利用同样的方式，我们可以在新产生的链表上，继续为每两个相邻的节点增加一个指针，从而产生第三层链表：

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105427.png" alt="image-20220502105426146" style="zoom:50%;" />

在这个新的三层链表结构中，我们试着 **查找 13**，那么沿着最上层链表首先比较的是 11，发现 11 比 13 小，于是我们就知道只需要到 11 后面继续查找，**从而一下子跳过了 11 前面的所有节点。**

可以想象，当链表足够长，这样的多层链表结构可以帮助我们跳过很多下层节点，从而加快查找的效率

#### 更进一步的跳跃表

**跳跃表 skiplist** 就是受到这种多层链表结构的启发而设计出来的。按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到 *O(logn)*。

但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点 *（也包括新插入的节点）* 重新进行调整，这会让时间复杂度重新蜕化成 *O(n)*。删除数据也有同样的问题。

**skiplist** 为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是 **为每个节点随机出一个层数(level)**。比如，一个节点随机出的层数是 3，那么就把它链入到第 1 层到第 3 层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个 skiplist 的过程：

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105630.png" alt="image-20220502105628712" style="zoom:50%;" />

从上面的创建和插入的过程中可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此，**插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整**，这就降低了插入操作的复杂度。

现在我们假设从我们刚才创建的这个结构中查找 23 这个不存在的数，那么查找路径会如下图：

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105703.png" alt="image-20220502105701759" style="zoom:50%;" />

#### 跳跃表的实现

Redis 中的跳跃表由 `server.h/zskiplistNode` 和 `server.h/zskiplist` 两个结构定义，前者为跳跃表节点，后者则保存了跳跃节点的相关信息，同之前的 `集合 list` 结构类似，其实只有 `zskiplistNode` 就可以实现了，但是引入后者是为了更加方便的操作：

```java
/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
    // value
    sds ele;
    // 分值
    double score;
    // 后退指针
    struct zskiplistNode *backward;
    // 层
    struct zskiplistLevel {
        // 前进指针
        struct zskiplistNode *forward;
        // 跨度
        unsigned long span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    // 跳跃表头指针
    struct zskiplistNode *header, *tail;
    // 表中节点的数量
    unsigned long length;
    // 表中层数最大的节点的层数
    int level;
} zskiplist;
```

==随机层数==

对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数，源码在 `t_zset.c/zslRandomLevel(void)` 中被定义：

```java
int zslRandomLevel(void) {
    int level = 1;
    while ((random()&0xFFFF) < (ZSKIPLIST_P * 0xFFFF))
        level += 1;
    return (level<ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;
}
```

直观上期望的目标是 50% 的概率被分配到 `Level 1`，25% 的概率被分配到 `Level 2`，12.5% 的概率被分配到 `Level 3`，以此类推...有 2-63 的概率被分配到最顶层，因为这里每一层的晋升率都是 50%。

**Redis 跳跃表默认允许最大的层数是 32**，被源码中 `ZSKIPLIST_MAXLEVEL` 定义，当 `Level[0]` 有 264 个元素时，才能达到 32 层，所以定义 32 完全够用了。

==创建跳跃表==

这个过程比较简单，在源码中的 `t_zset.c/zslCreate` 中被定义：

```java
zskiplist *zslCreate(void) {
    int j;
    zskiplist *zsl;

    // 申请内存空间
    zsl = zmalloc(sizeof(*zsl));
    // 初始化层数为 1
    zsl->level = 1;
    // 初始化长度为 0
    zsl->length = 0;
    // 创建一个层数为 32，分数为 0，没有 value 值的跳跃表头节点
    zsl->header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);
    
    // 跳跃表头节点初始化
    for (j = 0; j < ZSKIPLIST_MAXLEVEL; j++) {
        // 将跳跃表头节点的所有前进指针 forward 设置为 NULL
        zsl->header->level[j].forward = NULL;
        // 将跳跃表头节点的所有跨度 span 设置为 0
        zsl->header->level[j].span = 0;
    }
    // 跳跃表头节点的后退指针 backward 置为 NULL
    zsl->header->backward = NULL;
    // 表头指向跳跃表尾节点的指针置为 NULL
    zsl->tail = NULL;
    return zsl;
}
```

即执行完之后创建了如下结构的初始化跳跃表：

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502105923.png" alt="image-20220502105922140" style="zoom:50%;" />

==插入节点实现==

1. 找到当前我需要插入的位置 *（其中包括相同 score 时的处理）*；
2. 创建新节点，调整前后的指针指向，完成插入；

源码 `t_zset.c/zslInsert` 定义的插入函数可分为几个部分

**第一部分：声明需要存储的变量**

```c
// 存储搜索路径
zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
// 存储经过的节点跨度
unsigned int rank[ZSKIPLIST_MAXLEVEL];
int i, level;
```

**第二部分：搜索当前节点插入位置**

```c
serverAssert(!isnan(score));
x = zsl->header;
// 逐步降级寻找目标节点，得到 "搜索路径"
for (i = zsl->level-1; i >= 0; i--) {
    /* store rank that is crossed to reach the insert position */
    rank[i] = i == (zsl->level-1) ? 0 : rank[i+1];
    // 如果 score 相等，还需要比较 value 值
    while (x->level[i].forward &&
            (x->level[i].forward->score < score ||
                (x->level[i].forward->score == score &&
                sdscmp(x->level[i].forward->ele,ele) < 0)))
    {
        rank[i] += x->level[i].span;
        x = x->level[i].forward;
    }
    // 记录 "搜索路径"
    update[i] = x;
}
```

**讨论：** 有一种极端的情况，就是跳跃表中的所有 score 值都是一样，zset 的查找性能会不会退化为 O(n) 呢？

从上面的源码中我们可以发现 zset 的排序元素不只是看 score 值，也会比较 value 值 *（字符串比较）*

**第三部分：生成插入节点**

```c
/* we assume the element is not already inside, since we allow duplicated
 * scores, reinserting the same element should never happen since the
 * caller of zslInsert() should test in the hash table if the element is
 * already inside or not. */
level = zslRandomLevel();
// 如果随机生成的 level 超过了当前最大 level 需要更新跳跃表的信息
if (level > zsl->level) {
    for (i = zsl->level; i < level; i++) {
        rank[i] = 0;
        update[i] = zsl->header;
        update[i]->level[i].span = zsl->length;
    }
    zsl->level = level;
}
// 创建新节点
x = zslCreateNode(level,score,ele);
```

**第四部分：重排前向指针**

```c
for (i = 0; i < level; i++) {
    x->level[i].forward = update[i]->level[i].forward;
    update[i]->level[i].forward = x;

    /* update span covered by update[i] as x is inserted here */
    x->level[i].span = update[i]->level[i].span - (rank[0] - rank[i]);
    update[i]->level[i].span = (rank[0] - rank[i]) + 1;
}

/* increment span for untouched levels */
for (i = level; i < zsl->level; i++) {
    update[i]->level[i].span++;
}
```

**第五部分：重排后向指针并返回**

```c
x->backward = (update[0] == zsl->header) ? NULL : update[0];
if (x->level[0].forward)
    x->level[0].forward->backward = x;
else
    zsl->tail = x;
zsl->length++;
return x;
```

==节点删除实现==

删除过程由源码中的 `t_zset.c/zslDeleteNode` 定义，和插入过程类似，都需要先把这个 **"搜索路径"** 找出来，然后对于每个层的相关节点重排一下前向后向指针，同时还要注意更新一下最高层数 `maxLevel`，直接放源码 *(如果理解了插入这里还是很容易理解的)*：

```c
/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank */
void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) {
    int i;
    for (i = 0; i < zsl->level; i++) {
        if (update[i]->level[i].forward == x) {
            update[i]->level[i].span += x->level[i].span - 1;
            update[i]->level[i].forward = x->level[i].forward;
        } else {
            update[i]->level[i].span -= 1;
        }
    }
    if (x->level[0].forward) {
        x->level[0].forward->backward = x->backward;
    } else {
        zsl->tail = x->backward;
    }
    while(zsl->level > 1 && zsl->header->level[zsl->level-1].forward == NULL)
        zsl->level--;
    zsl->length--;
}

/* Delete an element with matching score/element from the skiplist.
 * The function returns 1 if the node was found and deleted, otherwise
 * 0 is returned.
 *
 * If 'node' is NULL the deleted node is freed by zslFreeNode(), otherwise
 * it is not freed (but just unlinked) and *node is set to the node pointer,
 * so that it is possible for the caller to reuse the node (including the
 * referenced SDS string at node->ele). */
int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) {
    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
    int i;

    x = zsl->header;
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward &&
                (x->level[i].forward->score < score ||
                    (x->level[i].forward->score == score &&
                     sdscmp(x->level[i].forward->ele,ele) < 0)))
        {
            x = x->level[i].forward;
        }
        update[i] = x;
    }
    /* We may have multiple elements with the same score, what we need
     * is to find the element with both the right score and object. */
    x = x->level[0].forward;
    if (x && score == x->score && sdscmp(x->ele,ele) == 0) {
        zslDeleteNode(zsl, x, update);
        if (!node)
            zslFreeNode(x);
        else
            *node = x;
        return 1;
    }
    return 0; /* not found */
}
```

==节点更新实现==

当我们调用 `ZADD` 方法时，如果对应的 value 不存在，那就是插入过程，如果这个 value 已经存在，只是调整一下 score 的值，那就需要走一个更新流程。

假设这个新的 score 值并不会带来排序上的变化，那么就不需要调整位置，直接修改元素的 score 值就可以了，但是如果排序位置改变了，那就需要调整位置，该如何调整呢？

从源码 `t_zset.c/zsetAdd` 函数 `1350` 行左右可以看到，Redis 采用了一个非常简单的策略：

```c
/* Remove and re-insert when score changed. */
if (score != curscore) {
    zobj->ptr = zzlDelete(zobj->ptr,eptr);
    zobj->ptr = zzlInsert(zobj->ptr,ele,score);
    *flags |= ZADD_UPDATED;
}
```

**把这个元素删除再插入这个**，需要经过两次路径搜索，从这一点上来看，Redis 的 `ZADD` 代码似乎还有进一步优化的空间。

==元素排名的实现==

跳跃表本身是有序的，Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 `span` 属性，用来 **表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点中间会跳过多少个节点**。在上面的源码中我们也可以看到 Redis 在插入、删除操作时都会小心翼翼地更新 `span` 值的大小。

所以，沿着 **"搜索路径"**，把所有经过节点的跨度 `span` 值进行累加就可以算出当前元素的最终 rank 值了：

```c
/* Find the rank for an element by both score and key.
 * Returns 0 when the element cannot be found, rank otherwise.
 * Note that the rank is 1-based due to the span of zsl->header to the
 * first element. */
unsigned long zslGetRank(zskiplist *zsl, double score, sds ele) {
    zskiplistNode *x;
    unsigned long rank = 0;
    int i;

    x = zsl->header;
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward &&
            (x->level[i].forward->score < score ||
                (x->level[i].forward->score == score &&
                sdscmp(x->level[i].forward->ele,ele) <= 0))) {
            // span 累加
            rank += x->level[i].span;
            x = x->level[i].forward;
        }

        /* x might be equal to zsl->header, so test if obj is non-NULL */
        if (x->ele && sdscmp(x->ele,ele) == 0) {
            return rank;
        }
    }
    return 0;
}
```

### Bitmap

`Bitmap`，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（`offset`）定位元素。`BitMap`通过最小的单位`bit`来进行`0|1`的设置，表示某个元素的值或者状态，时间复杂度为`O(1)`。由于`bit`是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。

这里的二值状态就是指集合元素的取值就只有 0 和 1 两种。例如在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 Bitmap。

Bitmap不属于Redis的基本数据类型，而是基于String类型进行的位操作。而Redis中字符串的最大长度是 512M，所以 BitMap 的 offset 值也是有上限的，其最大值是：`8 * 1024 * 1024 * 512  =  2^32`

> 优点
>
> - 基于最小的单位bit进行存储，所以非常省空间。
> - 设置时候时间复杂度`O(1)`、读取时候时间复杂度`O(n)`，操作是非常快的。
> - 二进制数据的存储，进行相关计算的时候非常快。
> - 方便扩容
>
> 缺点
>
> `Redis`中`bit`映射被限制在`512MB`之内，所以最大是`2^32`位。建议每个`key`的位数都控制下，因为读取时候时间复杂度`O(n)`，越大的串读的时间花销越多。



# 4. `Redis`主从是怎么做的







# 5. 缓存雪崩，缓存击穿，缓存穿透

## 缓存雪崩

> 当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。
>
> <font color='Apricot'>原因：</font>
>
> 造成缓存雪崩的关键在于在**同一时间大规模的key失效**。出现这个问题有两种可能，第一种可能是`Redis`宕机，第二种可能是采用了相同的过期时间。
>
> <font color='Apricot'>解决方案：</font>
>
> 1. 在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。
> 2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。同时，分布式集群可以防止Redis宕机导致缓存雪崩的问题。
> 3. 设置热点数据永远不过期。
>
> <font color='Apricot'>**缓存雪崩的兜底措施**：</font>
>
> 1. 使用熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
>
> 2. 提高数据库的容灾能力，可以使用分库分表，读写分离的策略。

## 缓存击穿

> 跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。
>
> <font color='Apricot'>原因：</font>
>
> 关键在于某个热点的`key`失效了，导致大并发集中打在数据库上。
>
> 所以要从两个方面解决，第一是否可以考虑热点`key`不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。
>
> <font color='Apricot'>解决方案：</font>
>
> 1. 如果业务允许的话，对于热点的key可以设置永不过期的key。
> 2. 使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。

## 缓存穿透

> 我们使用Redis大部分情况都是通过Key查询对应的值，假如发送的请求传进来的key是不存在Redis中的，那么就查不到缓存，查不到缓存就会去数据库查询。假如有大量这样的请求，这些请求像“穿透”了缓存一样直接打在数据库上，这种现象就叫做缓存穿透。
>
> <font color='Apricot'>原因：</font>
>
> **缓存穿透的情况是传进来的key在Redis中是不存在的**，这和缓存击穿有根本的区别。假如有黑客传进大量的不存在的`key`，那么大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，一些非法的参数，不可能存在的`key`就直接返回错误提示，要对调用方保持这种“不信任”的心态。
>
> <font color='Apricot'>解决方案：</font>
>
> 1. **把无效的Key存进Redis中**。如果`Redis`查不到数据，数据库也查不到，我们把这个`Key`值保存进`Redis`，设置`value="null"`，当下次再通过这个`Key`查询时就不需要再查询数据库。这种处理方式肯定是有问题的，假如传进来的这个不存在的`Key`值每次都是随机的，那存进`Redis`也没有意义。
> 2. **使用布隆过滤器**。布隆过滤器的作用是某个 `key `不存在，那么就一定不存在，它说某个 `key `存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询 `key `是否存在，如果不存在就直接返回。





//补充实际业务场景 面试一定会问到



# 6. 多线程与线程安全

## 多线程源头

1. 原子性

   > <font color='Magenta'>何为原子性：</font>
   >
   > 原子性的操作是不可被中断的一个或一系列操作。其他线程获取变量时稚嫩获取操作前的变量值和操作后的变量值，不能会去到操作过程中的中间值，在操作过程中其他操作需要获取变量值需要进入阻塞状态等待操作结束。
   >
   > 
   >
   > <font color='Magenta'>保证原子性的方式</font>
   >
   > 1. 加锁 synchronized，保证同一时间只有一个线程操作变量，其他线程需要等待操作结束才能使用临界资源
   > 2. `CAS`，变量计算前保留一份旧值 a，计算完成后结果值为 b，把 b 刷到内存之前先比较 a 是否与内存中的变量一致，如果一致就把内存中的变量赋值为 b，否则重新获取内存中变量值，重复操作直到 a 与内存中的一致，操作结束
   >
   > `Lock` 和原子类（`AtomicInteger`）是通过 `unsafe` 的 `compareAndSwap` 方法实现 `CAS` 操作保证原子性的

2. 可见性

   线程变量的可见性问题需要从操作系统的 CPU、缓存、内存的矛盾开始说起。读写性能上 CPU>缓存>内存>I/O。在 CPU 和内存之间隔着缓存和 CPU 寄存器。缓存又分为一级、二级、三级缓存。==CPU 读写性能大于内存，为提高效率会先将数据取到缓存中（每个CPU都有自己的缓存叫做本地工作内存），CPU 处理完数据后会先放到缓存（本地工作内存）中，然后同步到内存==

   <img src="https://pic4.zhimg.com/80/v2-d182eaedb593fc9615c2c665175a98cf_1440w.webp" alt="img" style="zoom:50%;" />

   >  <font color='Magenta'>保证可见性的方式</font>
   >
   > 1. 加锁（加锁是万能的操作）synchronized和Lock都可以保证。线程在加锁时，会清空工作内存中共享变量的值，共享变量使用时需要从主内存中重新获取。线程解锁时，会把共享变量重新刷新到主内存中。
   > 1. 使用volatile修饰共享变量，volatile修饰的共享变量在修改后会立即被更新到内存中，其他线程使用共享变量会去内存中读取
   >
   > 优先使用volatile来解决可见性问题，加锁需要消耗的资源太多。

3. 有序性

   计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，重排过程中会遵循as-if-serial语义，即不影响单线程的运行结果。。

   >指令重排一般分为以下三种：
   >
   >- <font color='Magenta'>编译器优化重排</font>
   >
   >  编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
   >
   >- <font color='Magenta'>指令并行重排</font>
   >
   >  现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。
   >
   >- <font color='Magenta'>内存系统重排</font>
   >
   >  由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

   指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。

   >  <font color='Magenta'>保证有序性的方式</font>
   >
   > 1. 加锁（还是加锁）synchronized和Lock，保证同一时刻只有一个线程进行操作
   > 2. 使用volatile修饰变量，在JMM中volatile的读和写都会插入内存屏障来禁止处理器的重排

   


## 何为线程安全

> 当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，并且不需要额外的同步，或者在调用方代码不做其他的协调操作，这个对象的行为获取的结果仍然是正确的，那个称这个对象是线程安全的。

## 出现的原因

**对象的有状态和无状态性**

~~~markdown
Java中按照状态可以把对象分为 有状态 和 无状态两种。
1. 无状态对象（Stateless Bean）：无状态对象就是没有实例变量的对象，所以也无法保存数据，它不包含域也没有引用其他类的域。又因为无状态对象没有存储的数据那么这个对象也没有什么改变之说所以是不可变的，同样的多线程下对该对象的任意操作都不会改变对象的状态。所以“无状态的对象一定是线程安全的”
2. 有状态对象（Stateful Bean）：就是有实例变量的对象 ，可以保存数据。
~~~

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428145349.jpg" alt="img" style="zoom: 67%;" />

> 实例的数据是保存在堆中，而堆中的数据是可以被多个线程共享的
>
> 而在多线程同时访问相同堆中的数据进行读写操作时，就达到了竞态条件 导致多线程在竞争资源读写数据时最后的结果不会像我们预想的那样正确，出现线程不安全的情况。同时修改对象的数据对象的状态也被改变所以被称为有状态对象

**竞态条件**

> 竞态条件是由于当一个对象或者一个不同步的共享状态，被多个线程修改时，会出现由于不恰当的执行时序而出现不正确的结果所引起。

**指令重排和有序性**

> 其实除了竞态的时候会出现不恰当的执行时序外，指令重排也会导致代码执行的顺序并不是按照你书写顺序的意愿执行的。
>
> 代码运行一般步骤是这样的：
> 1、从主内存中获取指令解码
> 2、在线程内存中计算值
> 3、执行代码操作
> 4、把结果写入主内存（主内存所有线程共享）
>
> 而把结果写入主内存的操作比较耗时，CPU为了提高性能，可能不会等它完成，就进行对下一个指令解码计算，这就是指令重排了。定义如下：
> 指令重排：计算机为了性能优化会对汇编指令进行重新排序，以便充分利用硬件的处理性能。
>
> 指令重排会改变代码执行的顺序，但是因为最后执行的结果不变所以在单线程下是没有什么问题的。
>
> 而如果在多线程中，同时操作一个数据，如果一个读，一个写，当写的线程值已经改变了但是还没写入主内存时（也就是说值的改变其他线程还没有看到），另一个线程已经开始读取了，那么这个时候就会出现和预期不一致的结果。
>
> 其实现在对于多线程并发为什么会出现不安全的问题已经很清楚了，究其根本是因为多线程是不共享的，并且也无法准确的知道互相之间的状态，包括值的修改也无法可见才会导致修改数据出现问题，出现线程不安全的问题。

## 出现的地方

1. 修改共享数据
2. 未保证原子性

​	原子性就是 提供互斥访问，同一时刻只能有一个线程对数据进行操作，有时也把这个现象叫做同步互斥，表示操作是互相排斥的

​	不保证原子性就会导致 一个线程正在对一个变量操作，中途其他线程插入进来了，如果这个操作被打断了，结果就可能是错误的。 这点也和线程的抢占式调度密切相关. 如果线程不是 “抢占” 的, 就算没有原子性, 	也问题不大

## 解决方式

### synchronized关键字

> 这是一个表现为原生语法层面的互斥锁，它是一种悲观锁（认为自己在使用数据的时候，一定有别的线程来修改数据，因此在获取数据的时候先加锁，确保数据不会被线程修改），使用它的时候我们一般需要一个监听对象 并且监听对象必须是唯一的，通常就是当前类的字节码对象。它是 `JVM `级别的，不会造成死锁的情况。使用 `synchronized `可以拿来修饰类，静态方法，普通方法和代码块。

~~~java
// Hashtable类就是使用synchronized来修饰方法的。 
public synchronized V put(K key, V value) {
        // Make sure the value is not null
        if (value == null) {
            throw new NullPointerException();
        } 
// ConcurrentHashMap类中就是使用synchronized来锁代码块的。putVal方法部分源码：
  else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
~~~

> - `synchronized`关键字底层实现主要是通过`monitorenter `与`monitorexit`计数 ，如果计数器不为 0，说明资源被占用，其他线程就不能访问了，但是可重入的除外。
>
>   可重入锁：指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响，执行对象中所有同步方法不用再次获得锁。避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。
>
> - 在使用`synchronized`时，存在一个锁升级原理。
>
>   1. 它是指在锁对象的对象头里面有一个 `threadid `字段，在第一次访问的时候 `threadid `为空，`jvm `让其持有偏向锁，并将 `threadid `设置为其线程 `id`，再次进入的时候会先判断 `threadid `是否与其线程 `id `一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 `synchronized `锁的升级。
>
>   2. 锁升级的目的是为了降低锁带来的性能消耗。在` Java 6` 之后优化 `synchronized `的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。
>
>   3. 偏向锁（无锁）：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后（线程的`id`会记录在对象的`Mark Word`中），消除这个线程锁重入（`CAS`）的开销，看起来让这个线程得到了偏护。
>
>   4. 轻量级锁（CAS）：就是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；轻量级锁的意图是在没有多线程竞争的情况下，通过`CAS`操作尝试将`MarkWord`更新为指向`LockRecord`的指针，减少了使用重量级锁的系统互斥量产生的性能消耗。
>
>   5. 重量级锁：虚拟机使用`CAS`操作尝试将`MarkWord`更新为指向`LockRecord`的指针，如果更新成功表示线程就拥有该对象的锁；如果失败，会检查`MarkWord`是否指向当前线程的栈帧，如果是，表示当前线程已经拥有这个锁；如果不是，说明这个锁被其他线程抢占，此时膨胀为重量级锁。

### 使用Lock接口下的实现类

`Lock`是`juc（java.util.concurrent）`包下面的一个接口。常用的实现类就是`ReentrantLock `类，它其实也是一种悲观锁。一种表现为 `API `层面的互斥锁。通过`lock()` 和 `unlock() `方法配合使用。因此也可以说是一种手动锁，使用比较灵活。但是使用这个锁时一定**要注意要释放锁**，不然就会造成死锁。一般配合`try/finally` 语句块来完成。

```java
public class TicketThreadSafe extends Thread{
      private static int num = 5000;
      ReentrantLock lock = new ReentrantLock();
      @Override
      public void run() {
        while(num>0){
             try {
               lock.lock();
               if(num>0){
                 System.out.println(Thread.currentThread().getName()+"你的票号是"+num--);
               }
              } catch (Exception e) {
                 e.printStackTrace();
              }finally {
                 lock.unlock();
              }
            }
      }
}
```

相比 `synchronized`，`ReentrantLock `增加了一些高级功能，主要有以下 3 项：**等待可中断、可实现公平锁，以及锁可以绑定多个条件。**

​	等待可中断是指：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。

​	公平锁是指：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。`synchronized `中的锁是非公平的，`ReentrantLock `默	认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。

```java 
public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
```

​	锁绑定多个条件是指：一个 `ReentrantLock `对象可以同时绑定多个 `Condition `对象，而在 `synchronized `中，锁对象的 `wait()` 和 `notify()` 或 `notifyAll()` 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时	候，就不得不额外地添加一个锁，而 `ReentrantLock `则无须这样做，只需要多次调用` newCondition()` 方法即可。

```java
final ConditionObject newCondition() { //ConditionObject是Condition的实现类
            return new ConditionObject();
    } 
```

### 使用线程本地存储`ThreadLocal`

当多个线程**操作同一个变量且互不干扰**的场景下，可以使用`ThreadLocal`来解决。它会在每个线程中对该变量创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。在很多情况下，`ThreadLocal`比直接使用`synchronized`同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。通过`set(T value)`方法给线程的局部变量设置值；`get()`获取线程局部变量中的值。当给线程绑定一个 `Object `内容后，只要线程不变,就可以随时取出；改变线程,就无法取出内容

```java
public class ThreadLocalTest {
      private static int a = 500;
      public static void main(String[] args) {
            new Thread(()->{
                  ThreadLocal<Integer> local = new ThreadLocal<Integer>();
                  while(true){
                        local.set(++a);   //子线程对a的操作不会影响主线程中的a
                        try {
                              Thread.sleep(1000);
                        } catch (InterruptedException e) {
                              e.printStackTrace();
                        }
                        System.out.println("子线程："+local.get());
                  }
            }).start();
            a = 22;
            ThreadLocal<Integer> local = new ThreadLocal<Integer>();
            local.set(a);
            while(true){
                  try {
                        Thread.sleep(1000);
                  } catch (InterruptedException e) {
                        e.printStackTrace();
                  }
                  System.out.println("主线程："+local.get());
            }
      }
} 
```

`ThreadLocal`线程容器保存变量时，底层其实是通过`ThreadLocalMap`来实现的。它是以当前`ThreadLocal`变量为`key `，要存的变量为`value`。获取的时候就是以当前`ThreadLocal`变量去找到对应的`key`，然后获取到对应的值。

```java
// 源码
 public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
     ThreadLocalMap getMap(Thread t) {
        return t.threadLocals; //ThreadLocal.ThreadLocalMap threadLocals = null;Thread类中声明的
    }
    void createMap(Thread t, T firstValue) {
        t.threadLocals = new ThreadLocalMap(this, firstValue);
    }
```

其实每个线程`Thread`内部有一个`ThreadLocal.ThreadLocalMap`类型的成员变量`threadLocals`，这个`threadLocals`就是用来存储实际的变量副本的，键值为当前`ThreadLocal`变量，`value`为变量副本（即T类型的变量）。

初始时，在`Thread`里面，`threadLocals`为空，当通过`ThreadLocal`变量调用`get()`方法或者`set()`方法，就会对`Thread`类中的`threadLocals`进行初始化，并且以当前`ThreadLocal`变量为键值，以`ThreadLocal`要保存的副本变量为`value`，存到`threadLocals`。

然后在当前线程里面，如果要使用副本变量，就可以通过`get`方法在`threadLocals`里面查找即可。

### 乐观锁机制

在表设计的时候，需要往表里加一个`version`字段。每次查询时，查出带有`version`的数据记录，更新数据时，判断数据库里对应`id`的记录的`version`是否和查出的`version`相同。若相同，则更新数据并把版本号`+1`；若不同，则说明，该数据发生了并发，被别的线程使用了，进行递归操作，再次执行递归方法，直到成功更新数据为止。



# 7. `JAVA`的一些锁

## 锁分类

一种是关键字 `Synchronized`，一种是对象 `lock`，还有一种 `volatile `关键字。

- `Synchronized `用于代码块或方法中，他能使一段代码处于同步执行。
- `lock `跟 `synchronized `类似，但需要自行加锁和释放锁。必须手动释放锁，不然会造成死锁。
  - `lock `比 `synchronized` 更有优势，因为他比 `synchronized `多了嗅探锁定，多路分支通知，判断锁的状态等功能。
  - 嗅探锁定：`lock` 可以使用 `tryLock()` 方法尝试获取锁，若获取不到就继续执行，不会造成线程的阻塞。而 `synchronized `只能进入阻塞他。
  - 多路分支通知：`lock `可以创建多个 `condition`，然后可以将线程对应一个 `condition`，当要唤醒此线程时可以用对应的 `condition `来唤醒。
- `volatile `作用范围小，只作用在一个变量上。`volatile `具有以下三个特性：
  - 可见性：他会从工作内存中复制一份到主内存中，并且每次更新也会随之更新到主内存。当不同线程需要获取其值时，可以从主内存中获取，从而达到一致性。
  - 禁止指令重排：添加了 volatile 关键字的变量，其前面的代码不能运行在此变量后，在后面的代码不能运行在此变量前。
  - `volatile `实际上并不是锁，不具备加锁，阻塞等操作。他使用的方式是根据 `volatile `对象是否变化来判断接下来如何执行。
  - `volatile `也存在缺陷，有时在改变变量时可能还会取到先前的值，但这是非常小的小概率事件。

## Java锁机制

### 1. 公平锁/非公平锁

​	公平锁就是按照先到先得的顺序获得锁。当一个线程获得锁并且没有释放，接下来的线程就会进入阻塞队列等待，并按照队列的方式顺序的获取锁。

​	非公平锁就是新来的线程可以跟阻塞队列的队头争夺一把锁，争夺不过才会添加到队尾。这种情况下，后到的线程有可能无需进入等待队列直接获取锁。

​	`Synchronized `和 `lock `默认都是非公平锁。`lock `可以通过构造函数的方式改为公平锁。

​	非公平锁性能高于公平锁。因为当一个线程执行完释放锁时，阻塞的线程需要被唤醒，这个过程有些漫长。在等待的时间如果有一个活跃的线程想争夺这把锁，就把锁让给他，减少等待的时间。

### 2. 乐观锁/悲观锁

乐观锁和悲观锁是一种概念。

​		乐观锁：很乐观，每次拿数据时都认为数据没有被修改，所以先不加锁。通过判断其版本号来判断此数据是否发生改变。

​		悲观锁：很悲观，每次拿数据时都认为别人会修改数据，这时就要上锁来阻止别人进行修改。

悲观锁比较暴力，直接加锁。

乐观锁一般采用` CAS（compare and swapper）`比较并交换的方式来实现。

- 使用 `volatile` 关键字修饰的变量作为版本号，这是因为 `volatile `具有可见性。

​		实现思路：参考 `AtomicInteger `的实现：

> - 先通过 `get()` 方式从内存中获取到变量的原先值，（这个值当成版本号）。
> - 接下来修改值时调用 `unsafe `里的 `compareAndSwapper()` 方法。
> - 该方法需要传入内存中的基址，偏移量，旧值（版本号），更新的值）
> - 如果旧值和内存里的值一样，就进行交换，如果不一样，说明被人改了，则停止交换，返回 `false`。
> - 交换失败后若还想改变，则必须重新 `get()` 内存里的新值，在进行 `CAS`。

上述有种缺陷：因为该思路将自身值作为版本号，可以任意改变，而正常的版本号是不断增加的。造成的 `ABA ` 的问题：

- 若两个线程同时从内存种取值，取到都是 A。
- 第一个线程停止，第二个线程把 A 换为 B。
- 再来一个线程，把 B 重新换回 A。
- 这时第一个线程执行，他会认为此变量根本没有发生变化。

解决方法：不把自身作为版本号，而是再新建一个字段作为版本号，此版本只能增加，不能回溯。但此时只是版本号来进行 `CAS`，而需要同步的变量只是做普通的改变，这也会造成并发异常。解决方法还是得加锁。

```java
if (version == UNSAFE.getObject()){ // 版本号相比较，比较成功修改
    synchronized(对象){
        // 对象赋值    // 赋值完再更改版本号
        // 更改版本号
    }
}
```

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220502162729.jpg)

### 3. 自旋锁

由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短。所以当一个线程需要等待锁时没有必要挂起，因为用户态和内核态之间的切换十分影响性能。

自旋的利用 `CAS `操作，比较版本号是否相同，如果相同则得到锁，不相同就一直循环获取锁，让其处于活跃态，从而不用挂起线程。

// TODO 自旋锁会自旋多久 一直拿不到会一直自旋吗？ 常问问题

> 自旋锁避免了操作系统进程调度和线程切换，所以自旋锁通常适用在时间比较短的情况下。由于这个原因，**操作系统的内核经常使用自旋锁**。但是，如果长时间上锁的话，自旋锁会非常耗费性能，它阻止了其他线程的运行和调度。线程持有锁的时间越长，则持有该锁的线程将被 `OS(Operating System)` 调度程序中断的风险越大。如果发生中断情况，那么其他线程将保持旋转状态(反复尝试获取锁)，而持有该锁的线程并不打算释放锁，这样导致的结果是无限期推迟，直到持有锁的线程可以完成并释放它为止。
>
> 解决上面这种情况一个很好的方式是给自旋锁设定一个自旋时间，等时间一到立即释放自旋锁。自旋锁的目的是占着CPU资源不进行释放，等到获取锁立即进行处理。如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。JDK在1.6 引入了适应性自旋锁，适应性自旋锁意味着自旋时间不是固定的，而是由前一次在同一个锁上的自旋时间以及锁拥有的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162730.jpg" alt="img" style="zoom: 33%;" />

### 4. 自适应自旋锁

由于一直循环也十分耗费资源。自旋的时间并不是固定的，于是采取了一种方法，当超过了时间就不再进行循环，而是直接将线程挂起。

`jdk1.7` 中 `concurrentHashMap `添加就是采用此操作。

```java
private HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {
    HashEntry<K,V> first = entryForHash(this, hash);   // 得到链表的第一个节点
    HashEntry<K,V> e = first;
    HashEntry<K,V> node = null;
    int retries = -1;      // 重复尝试
    while (!tryLock()) {         // 自旋操作，没有获取到锁
        HashEntry<K,V> f; 
        if (retries < 0) {
            if (e == null) {         // 首节点为 null
                if (node == null) 
                    node = new HashEntry<K,V>(hash, key, value, null);   // 给 node 创建对象
                retries = 0;     // 重复尝试
            }
            else if (key.equals(e.key))   // 添加的节点已存在
                retries = 0;
            else
                e = e.next;
        }
        else if (++retries > MAX_SCAN_RETRIES) {
            // 如果尝试次数大于默认的最大尝试次数，就使用 lock 阻塞。减少资源消耗，自适应自旋
            lock();
            break;
        }
        else if ((retries & 1) == 0 && (f = entryForHash(this, hash)) != first) {
            // 判断首节点是否已经改变，已经改变
            e = first = f;   // 更换首节点
            retries = -1;    // 重新进行尝试，查看当前线程添加的节点是否是新添加的节点
        }
    }
    return node;    // 获得锁时退出循环，并返回此节点
}
```

### 5. 可重入锁

可重入锁就是当线程已获取到了 A 锁，当在执行阶段又需要获取 A 锁，并不会因为 A 锁被人拿走了而进行阻塞，而是因为自己有此锁继续执行。

`Synchronized `和 `ReentrantLock `都是可重入锁，只不过 `Synchronized `自动获取和自动释放锁。`ReentrantLock `得手动获取和释放，并且获取锁的次数必须和释放锁的次数相同，否则会造成死锁。

### 6. 读写锁（共享锁/互斥锁）

`ReentrantLock `类具有完全互斥的效果，同一时间只有一个线程在执行，效率低下。

`JDK `提供了一种读写锁 -- `ReentrantReadWriteLock `类，使用它可以在进行一些操作时不需要同步执行，提高效率。

读锁之间不互斥，读锁和写锁互斥，写锁和写锁互斥（只要出现写锁就互斥）。

## Synchronized 的锁机制

从 `JDK1.6 `版本后，`Synchronized `本身也在不断优化锁的机制，有些情况下它并不是一个很重量级的锁。优化机制包括自适应锁，自旋锁，轻量级锁，重量级锁。

### Java 对象头

java 对象分为三部分：对象头，实体数据，对齐填充符。

- 对象头：
  - `Mark Word`
    - 对象的 `HashCode`
    - 分代年龄
    - GC 标记
    - 锁的标记
  - 指向类的指针
  - 数组长度
- 实例数据
- 对齐填充符

在无锁的状态下，`Mark Word `会记录：对象的 `HashCode`，分代年龄，是否是偏向锁，锁标志。

### 偏向锁

1. 偏向锁的设计理念：

- 由于每次进入和退出同步块都需要获取和释放锁，十分浪费资源。
- 经过大量的验证，发现很多情况下都是同一个线程来获取锁。
- 于是就理想化的让这个锁一直给这个线程。

​	要保证锁是由一个线程来获取，就必须在锁的对象头上添加此线程的 `ID`。于是偏向锁状态下，`Mark Word` 会记录：线程对象的 `HashCode`，分代年龄，是否偏向锁，锁标志。

2. 执行流程：

- 当锁第一次被线程获取，就将线程 `Hashcode `添加到锁的对象头里。
- 线程执行完后并不释放锁。
- 当第二次获取锁，会先判断此线程是否和对象头记录的线程一致，一致的话就直接运行同步代码。
- 若不一致，则锁会升级/膨胀，变成轻量级锁。

​	优点：在没有竞争或者只有一个线程使用锁的情况下，偏向锁节省了获取和释放锁对性能的损耗。

### 轻量级锁

轻量级锁状态下，`Mark Word` 会记录：指向线程栈中锁记录的指针，锁标志位。

- 虚拟机会在线程栈中创建一块内存 `Lock Record` 来存放信息。（从锁的 `Mark Word` 中 `copy`）
- 当线程要获取锁时，会进行 `CAS `操作，将锁的 `Mark Word` 更新为指向栈中锁记录的指针。
- 如果 `CAS `操作成功，则表示该线程获取到锁。
- `CAS `失败，表示锁被别的线程获取到，采用自旋锁的方式来等待获取锁。

优点：避免在了线程的阻塞，当线程获取不到锁时，会进行自旋，而不会阻塞，造成系统调用内核态和用户态。

缺点：如果存在大量竞争，轻量锁采用的 CAS 和自旋操作会大量的消耗资源，程序的性能反而会下降。

适用场景：在没有多线程竞争 IO 少量线程竞争的前提下，使用轻量级锁会减少系统在用户态和内核态之间的转换，提高性能。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428154904.awebp" alt="img" style="zoom: 50%;" />

### 重量级锁

重量级锁是依赖对象内部的 `monitor `锁来实现的，而 `monitor `又依赖操作系统的 `MutexLock`（互斥锁）来实现，所以重量级锁也称为互斥锁。

重量级锁需要阻塞线程，唤醒线程，释放锁，消耗资源很大。

// TODO 补充AQS数据结构+实际使用场景+源码分析

## AQS

`AQS` 是多线程同步器，它是 `JUC` 包中多个组件的底层实现，如 `Lock、 CountDownLatch、Semaphore `等都用到了 `AQS`.

从本质上来说，`AQS` 提供了两种锁机制，分别是 排它锁 和 共享锁。 排它锁，就是存在多线程竞争同一共享资源时，同一时刻只允许一个线程访问该共享资源，也就是多个线程中只能有一个线程获得锁资源，比如 `Lock` 中的 `ReentrantLock` 重入锁实现就是用到了 `AQS` 中的排它锁功能。 共享锁也称为读锁，就是在同一时刻允许多个线程同时获得锁资源，比如 `CountDownLatch` 和 `Semaphore` 都是用到了 `AQS` 中的共享锁功能。

1. `AQS` 在内部定义了一个 `volatile int state` 变量，表示同步状态:当线程调用 `lock` 方法时 ，如果 `state=0`，说明没有任何线程占有共享资源的锁，可以获得锁并将 `state=1`;如果 `state=1`，则说明有线程目前正在 使用共享变量，其他线程必须加入同步队列进行等待。
2. `AQS` 通过 `Node` 内部类构成的一个双向链表结构的同步队列，来完成线程获取锁的排队工作，当有线程获取锁失败后，就被添加到队列末尾。`Node` 类是对要访问同步代码的线程的封装，包含了线程本身及其状态叫`waitStatus`(有五种不同 取值，分别表示是否被阻塞，是否等待唤醒， 是否已经被取消等)，每个 `Node` 结点关联其 `prev` 结点和 `next` 结 点，方便线程释放锁后快速唤醒下一个在等待的线程，是一个 `FIFO` 的过 程。`Node` 类有两个常量，`SHARED` 和 `EXCLUSIVE`，分别代表共享模式和独占模式。所谓共享模式是一个锁允许多条线程同时操作(信号量`Semaphore` 就是基于 `AQS` 的共享模式实现的)，独占模式是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待 ( 如 `ReentranLock`) 。
3. `AQS` 通过内部类 `ConditionObject` 构建等待队列(可有多个)，当`Condition` 调用 `wait()` 方法后，线程将会加入等待队列中，而当`Condition` 调用 `signal()` 方法后，线程将从等待队列转移动同步队列中进行锁竞争。
4. `AQS` 和 `Condition` 各自维护了不同的队列，在使用 `Lock` 和`Condition` 的时候，其实就是两个队列的互相移动。

# 8. JVM

## Java内存模型

Java内存模型，是Java虚拟机规范中所定义的一种内存模型，Java内存模型是标准化的，屏蔽掉了底层不同计算机的区别。 Java内存模型是一套规范，描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量存储到内存和从内存中读取变量这样的底层细节，根据官方的解释，主要是在说两个关键字，一个是`volatile`，一个是`synchronized`。

<font color='Apricot'>主内存</font>：主内存是所有线程都共享的，都能访问的。所有的共享变量都存储于主内存。

<font color='Apricot'>工作内存</font>：每一个线程有自己的工作内存，工作内存只存储该线程对共享变量的副本。线程对变量的所有的操 作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量，不同线程之间也不能直接访问对方工作内存中的变量。Java的线程不能直接在主内存中操作共享变量。而是首先将主内存中的共享变量赋值到自己的工作内存中，再进行操作，操作完成之后，刷回主内存。

<font color='Apricot'>Java内存模型的作用</font>：Java内存模型是一套在多线程读写共享数据时，对共享数据的可见性、有序性、和原子性的规则和保障。 synchronized,volatile



<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428162220.jpg" alt="img" style="zoom:67%;" />

## Java内存结构

- <font color='Magenta'>堆：</font>线程共享。所有的对象实例以及数组都要在堆上分配。是垃圾回收的主要操作区域。

  - 从结构上来分，可以分为新生代(`1/3`)和老年代(`2/3`)。而新生代又可以分为Eden 空间(`8/10`)、From Survivor 空间（`1/10`）、To Survivor 空间（`1/10`）。 所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。
  - Java 虚拟机规范规定，堆可以处于物理上不连续的内存空间，只要逻辑上连续即可。在实现时，即可实现成固定大小也可以是可扩展的，当前主流虚拟机都是按照可扩展来实现的
  - 控制参数：`-Xms`设置堆的最小空间大小。`-Xmx`设置堆的最大空间大小。`-XX:NewSize`设置新生代最小空间大小。`-XX:MaxNewSize`设置新生代最大空间大小。

  - 异常情况：
    - 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出`OutOfMemoryError `异常

- <font color='Magenta'>方法区：</font>线程共享。主要存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

  - Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择<font color='Peach'>不实现垃圾收集</font>。相对而言垃圾收集在此区域较少出现，但并非数据进了方法区就永久存在了。这个区域的垃圾回收目标主要是针对常量池的回收和对类型的卸载。
  - 运行时常量池是方法区的一部分，用于存放编译期生成的各种字面常量和符号引用
  - 控制参数：`-XX:PermSize` 设置最小空间 `-XX:MaxPermSize` 设置最大空间。

  - 异常情况： 当方法区无法满足内存分配需求时，将抛出`OutOfMemoryError`。

- <font color='Magenta'>Java 虚拟机栈：</font>线程私有，生命周期与线程相同。虚拟机栈描述的是 `Java` 方法执行的内存模型，每个方法在执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法返回地址等信息，每个方法从被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

  - 控制参数：`-Xss`控制每个线程栈的大小。

  - 异常情况：
    - `- StackOverflowError`： 异常线程请求的栈深度大于虚拟机所允许的深度时抛出；
    - `- OutOfMemoryError` ： 虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出。

- <font color='Magenta'>本地方法栈：</font>线程私有。与`Java` 虚拟机栈作用相似（包括控制参数和异常情况），`Java` 虚拟机栈是为 `Java` 方法服务，本地方法栈为虚拟机使用到的`Native` 方法服务。如 Java 使用 `c` 或者 `c++` 编写的接口服务时，代码在此区运行。

- <font color='Magenta'>程序计数器：</font>线程私有。它可以看作是当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。如果执行的是方法，这里记录的是虚拟机字节码指令的地址，当执行 `Native` 方法的时候为空（`Undefined`）。因为只存储一个指令，所以它也是唯一一个在 `Java` 虚拟机规范中没有规定任何`OutOfMemory Error`情况的区域。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428162439.jpg" alt="img" style="zoom:67%;" />

## 常见内存溢出错误

```text
Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space
```

原因：对象不能被分配到堆内存中。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space
```

原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit
```

原因：创建的数组大于堆内存的空间。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: request <size> bytes for <reason>. Out of swap space?
```

原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: <reason> <stack trace>（Native method）
```

原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现。

## 堆的划分

1、堆结构分代的意义

　　Java虚拟机根据对象存活的周期不同，把堆内存划分为几块，一般分为新生代、老年代和永久代（对HotSpot虚拟机而言），这就是JVM的内存分代策略。

　　堆内存是虚拟机管理的内存中最大的一块，也是垃圾回收最频繁的一块区域，我们程序所有的对象实例都存放在堆内存中。给堆内存分代是为了提高对象内存分配和垃圾回收的效率。试想一下，如果堆内存没有区域划分，所有的新创建的对象和生命周期很长的对象放在一起，随着程序的执行，堆内存需要频繁进行垃圾收集，而每次回收都要遍历所有的对象，遍历这些对象所花费的时间代价是巨大的，会严重影响我们的GC效率。

　　有了内存分代，情况就不同了，新创建的对象会在新生代中分配内存，经过多次回收仍然存活下来的对象存放在老年代中，静态属性、类信息等存放在永久代中，新生代中的对象存活时间短，只需要在新生代区域中频繁进行GC，老年代中对象生命周期长，内存回收的频率相对较低，不需要频繁进行回收，永久代中回收效果太差，一般不进行垃圾回收，还可以根据不同年代的特点采用合适的垃圾收集算法。分代收集大大提升了收集效率，这些都是内存分代带来的好处。

2、堆结构分代

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428163721.jpg" alt="img" style="zoom:50%;" />

　　Java虚拟机将堆内存划分为新生代、老年代和永久代，永久代是`HotSpot`虚拟机特有的概念（`JDK1.8`之后为`metaspace`替代永久代），它采用永久代的方式来实现方法区，其他的虚拟机实现没有这一概念，而且`HotSpot`也有取消永久代的趋势，在`JDK 1.7`中`HotSpot`已经开始了“去永久化”，把原本放在永久代的字符串常量池移出。永久代主要存放常量、类信息、静态变量等数据，与垃圾回收关系不大，新生代和老年代是垃圾回收的主要区域。

3、新生代（Young Generation）

新生成的对象优先存放在新生代中，新生代对象朝生夕死，存活率很低，在新生代中，常规应用进行一次垃圾收集一般可以回收`70% ~ 95%` 的空间，回收效率很高。

`HotSpot`将新生代划分为三块，一块较大的Eden（伊甸）空间和两块较小的Survivor（幸存者）空间，默认比例为`8：1：1`。划分的目的是因为`HotSpot`采用复制算法来回收新生代，设置这个比例是为了充分利用内存空间，减少浪费。新生成的对象在`Eden`区分配（大对象除外，大对象直接进入老年代），当`Eden`区没有足够的空间进行分配时，虚拟机将发起一次`Minor GC`。

　　GC开始时，对象只会存在于`Eden`区和`From Survivor`区，`To Survivor`区是空的（作为保留区域）。GC进行时，`Eden`区中所有存活的对象都会被复制到`To Survivor`区，而在`From Survivor`区中，仍存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阀值（默认为15，新生代中的对象每熬过一轮垃圾回收，年龄值就加1，GC分代年龄存储在对象的`header`中）的对象会被移到老年代中，没有达到阀值的对象会被复制到`To Survivor`区。接着清空`Eden`区和`From Survivor`区，新生代中存活的对象都在`To Survivor`区。接着， `From Survivor`区和`To Survivor`区会交换它们的角色，也就是新的`To Survivor`区就是上次`GC`清空的`From Survivor`区，新的`From Survivor`区就是上次`GC`的`To Survivor`区，总之，不管怎样都会保证`To Survivor`区在一轮`GC`后是空的。`GC`时当`To Survivor`区没有足够的空间存放上一次新生代收集下来的存活对象时，需要依赖老年代进行分配担保，将这些对象存放在老年代中。

4、老年代（Old Generationn）

　　在新生代中经历了多次（具体看虚拟机配置的阀值）GC后仍然存活下来的对象会进入老年代中。老年代中的对象生命周期较长，存活率比较高，在老年代中进行GC的频率相对而言较低，而且回收的速度也比较慢。

5、永久代（Permanent Generationn）

　　永久代存储类信息、常量、静态变量、即时编译器编译后的代码等数据，对这一区域而言，Java虚拟机规范指出可以不进行垃圾收集，一般而言不会进行垃圾回收。

## 永久代和方法区

1、方法区

　　方法区（Method Area）是`jvm`规范里面的运行时数据区的一个组成部分，`jvm`规范中的运行时数据区还包含了：pc寄存器、虚拟机栈、堆、方法区、运行时常量池、本地方法栈。主要用来存储`class`、运行时常量池、字段、方法、代码、`JIT`代码等。运行时数据区跟内存不是一个概念，方法区是运行时数据区的一部分。方法区是`jvm`规范中的一部分，并不是实际的实现，切忌将规范跟实现混为一谈。

2、永久代

　　永久带又叫`Perm`区，只存在于`hotspot jvm`中，并且只存在于`jdk7`和之前的版本中，`jdk8`中已经彻底移除了永久带，`jdk8`中引入了一个新的内存区域叫`metaspace`。并不是所有的`jvm`中都有永久带，`ibm`的`j9`，`oracle`的`JRocket`都没有永久带，永久带是实现层面的东西，永久带里面存的东西基本上就是方法区规定的那些东西。

3、区别

　　方法区是规范层面的东西，规定了这一个区域要存放哪些东西，永久带或者是`metaspace`是对方法区的不同实现，是实现层面的东西。

4、`hotspot jdk8`中移除了永久带以后的内存结构

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162939.jpg" alt="img" style="zoom:50%;" />

// TODO 分别补充G1&CMS内存区别

## 类加载过程

Java类加载过程是Java虚拟机（JVM）将.class文件中的字节码装载到内存中，分为五个部分：加载，检验，准备，解析，初始化，在类加载的过程中，这些阶段会互相混合，交叉运行，最终完成类的加载和初始化。

> 例如在加载阶段，需要使用验证的能力去校验字节码正确性。在解析阶段，也要使用验证的能力去校验符号引用的正确性。或者加载阶段生成Class对象的时候，需要解析阶段符号引用转直接引用的能力等等......

1. <font color='RedOrange'>加载阶段</font>

   > 这个过程主要由加载器完成三件事情：
   >
   > 1. 通过类的全限定名来获取定义此类的二进制字节流
   > 2. 将这个类字节流代表的静态存储结构转为方法区的运行时数据结构
   > 3. 在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。
   >
   > Java虚拟机并没有规定类的字节流必从.class文件中加载，在加载阶段，程序员可以通过自定义的类加载器，自行定义读取的地方，例如通过网络、数据库等。

2. <font color='RedOrange'>检验阶段</font>

   > 此阶段主要确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机的自身安全。
   >
   > 1. 文件格式验证：基于字节流验证。
   > 2. 元数据验证：基于方法区的存储结构验证。
   > 3. 字节码验证：基于方法区的存储结构验证。
   > 4. 符号引用验证：基于方法区的存储结构验证。

3. <font color='RedOrange'>准备阶段</font>

   > 为类变量分配内存，并将其初始化为默认值。（此时为默认值，在初始化的时候才会给变量赋值）即在方法区中分配这些变量所使用的内存空间。例如：
   >
   > ```csharp
   > public static int value = 123;
   > ```
   >
   > 此时在准备阶段过后的初始值为0而不是123；将value赋值为123的putstatic指令是程序被编译后，存放于类构造器<client>方法之中.特例：
   >
   > ```java
   > public static final int value = 123;
   > ```
   >
   > 此时value的值在准备阶段过后就是123。

4. <font color='RedOrange'>解析阶段</font>

   > 把类型中的符号引用转换为直接引用。
   >
   > - 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。
   > - 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在
   >
   > 主要有以下四种：
   >
   > 1. 类或接口的解析
   > 2. 字段解析
   > 3. 类方法解析
   > 4. 接口方法解析

5. <font color='RedOrange'>初始化阶段</font>

   > 初始化阶段是执行类构造器<client>方法的过程。<client>方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证<client>方法执行之前，父类的<client>方法已经执行完毕。如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成<client>()方法。
   >
   > Java 中，对于初始化阶段，有且只有以下五种情况才会对要求类立刻“初始化”（加载，验证，准备，自然需要在此之前开始）：
   >
   > 1. 使用new关键字实例化对象、访问或者设置一个类的静态字段（被final修饰、编译器优化时已经放入常量池的例外）、调用类方法，都会初始化该静态字段或者静态方法所在的类。
   > 2. 初始化类的时候，如果其父类没有被初始化过，则要先触发其父类初始化。
   > 3. 使用java.lang.reflect包的方法进行反射调用的时候，如果类没有被初始化，则要先初始化。
   > 4. 虚拟机启动时，用户会先初始化要执行的主类（含有main）
   > 5. jdk 1.7后，如果java.lang.invoke.MethodHandle的实例最后对应的解析结果是 REF_getStatic、REF_putStatic、REF_invokeStatic方法句柄，并且这个方法所在类没有初始化，则先初始化。

**类加载器**

> 把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作交给虚拟机之外的类加载器来完成。这样的好处在于，我们可以自行实现类加载器来加载其他格式的类，只要是二进制字节流就行，这就大大增强了加载器灵活性。系统自带的类加载器分为三种：
>
> 1. 启动类加载器。
> 2. 扩展类加载器。
> 3. 应用程序类加载器。

### 双亲委派机制

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202401081536600" alt="img" style="zoom: 50%;" />

双亲委派机制工作过程：

> <font color='RedOrange'>工作过程</font>：如果一个类加载器收到了类加载的请求，它首先会将这个任务委派给父加载器去完成，每个层次的类加载器都是如此。因此所有的加载请求最终都会传送到Bootstrap类加载器(启动类加载器)中。只有父类加载反馈自己无法加载这个请求(它的搜索范围中没有找到所需的类)时。子加载器才会尝试自己去加载。
>
> <font color='RedOrange'>优点</font>：<font color='Peach'>使用双亲委派模式，可以保证，每一个类只会有一个类加载器</font>。
>
> <font color='RedOrange'>注意</font>：不同的类加载器，加载同一个类，结果是虚拟机里会存在两份这个类的信息，所以当判断这两个类是否“相等”时，必定是不相等的。
>
> <font color='RedOrange'>举例</font>：例如类java.lang.Object，它存放在`rt.jart`之中。无论哪一个类加载器都要加载这个类。最终都是双亲委派模型最顶端的Bootstrap类加载器去加载。因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户编写了一个称为“java.lang.Object”的类，并存放在程序的ClassPath中，那系统中将会出现多个不同的Object类，java类型体系中最基础的行为也就无法保证，应用程序也将会一片混乱。

## 垃圾回收算法

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202401081446835.png" alt="img" style="zoom: 40%;" />

**1. 标记-清除算法**：

- 标志清除算法有两个阶段：

  > 1. 标记阶段：找到所有可访问的对象，做个标记
  > 2. 清除阶段：遍历堆，把未被标记的对象回收

- 应用场景：

  一般应用于老年代,因为老年代的对象生命周期比较长

- 优缺点:

  > 优点:
  >
  > 1. 可以解决循环引用的问题
  > 2. 内存不足时才回收
  >
  > 缺点：
  >
  > 1. 回收时，应用需要挂起。
  > 2. 标记和清除的效率不高，尤其是要扫描的对象比较多的时候
  > 3. 会造成内存碎片(会导致明明有内存空间,但是由于不连续,申请稍微大一些的对象无法做到)

**2. 复制算法**：

- 一开始就会将可用内存分为两块，from域和to域， 每次只是使用from域，to域空闲。当from域内存不够开始执行GC操作时，会把from域存活的对象拷贝到to域然后直接对from域进行内存清理。

- 应用场景：一般是使用在**新生代**中，因为新生代中的对象一般都是朝生夕死的，存活对象的数量并不多，这样使用coping算法进行拷贝时效率比较高。

  > JVM 将 Heap 内存划分为新生代与老年代，又将新生代划分为Eden(伊甸园) 与2块Survivor Space(幸存者区) ,然后在Eden –>Survivor Space 以及From Survivor Space 与To Survivor Space 之间实行Copying 算法。
  >
  > 不过jvm在应用coping算法时，并不是把内存按照1:1来划分的，这样太浪费内存空间了。一般的jvm都是8:1。也即是说:
  >
  > ```
  > Eden区:From区:To区域 = 8:1:1
  > ```
  >
  > 始终有90%的空间是可以用来创建对象的,而剩下的10%用来存放回收后存活的对象。

  ![image-20240108143122702](https://gitee.com/qc_faith/picture/raw/master/image/202401081431883.png)

- 图中流程解析：

  > 1.当Eden区满的时候，会触发第一次young gc，把还活着的对象拷贝到Survivor From区；当Eden区再次触发young gc的时候，会扫描Eden区和From区域，对两个区域进行垃圾回收，经过这次回收后还存活的对象，则直接复制到To区域，并将Eden和From区域清空。
  >
  > 2.当后续Eden又发生young gc的时候，会对Eden和To区域进行垃圾回收，存活的对象复制到From区域，并将Eden和To区域清空。
  >
  > 3.可见部分对象会在From和To区域中复制来复制去，如此交换15次(由JVM参数MaxTenuringThreshold决定，这个参数默认是15)，最终如果还是存活，就存入到老年代

- 注意: 万一存活对象数量比较多，那么To域的内存可能不够存放，这个时候会借助老年代的空间。

- 优缺点：

  > 优点：在存活对象不多的情况下，性能高，能解决内存碎片和java垃圾回收算法 - 标记清除 中导致的引用更新问题。
  >
  > 缺点：会造成一部分的内存浪费。不过可以根据实际情况，将内存块大小比例适当调整；如果存活对象的数量比较大，coping的性能会变得很差。

**3. 标记-压缩（整理）算法**：

- 标记压缩算法 和 标记清除算法非常相似，但是标记压缩算法 在 标记清除算法 之上解决了内存碎片化。

- 压缩算法压缩对象的顺序主要分为如下几类：

  > - 任意顺序 : 即不考虑原先对象的排列顺序，也不考虑对象之间的引用关系，随意移动对象；
  > - 线性顺序 : 考虑对象的引用关系，例如a对象引用了b对象，则尽可能将a和b移动到一块；
  > - 滑动顺序 : 按照对象原来在堆中的顺序滑动到堆的一端。

- 优点是解决内存碎片问题。缺点是压缩阶段由于移动了可用对象，需要去更新引用。

**4. 分代算法**：

- 这种算法，根据对象的存活周期的不同将内存划分成几块，新生代和老年代，<font color='Peach'>新生代基本采用复制算法，老年代采用标记整理算法</font>。

  > **新生代** ：在新生代，每次垃圾收集器都发现有大批对象死去，只有少量存活，采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集；
  >
  > **老年代** ：而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须“标记－清除－压缩”算法进行回收。新创建的对象被分配在新生代，如果对象经过几次回收后仍然存活，那么就把这个对象划分到老年代。老年代区存放Young区Survivor满后触发minor GC后仍然存活的对象，当Eden区满后会将存活的对象放入Survivor区域，如果Survivor区存不下这些对象，GC收集器就会将这些对象直接存放到Old区中，如果Survivor区中的对象足够老，也直接存放到Old区中。如果Old区满了，将会触发Full GC回收整个堆内存。

### Minor GC 和Full GC

新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。

老年代 GC（Major GC/Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC慢10倍以上。

Minor GC触发机制：

> 当年轻代满时就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发

GCFull GC触发机制:

> 当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代，当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载其中

虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁）时，就会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold (阈值)来设置。

## CMS收集器

CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，基于并发“标记清理”实现，在标记清理过程中不会导致用户线程无法定位引用对象。仅作用于老年代收集。分为以下四个流程：

1. 初始标记（CMS initial mark <font color='Apricot'>STW</font>）：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。
2. 并发标记（CMS concurrent mark）：对「初始标记阶段」标记的对象进行整个引用链的扫描，它在整个回收过程中耗时最长，可能发生漏标。不需要停顿。
3. 重新标记（CMS remark <font color='Apricot'>STW</font>）：对「并发标记」阶段出现的问题进行校正，需要停顿。
4. 并发清理（CMS concurrent sweep）：可以和用户线程并发执行，清理在重复标记中被标记为可回收的对象。不需要停顿。

### CMS的优点：

- 支持并发收集.
- 低停顿，因为`CMS`可以控制将耗时的两个`stop-the-world`操作保持与用户线程恰当的时机并发执行，并且能保证在短时间执行完成，这样就达到了近似并发的目的.

### CMS的缺点：

- 吞吐量低: 低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。
- 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。
- 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。

### 使用场景

它关注的是垃圾回收最短的停顿时间（低停顿），在老年代并不频繁GC的场景下，是比较适用的。

## G1收集器

堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。G1 把堆划分成多个大小相等的独立区域(Region)，新生代和老年代不再物理隔离。通过引入 Region 的概念，将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。通过记录每个 Region 垃圾回收时间以及回收所获得的空间(这两个值是通过过去回收的经验获得)，并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。

<font color='Apricot'>G1 回收流程：</font>

1. 初始标记（Initial Marking <font color='RedOrange'>STW</font>）：所有应用线程会被暂停，标记出从 GC Root 开始直接可达的对象。

   > 标记一下`GC Roots`能直接关联到的对象，伴随着一次普通的`Young GC`发生，并修改`NTAMS`（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，此阶段是`stop-the-world`操作，但是耗时很短，而且是借用进行 Minor GC 的时候同步完成的，所以在这个阶段实际并没有额外的停顿。

2. 并发标记（Concurrent Marking）：是从`GC Roots`开始堆中对象进行可达性分析，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行，该阶段可以被`Young GC`中断。

3. 最终标记（Final Marking <font color='RedOrange'>STW</font>）：标记那些在并发标记阶段发生变化的对象，将被回收。

   > 是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程`Remembered Set Logs`里面，最终标记阶段需要把`Remembered Set Logs`的数据合并到`Remembered Set`中。这阶段需要停顿线程，但是可并行执行。

4. 筛选回收（Live Data Counting and Evacuation <font color='RedOrange'>STW</font>）：对各个 Region 的回收价值和成本进行排序，根据用户所期待的 GC 停顿时间来指定回收计划，可以自由选择多个 Region 构成回收集，然后把决定回收的那一部分 Region 的存活对象复制到空的 Region 中，再清理掉整个旧 Region 的全部空间。这里的操作涉及存活对象的移动，必须暂停用户线程，由多条收集器线程并行完成

### G1 的 GC 模式

G1 中提供了 <font color='Peach'>Young GC</font>、<font color='Peach'>Mixed GC</font> 两种垃圾回收模式，这两种垃圾回收模式，都是 Stop The World(STW) 的。

1. <font color='Apricot'>YoungGC 年轻代收集</font>

   > 在分配一般对象（非巨型对象）时，当所有 eden region 使用达到最大阀值、并且无法申请足够内存时，会触发一次 YoungGC 。
   >
   > 每次 younggc 会回收所有 Eden 、以及 Survivor 区，并且将存活对象复制到 Old 区以及另一部分的 Survivor 区。
   >
   > <font color='Magenta'>YoungGC 的回收过程</font>：
   >
   > - 根扫描，跟 CMS 类似，Stop the world，扫描 GC Roots 对象；
   > - 处理 Dirty card，更新 RSet；
   > - 扫描 RSet ，扫描 RSet 中所有 old 区，对扫描到的 young 区或者 survivor 区的引用；
   > - 拷贝扫描出的存活的对象到 survivor2/old 区；
   > - 处理引用队列、软引用、弱引用、虚引用。

2. <font color='RedOrange'>Mixed GC</font>

   > 当越来越多的对象晋升到老年代 old region 时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 mixed gc ，该算法并不是一个 old gc ，除了回收整个 young region ，还会回收一部分的 old region 。
   >
   > 这里需要注意：是一部分老年代，而不是全部老年代，可以选择哪些 old region 进行收集，从而可以对垃圾回收的耗时时间进行控制。
   >
   > G1 没有 fullGC 概念，需要 fullGC 时，调用 serialOldGC 进行全堆扫描（包括 eden、survivor、o、perm）。

### G1的特点

- 算法： G1 基于标记--整理算法，不会产生空间碎片，在分配大对象时，不会因无法得到连续的空间，而提前触发一次 FULL GC 。
- 并行与并发：G1充分发挥多核性能，使用多CPU来缩短Stop-The-world的时间，
- 分代收集：G1能够自己管理不同分代内已创建对象和新对象的收集。
- 停顿时间可控： G1 可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象。

### 使用场景

- 实时数据占用超过一半的堆空间
- 对象分配或者晋升的速度变化大
- 希望消除长时间的GC停顿（超过0.5-1秒）



## 四种引用类型

JVM 垃圾回收中，GC判断堆中的对象实例或数据是不是垃圾的方法有 <font color='Apricot'>引用计数法</font> 和 <font color='Apricot'>可达性算法</font> 两种。

**引用计数器法**：为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。缺点是不能解决循环引用的问题。

**可达性分析算法**：从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是可以被回收的。

无论是通过引用计数算法判断对象的引用数量，还是通过根搜索算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。

- 强引用（Strong Reference）：一个对象通过一串强引用链接可到达，即使内存不足抛出OutOfMemoryError，也不会回收该对象。
- 软引用（Soft Reference）：对于一些非必须，但仍有用的对象，内存不足时，系统会回收软引用对象
- 弱引用（Weak Reference）：随时可能被垃圾回收器回收，无论内存是否足够，只要JVM开始进行垃圾回收，被弱引用关联的对象都会被回收。
- 虚引用（Phantom Reference）：所有引用类最脆弱的一个，如果一个对象持有虚引用，那么这个对象随时可能被回收，甚至不能通过get方法来获得其指向的对象。虚引用唯一的作用是，当其指向的对象被回收后，自己被加入到引用队列，用做记录该引用指向的对象已被销毁。

这四种引用强度依次逐渐减弱。

Java 中引入四种引用的目的是让程序自己决定对象的生命周期，JVM 是通过垃圾回收器对这四种引用做不同的处理，来实现对象生命周期的改变。

<font color='RedOrange'>强引用</font>

> 最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。类似 `“Object obj = new Object()”` 这类的引用。
>
> 当一个对象被强引用变量引用时，它处于可达状态，是不可能被垃圾回收器回收的，即使该对象永远不会被用到也不会被回收。
>
> 当内存不足，JVM 开始垃圾回收，对于强引用的对象，就算是出现了 OOM 也不会对该对象进行回收。因此强引用有时也是造成 Java 内存泄露的原因之一。
>
> 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，一般认为就是可以被垃圾收集器回收。（具体回收时机还要要看垃圾收集策略）。

<font color='RedOrange'>软引用</font>

> 软引用是一种相对强引用弱化了一些的引用，需要用`java.lang.ref.SoftReference` 类来实现，可以让对象豁免一些垃圾收集。
>
> 软引用用来描述一些还有用，但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。
>
> 对于只有软引用的对象来说：<font color='Peach'>当系统内存充足时它不会被回收，当系统内存不足时它才会被回收</font>。

<font color='RedOrange'>弱引用</font>

> 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。
>
> 弱引用需要用`java.lang.ref.WeakReference`类来实现，它比软引用的生存期更短。
>
> 对于只有弱引用的对象来说，<font color='Peach'>只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，都会回收该对象占用的内存</font>。

<font color='RedOrange'>虚引用</font>

> 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。
>
> 虚引用，顾名思义，就是形同虚设，与其他几种引用都不太一样，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。
>
> 虚引用需要`java.lang.ref.PhantomReference` 来实现。
>
> 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，它不能单独使用也不能通过它访问对象，虚引用必须和引用队列（RefenenceQueue）联合使用。
>
> 虚引用的主要作用是跟踪对象垃圾回收的状态。仅仅是提供了一种确保对象被 `finalize` 以后，做某些事情的机制。
>
> `PhantomReference` 的 `get` 方法总是返回 null，因此无法访问对应的引用对象。其意义在于说明一个对象已经进入 `finalization` 阶段，可以被 GC 回收，用来实现比 `finalization` 机制更灵活的回收操作。
>
> 换句话说，<font color='Peach'>设置虚引用的唯一目的，就是在这个对象被回收器回收的时候收到一个系统通知或者后续添加进一步的处理</font>。
>
> Java 允许使用 `finalize()` 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。

<font color='RedOrange'>引用队列</font>

> `ReferenceQueue` 是用来配合引用工作的，没有`ReferenceQueue` 一样可以运行。
>
> `SoftReference`、`WeakReference`、`PhantomReference` 都有一个可以传递 `ReferenceQueue` 的构造器。
>
> 创建引用的时候，可以指定关联的队列，当 GC 释放对象内存的时候，会将引用加入到引用队列。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动，这相当于是一种通知机制。
>
> 当关联的引用队列中有数据的时候，意味着指向的堆内存中的对象被回收。通过这种方式，JVM 允许我们在对象被销毁后，做一些我们自己想做的事情

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202401081341680.jpeg" alt="img" style="zoom:50%;" />

## 卡表（Card Table）

有个场景，老年代的对象可能引用新生代的对象，由于新生代的垃圾收集通常很频繁，那标记存活对象的时候，需要扫描从老年代到新生代的所有引用对象。因为该对象拥有对新生代对象的引用，那么这个引用也会被称为`GC Roots`。那不是每次`YGC`时又得做全堆扫描？显然不是，对于`HotSpot JVM`，使用了*卡标记（Card Marking）*技术来解决老年代到新生代的引用问题。具体是，使用卡表（Card Table）和写屏障（Write Barrier）来进行标记并加快对`GC Roots`的扫描。卡表的设计师将堆内存平均分成  2的N次方大小（默认512字节）个卡，并且维护一个卡表，用来储存每个卡的标识位。当对一个对象引用进行写操作时（对象引用改变），写屏障逻辑将会标记对象所在的卡页为脏页。在`YGC`只需要扫描卡表中的脏卡，将脏中的对象加入到`YGC`的`GC Roots`里面。当完成所有脏卡扫描时候，虚拟机会将卡表的脏卡标志位清空。

> 在高并发环境下，每次对引用的更新，无论是否更新了老年代对新生代对象的引用，都会进行一次写屏障操作，频繁的写屏障很容易发生虚共享(false sharing),从而带来性能开销。举 个例子：假设CPU缓存行大小为64字节，由于一个卡表项占1个字节，这意味着，64个卡表项将共享同一个缓存行。`HotSpot`每个卡页为512字节，那么一个缓存行将对应64个卡页一共 64*512=32KB。如果不同线程对对象引用的更新操作，恰好位于同一个32KB区域内，这将导致同时更新卡表的同一个缓存行，从而造成缓存行的写回、无效化或者同步操作，间接影响程序 性能。

在`JDK 7`中引入了VM参数`-XX:+UseCondCardMark` ，意思就是现在不采用无条件写屏障，而是先检查此卡是否已经是脏页，如果是将不再标记。这样就减少了并发下的虚共享问题。但是这样却不能避免对未标记的页进行并发标记。



## 新生代晋升老年代

对象优先在`Eden`分配，且新生代对象晋升到老年代有多种情况，

1. 分配担保。
   `Eden`区满时，进行`Minor GC`，当`Eden`和一个`Survivor`区中依然存活的对象无法放入到`Survivor`中，则通过分配担保机制提前转移到老年代中。

2. 大对象直接进入年老代

   - 大对象即需要大量连续内存空间的`Java`对象，如长字符串及数组。经常出现大对象导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来安置他们。 

   - 虚拟机提供了一个`-XX：PretenureSizeThreshold`参数，令大于这个设置值的对象直接在老年代分配。 这样做的目的是避免在`Eden`区及两个`Survivor`区之间发生大量的内存复制（新生代采用复制算法收集内存）。

3. 长期存活的对象将进入老年代。
   虚拟机给每个对象定义了一个对象年龄计数器，在对象在`Eden`创建并经过第一次`Minor GC`后仍然存活，并能被`Suivivor`容纳的话，将会被移动到`Survivor`空间，并对象年龄设置为1。每经历过`Minor GC`，年龄就增加1岁，当到一定程度（默认15岁，可以通过参数`-XXMaxTenuringThreshold`设置），就将会晋升年老代。

4. 动态对象年龄判定。
   虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升到老年代，如果在`Survivor`区中相同年龄（设年龄为`age`）的对象的所有大小之和超过`Survivor`空间的一半，年龄大于或等于该年龄（`age`）的对象就可以直接进入老年代，无需等到`MaxTenuringThreshold`中要求的年龄。



// TODO 补充G1&CMS参数优化  （注重高并发如何优化，大量计算情况下如何优化）

## CMS参数优化 

1. <span style="background:#f9eda6;">-XX:+UseConcMarkSweepGC</span>

   > CMS全称 `Concurrent Mark Sweep`，是一款并发的、使用标记-清除算法的垃圾回收器，
   > 如果老年代使用CMS垃圾回收器，需要添加虚拟机参数-"XX:+UseConcMarkSweepGC"。

2. <span style="background:#f9eda6;">- XX:CMSInitiatingOccupancyFraction =n</span>

   > CMS的另一个缺点是它需要更大的堆空间。因为CMS标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在CMS回 收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。也就是说，CMS不会在老年代满的时候才开始收集。相反，它会尝试更早的开始收集，已 避免上面提到的情况：在回收完成之前，堆没有足够空间分配！默认当老年代使用68%的时候，CMS就开始行动了。 
   >
   > `– XX:CMSInitiatingOccupancyFraction =n` 来设置这个阀值。

3. <span style="background:#f9eda6;">Old GC触发条件</span>

   > 周期性`Old GC`，执行的逻辑也叫`Background Collect`，对老年代进行回收，在GC日志中比较常见，由后台线程`ConcurrentMarkSweepThread`循环判断（默认2s）是否需要触发。
   >
   > 触发条件
   >
   > 1、如果没有设置`-XX:+UseCMSInitiatingOccupancyOnly`，虚拟机会根据收集的数据决定是否触发（建议线上环境带上这个参数，不然会加大问题排查的难度）。
   > 2、老年代使用率达到阈值 `CMSInitiatingOccupancyFraction`，默认92%。
   > 3、永久代的使用率达到阈值 `CMSInitiatingPermOccupancyFraction`，默认92%，前提是开启 `CMSClassUnloadingEnabled`。
   > 4、新生代的晋升担保失败。
   >
   > `CMS GC`要决定是否在`full GC`时做压缩，会依赖几个条件。其中: 
   >
   > 1. 第一种条件，`UseCMSCompactAtFullCollection `与 `CMSFullGCsBeforeCompaction `是搭配使用的；前者目前默认就是`true`了，也就是关键在后者上。 
   > 2. 第二种条件是用户调用了`System.gc()`，而且`DisableExplicitGC`没有开启。 
   > 3. 第三种条件是`young gen`报告接下来如果做增量收集会失败；简单来说也就是`young gen`预计`old gen`没有足够空间来容纳下次`young GC`晋升的对象。 
   > 4. 上述三种条件的任意一种成立都会让`CMS`决定这次做`full GC`时要做压缩。 

   > 1. `CMSFullGCsBeforeCompaction `说的是，在上一次`CMS`并发`GC`执行过后，到底还要再执行多少次`full GC`才会做压缩。默认是`0`，也就是在默认配置下每次`CMS GC`顶不住了而要转入`full GC`的时候都会做压缩。 把`CMSFullGCsBeforeCompaction`配置为`10`，就会让上面说的第一个条件变成每隔`10`次真正的`full GC`才做一次压缩（而不是每`10`次`CMS`并发`GC`就做一次压缩，目前VM里没有这样的参数）。这会使`full GC`更少做压缩，也就更容易使`CMS`的`old gen`受碎片化问题的困扰。 本来这个参数就是用来配置降低`full GC`压缩的频率，以期减少某些`full GC`的暂停时间。`CMS`回退到`full GC`时用的算法是`mark-sweep-compact`，但`compaction`是可选的，不做的话碎片化会严重些但这次`full GC`的暂停时间会短些；这是个取舍。
   >
   > 2. `-XX:CMSInitiatingOccupancyFraction=70` 和`-XX:+UseCMSInitiatingOccupancyOnly`
   >
   >    这两个设置一般配合使用,一般用于『降低`CMS GC`频率或者增加频率、减少`GC`时长』的需求
   >
   >    ` -XX:CMSInitiatingOccupancyFraction=70` 是指设定`CMS`在对内存占用率达到`70%`的时候开始`GC`(因为`CMS`会有浮动垃圾,所以一般都较早启动`GC`);
   >
   >     `-XX:+UseCMSInitiatingOccupancyOnly` 只是用设定的回收阈值(上面指定的`70%`),如果不指定，`JVM`仅在第一次使用设定值，后续则自动调整.
   >
   > 3. `-XX:+CMSScavengeBeforeRemark`
   >
   >    在`CMS GC`前启动一次`ygc`，目的在于减少`old gen`对`ygc gen`的引用，降低`remark`时的开销-----一般`CMS`的`GC`耗时 `80%`都在`remark`阶段
   >
   >    `-XX：+UseCMSInitiatingOccupancyOnly`
   >
   >    我们用`-XX+UseCMSInitiatingOccupancyOnly`标志来命令`JVM`不基于运行时收集的数据来启动`CMS`垃圾收集周期。而是，当该标志被开启时，`JVM`通过`CMSInitiatingOccupancyFraction`的值进行每一次`CMS`收集，而不仅仅是第一次。然而，请记住大多数情况下，`JVM`比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。

### CMS优化方向

1. 原则

   - `cms`的的优势就是低延迟，但是如果出现了长时间的`stw`，则对应用程序有很大的影响
   - 如果出现了`concurrent mode failure`和`promotion failed`，代价都非常昂贵，我们调优应该尽量避免这些情况

2. 针对`concurrent mode failure`的优化

   - 发生该失败的主要原因是由于`CMS`不能以足够快的速度清理老年代空间

   - 当老年代空间的占用达到某个阈值时，并发回收就开始了。一个`CMS`后台线程开始扫描老年代空间，寻找无用的垃圾对象时，竞争就开始了。`CMS`收集器必须在老年代剩余的空间用尽之前，完成老年代空间的扫描及回收工作。否则如果在正常速度的比赛中失效，就会发生该错误

   - 在并发清理阶段，用户线程仍然在运行，必须预留出空间给用户线程使用，会产生’浮动垃圾‘

   - 常规优化途径如下：

     > 以更高的频率执行后台的回收线程，即提高`CMS`并发周期发生的频率
     >
     > - 主要是调低`CMSInitiatingOccupancyFraction`的值
     >
     > - 但是不能太低，太低会导致过于频繁的`gc`，会消耗更多的的`cpu`和停顿
     >
     > - `landon`
     >
     >   > 需要先计算老年代常驻内存大小，如占用`60%`，那么这个阈值则可以设置为约`70%`，否则会比较频繁`gc`
     >   >
     >   > 可以考虑担保机制，只要老年代预留剩余空间大于年轻代大小，比如新生代和老年代的比例是1 : 4，即新生代占用老年代的`25%`，那么这个阈值可以设置为`70`，即老年代还预留出来`30%`的空间
     >   >
     >   > > 注意如果浮动垃圾很多的话，也无法解决该问题，即`cms`并发回收期间，浮动垃圾越来越多，占用预留空间，多次的`ygc`的话，会有填满预留空间的可能，虽然概率较低
     >   >
     >   > 两个条件综合考虑，如果设置了阈值70，但是老年代常驻内存很大，甚至超过70，那么此时的建议要提高堆内存，增加老年代的大小或者减少新生代的大小

3. 针对`promotion failed`的优化

   - 这个是`cms`最为严重的’碎片问题‘，我们要尽量避免这个发生后引起的`fgc`

   - 所以优化这个问题，也可以描述为'如何解决碎片问题'

   - 常规优化途径如下

     > - 增大堆内存，增加老年代大小，但要注意不要超过`32g(the HotSpot JVM uses a trick to compress object pointers when heaps are less than around 32 GB)`
     > - 尽早执行`cms gc`，合理设置`CMSInitiatingOccupancyFraction`，会合并老生代中相邻的`free`空间，可分配给较大的对象
     > - 和上面一样，也可以做一个老年代预留空间大于年轻代
     >
     > > 到了阈值后，就会触发`cms gc`，但还是和上面说的，会产生浮动垃圾 + 碎片，还是会出现
     >
     > - 另外一个比较“挫”的办法，是在每天凌晨访问量低的时候，主动执行一下`fgc`，执行一下'碎片压缩'
     > - 如`System.gc`，但是要注意是否开启了`-XX:+ExplicitGCInvokesConcurrent`
     > - 所以建议办法是用`jmap -histo:live`

   - 另外晋升还包括`to space`空间小，可以根据情况尝试提高`Survivor`



## G1参数优化

1. **暂停时间**：

   > 用`-XX:MaxGCPauseMillis`来指定，默认值200ms。这是一个软性目标，G1会尽量达成，如果达不成，会逐渐做自我调整。对于`Young GC`来说，会逐渐减少`Eden`区个数，减少Eden空间那么`Young GC`的处理时间就会相应减少；对于`Mixed GC`，G1会调整每次`Choose Cset`的比例，默认最大值是10%，当然每次选择的`Cset`少了，所要经历的`Mixed GC`的次数会相应增加。同时减少Eden的总空间时，就会更加频繁的触发`Young GC`，也就是会加快Mixed GC的执行频率，因为Mixed GC是由Young GC触发的，或者说借机同时执行的。频繁GC会对对应用的吞吐量造成影响，每次Mixed GC回收时间太短，回收的垃圾量太少，可能最后GC的垃圾清理速度赶不上应用产生的速度，那么可能会造成串行的Full GC，这是要极力避免的。所以暂停时间肯定不是设置的越小越好，当然也不能设置的偏大，转而指望G1自己会尽快的处理，这样可能会导致一次全部并发标记后触发的Mixed GC次数变少，但每次的时间变长，STW时间变长，对应用的影响更加明显。

2. **Region大小**：

   > 用`-XX:G1HeapRegionSize`来指定，若未指定则默认最多生成2048块，每块的大小需要为2的幂次方，如1,2,4,8,16,32，最大值为32M。Region的大小主要是关系到Humongous Object的判定，当一个对象超过Region大小的一半时，则为巨型对象，那么其会至少独占一个Region，如果一个放不下，会占用连续的多个Region。当一个`Humongous Region`放入了一个巨型对象，可能还有不少剩余空间，但是不能用于存放其他对象，这些空间就浪费了。所以如果应用里有很多大小差不多的巨型对象，可以适当调整Region的大小，尽量让他们以普通对象的形式分配，合理利用Region空间。

3. **新生代比例**：

   > 新生代比例有两个数值指定，下限：`-XX:G1NewSizePercent`，默认值5%，上限：`-XX:G1MaxNewSizePercent`，默认值60%。G1会根据实际的GC情况(主要是暂停时间)来动态的调整新生代的大小，主要是Eden Region的个数。最好是Eden的空间大一点，毕竟Young GC的频率更大，大的Eden空间能够降低Young GC的发生次数。但是Mixed GC是伴随着Young GC一起的，如果暂停时间短，那么需要更加频繁的Young GC，同时也需要平衡好Mixed GC中新生代和老年代的Region，因为新生代的所有Region都会被回收，如果Eden很大，那么留给老年代回收空间就不多了，最后可能会导致Full GC。

4. **并发GC线程数**：

   > 通过 `-XX:ConcGCThreads`来指定，默认是`-XX:ParallelGCThreads/4`，也就是在非STW期间的GC工作线程数，当然其他的线程很多工作在应用上。当并发周期时间过长时，可以尝试调大GC工作线程数，但是这也意味着此期间应用所占的线程数减少，会对吞吐量有一定影响。

5. **并行GC线程数**：

   > 通过 `-XX:ParallelGCThreads`来指定，也就是在STW阶段工作的GC线程数，其值遵循以下原则：
   > ① 如果用户显示指定了ParallelGCThreads，则使用用户指定的值。
   > ② 否则，需要根据实际的CPU所能够支持的线程数来计算ParallelGCThreads的值，计算方法见步骤③和步骤④。
   > ③ 如果物理CPU所能够支持线程数小于8，则ParallelGCThreads的值为CPU所支持的线程数。这里的阀值为8，是因为JVM中调用nof_parallel_worker_threads接口所传入的switch_pt的值均为8。
   > ④ 如果物理CPU所能够支持线程数大于8，则ParallelGCThreads的值为8加上一个调整值，调整值的计算方式为：物理CPU所支持的线程数减去8所得值的5/8或者5/16，JVM会根据实际的情况来选择具体是乘以5/8还是5/16。
   > 比如，在64线程的x86 CPU上，如果用户未指定ParallelGCThreads的值，则默认的计算方式为：ParallelGCThreads = 8 + (64 - 8) * (5/8) = 8 + 35 = 43。

6. **被纳入Cset的Region的存活空间占比阈值**：

   > 通过 `-XX:G1MixedGCLiveThresholdPercent`指定，不同版本默认值不同，有65%和85%。在全局并发标记阶段，如果一个Region的存活对象的空间占比低于此值，则会被纳入Cset。此值直接影响到Mixed GC选择回收的区域，当发现GC时间较长时，可以尝试调低此阈值，尽量优先选择回收垃圾占比高的Region，但此举也可能导致垃圾回收的不够彻底，最终触发Full GC。

7. **触发全局并发标记的老年代使用占比**：

   > 通过`-XX:InitiatingHeapOccupancyPercent`指定，默认值45%，也就是老年代占堆的比例超过45%。如果Mixed GC周期结束后老年代使用率还是超过45%,那么会再次触发全局并发标记过程，这样就会导致频繁的老年代GC，影响应用吞吐量。同时老年代空间不大，Mixed GC回收的空间肯定是偏少的。可以适当调高IHOP的值，当然如果此值太高，很容易导致年轻代晋升失败而出发Full GC，所以需要多次调整测试。

8. **触发Mixed GC的堆垃圾占比**：

   > 通过`-XX:G1HeapWastePercent`指定，默认值5%，也就是在全局标记结束后能够统计出所有Cset内可被回收的垃圾占整对的比例值，如果超过5%，那么就会触发之后的多轮Mixed GC，如果不超过，那么会在之后的某次Young GC中重新执行全局并发标记。可以尝试适当的调高此阈值，能够适当的降低Mixed GC的频率。

9. **每轮Mixed GC回收的Region最大比例**：

   > 通过`-XX:G1OldCSetRegionThresholdPercent`指定，默认10%，也就是每轮Mixed GC附加的Cset的Region`不超过`全部Region的10%，最多10%，如果暂停时间短，那么可能会少于10%。一般这个值不需要额外调整。

10. **一个周期内触发Mixed GC最大次数**：

    > 通过`-XX:G1MixedGCCountTarget`指定，默认值8。也就是在一次全局并发标记后，最多接着8此Mixed GC，也就是会把全局并发标记阶段生成的Cset里的Region拆分为最多8部分，然后在每轮Mixed GC里收集一部分。这个值要和上一个参数配合使用，8*10%=80%，应该来说会大于每次标记阶段的Cset集合了。一般此参数也不需额外调整。

11. **G1为分配担保预留的空间比例**：

    > 通过`-XX:G1ReservePercent`指定，默认10%。也就是老年代会预留10%的空间来给新生代的对象晋升，如果经常发生新生代晋升失败而导致Full GC，那么可以适当调高此阈值。但是调高此值同时也意味着降低了老年代的实际可用空间。

12. **谨慎使用Soft Reference**

    > 如果SoftReference过多，会有频繁的老年代收集。-XX:SoftRefLRUPolicyMSPerMB参数，可以指定每兆堆空闲空间的软引用的存活时间，默认值是1000，也就是1秒。可以调低这个参数来触发更早的回收软引用。如果调高的话会有更多的存活数据，可能在GC后堆占用空间比会增加。 对于软引用，还是建议尽量少用，会增加存活数据量，增加GC的处理时间。

13. **晋升年龄阈值**：

    > 通过`-XX:MaxTenuringThreshold`指定，默认值15。一般新生对象经过15次Young GC会晋升到老年代，巨型对象会直接分配在老年代，同时在Young GC时，如果相同age的对象占Survivors空间的比例超过 `-XX:TargetSurvivorRatio`的值(默认50%)，则会自动将此次晋升年龄阈值设置为此age的值，所有年龄超过此值的对象都会被晋升到老年代，此举可能会导致老年代需要不少空间应对此种晋升。一般这个值不需要额外调整。

# 9. 设计模式？哪些框架有设计模式？每个模式是什么样的？

## Spring:

> **工厂模式：**
>
> Spring使用工厂模式可以通过 `BeanFactory `或 `ApplicationContext` 创建`bean`对象。
>
> -  `BeanFactory` ：延迟注入(使用到某个 `bean` 的时候才会注入)，程序启动速度更快。是`Spring`里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能；
> -  `ApplicationContext `：继承`BeanFactory`接口，容器启动的时候，不管你用没用到，一次性创建所有 `bean` 。还可以为`Bean`配置`lazy-init=true`来让`Bean`延迟实例化； 
>
> **单例模式**
>
> `Spring`中`bean`的默认作用域就是`singleton`。
>
> 除了`singleton`作用域，`Spring bean`还有下面几种作用域：
>
> -  `prototype` : 每次请求都会创建一个新的 `bean `实例。
> -  `request `: 每一次`HTTP`请求都会产生一个新的`bean`，该`bean`仅在当前`HTTP request`内有效。
> -  `session` : 每一次`HTTP`请求都会产生一个新的 `bean`，该`bean`仅在当前 `HTTP session` 内有效。
> -  `global-session`： 全局`session`作用域，仅仅在基于`portlet`的`web`应用中才有意义，`Spring5`已经没有了。
>
> **代理模式**
>
> `Spring AOP`就是基于动态代理的，如果要代理的对象，实现了某个接口，那么`Spring AOP`会使用`JDK Proxy`，去创建代理对象，而对于没有实现接口的对象，这时候`Spring AOP`会使用`Cglib`生成一个被代理对象的子类来作为代理。
>
> **模板设计模式**
>
> `Spring`中的`jdbcTemplate`、`hibernateTemplate`等以`Template`结尾的对数据库操作的类，它们就使用到了模板模式。一般情况下，我们都是使用继承的方式来实现模板模式，但是Spring并没有使用这种方式，而是使用Callback模式与模板方法配合，既达到了代码复用的效果，同时增加了灵活性。
>
> **观察者模式**
>
> 观察者模式是一种对象行为模式。它表示的是一种对象与对象之间具有依赖关系，当一个对象发生改变时，这个对象所依赖的对象也会做出反应。`Spring`事件驱动模型就是观察者模式很经典的应用。
>
> 事件角色：`ApplicationEvent`（`org.springframework.context`包下）充当事件的角色，这是一个抽象类。
>
> 事件监听者角色：`ApplicationListener`充当了事件监听者的角色，它是一个接口，里面只定义了一个`onApplicationEvent（）`方法来处理`ApplicationEvent`。
>
> 事件发布者角色：`ApplicationEventPublisher`充当了事件的发布者，它也是个接口。
>
> `Spring`事件流程总结：
>
> 1.  定义一个事件: 实现一个继承自 `ApplicationEvent`，并且写相应的构造函数；
> 2.  定义一个事件监听者：实现 `ApplicationListener `接口，重写 `onApplicationEvent() `方法；
> 3.  使用事件发布者发布消息: 可以通过 `ApplicationEventPublisher` 的 `publishEvent()` 方法发布消息。
>
> **适配器设计模式**
>
> 适配器设计模式将一个接口转换成客户希望的另一个接口，适配器模式使得接口不兼容的那些类可以一起工作，其别名为包装器。在`Spring MVC`中，`DispatcherServlet`根据请求信息调用`HandlerMapping`，解析请求对应的`Handler`，解析到对应的`Handler`（也就是我们常说的`Controller`控制器）后，开始由`HandlerAdapter`适配器处理。
>
> **装饰者设计模式**
>
> 装饰者设计模式可以动态地给对象增加些额外的属性或行为。相比于使用继承，装饰者模式更加灵活。`Spring `中配置`DataSource`的时候，`DataSource`可能是不同的数据库和数据源。我们能否根据客户的需求在少修改原有类的代码下切换不同的数据源，这个时候据需要用到装饰者模式。
>
> **策略设计模式**
>
> `Spring `框架的资源访问接口就是基于策略设计模式实现的。该接口提供了更强的资源访问能力，`Spring`框架本身大量使用了`Resource`接口来访问底层资源。`Resource`接口本身没有提供访问任何底层资源的实现逻辑，针对不同的额底层资源，`Spring`将会提供不同的`Resource`实现类，不同的实现类负责不同的资源访问类型。
>
> `Spring `为 `Resource `接口提供了如下实现类： 
>
> - UrlResource：访问网络资源的实现类。
>
> - ClassPathResource：访问类加载路径里资源的实现类。
>
> - FileSystemResource：访问文件系统里资源的实现类。
>
> - ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类.
>
> - InputStreamResource：访问输入流资源的实现类。
>
> - ByteArrayResource：访问字节数组资源的实现类。 
>
>   这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。

## Mybatis

> 1. Builder模式，例如`SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder`；
> 2. 工厂模式，例如`SqlSessionFactory、ObjectFactory、MapperProxyFactory`；
> 3. 单例模式，例如`ErrorContext`和`LogFactory`；
> 4. 代理模式，`Mybatis`实现的核心，比如`MapperProxy`、`ConnectionLogger`，用的`jdk`的动态代理；还有`executor.loader`包使用了`cglib`或者`javassist`达到延迟加载的效果；
> 5. 组合模式，例如`SqlNode`和各个子类`ChooseSqlNode`等；
> 6. 模板方法模式，例如`BaseExecutor`和`SimpleExecutor`，还有`BaseTypeHandler`和所有的子类例如`IntegerTypeHandler`；
> 7. 适配器模式，例如`Log`的`Mybatis`接口和它对`jdbc`、`log4j`等各种日志框架的适配实现；
> 8. 装饰者模式，例如`Cache`包中的`cache.decorators`子包中等各个装饰者的实现；
> 9. 迭代器模式，例如迭代器模式`PropertyTokenizer`；

**1、Builder模式**

`Builder`模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和`Builder`模式，相对于工厂模式会产出一个完整的产品，`Builder`应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。

在`Mybatis`环境的初始化过程中，`SqlSessionFactoryBuilder`会调用`XMLConfigBuilder`读取所有的`MybatisMapConfig.xml`和所有的`*Mapper.xml`文件，构建`Mybatis`运行的核心对象`Configuration`对象，然后将该`Configuration`对象作为参数构建一个`SqlSessionFactory`对象。

其中`XMLConfigBuilder`在构建`Configuration`对象时，也会调用`XMLMapperBuilder`用于读取`*Mapper`文件，而`XMLMapperBuilder`会使用`XMLStatementBuilder`来读取和`build`所有的`SQL`语句。

在这个过程中，有一个相似的特点，就是这些`Builder`会读取文件或者配置，然后做大量的`XpathParser`解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了`Builder`模式来解决。

**2、工厂模式**

在Mybatis中比如SqlSessionFactory使用的是工厂模式，该工厂没有那么复杂的逻辑，是一个简单工厂模式。

简单工厂模式`(Simple Factory Pattern)`：又称为静态工厂方法`(Static Factory Method)`模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。

`SqlSession`可以认为是一个`Mybatis`工作的核心的接口，通过这个接口可以执行执行`SQL`语句、获取`Mappers`、管理事务。类似于连接`MySQL`的`Connection`对象。`SqlSessionFactory`的`openSession`方法重载了很多个，分别支持`autoCommit`、`Executor`、`Transaction`等参数的输入，来构建核心的`SqlSession`对象。

**3、单例模式**

单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。

单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。

在`Mybatis`中有两个地方用到单例模式，`ErrorContext`和`LogFactory`，其中`ErrorContext`是用在每个线程范围内的单例，用于记录该线程的执行环境错误信息，而`LogFactory`则是提供给整个`Mybatis`使用的日志工厂，用于获得针对项目配置好的日志对象。

**4、代理模式**

代理模式可以认为是`Mybatis`的核心使用的模式，正是由于这个模式，我们只需要编写`Mapper.java`接口，不需要实现，由`Mybatis`后台帮我们完成具体`SQL`的执行。

代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用，它是一种对象结构型模式。

代理模式包含如下角色：

- `Subject`: 抽象主题角色
- `Proxy`: 代理主题角色
- `RealSubject`: 真实主题角色

**5、组合模式**

组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。

组合模式对单个对象(叶子对象)和组合对象(组合对象)具有一致性，它将对象组织到树结构中，可以用来描述整体与部分的关系。同时它也模糊了简单元素(叶子对象)和复杂元素(容器对象)的概念，使得客户能够像处理简单元素一样来处理复杂元素，从而使客户程序能够与复杂元素的内部结构解耦。

在使用组合模式中需要注意一点也是组合模式最关键的地方：叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。

**6、模板方法模式**

模板方法模式是所有模式中最为常见的几个模式之一，是基于继承的代码复用的基本技术。

模板方法模式需要开发抽象类和具体子类的设计师之间的协作。一个设计师负责给出一个算法的轮廓和骨架，另一些设计师则负责给出这个算法的各个逻辑步骤。代表这些具体逻辑步骤的方法称做基本方法(primitive method)；而将这些基本方法汇总起来的方法叫做模板方法(template method)，这个设计模式的名字就是从此而来。

模板类定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。

在`Mybatis`中，`sqlSession`的`SQL`执行，都是委托给`Executor`实现的，`Executor`包含以下结构：

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220428172422.jpg)

其中的`BaseExecutor`就采用了模板方法模式，它实现了大部分的`SQL`执行逻辑，然后把以下几个方法交给子类定制化完成：

```java
protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException;

protected abstract List<BatchResult> doFlushStatements(boolean isRollback) throws SQLException;

protected abstract <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds,
     ResultHandler resultHandler, BoundSql boundSql) throws SQLException;
```

该模板方法类有几个子类的具体实现，使用了不同的策略：

- 简单`SimpleExecutor`：每执行一次`update`或`select`，就开启一个`Statement`对象，用完立刻关闭`Statement`对象。（可以是`Statement`或`PrepareStatement`对象）
- 重用`ReuseExecutor`：执行`update`或`select`，以`sql`作为`key`查找`Statement`对象，存在就使用，不存在就创建，用完后，不关闭`Statement`对象，而是放置于`Map<String, Statement>`内，供下一次使用。（可以是`Statement`或`PrepareStatement`对象）
- 批量`BatchExecutor`：执行`update`（没有`select`，`JDBC`批处理不支持select`）`，将所有`sql`都添加到批处理中（`addBatch()`），等待统一执行（`executeBatch()`），它缓存了多个`Statement`对象，每个`Statement`对象都是`addBatch()`完毕后，等待逐一执行`executeBatch()`批处理的；`BatchExecutor`相当于维护了多个桶，每个桶里都装了很多属于自己的`SQL`，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库。（可以是`Statement`或`PrepareStatement`对象）

**7、适配器模式**

适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。

在`Mybatsi`的`logging`包中，有一个`Log`接口：

该接口定义了`Mybatis`直接使用的日志方法，而`Log`接口具体由谁来实现呢？`Mybatis`提供了多种日志框架的实现，这些实现都匹配这个`Log`接口所定义的接口方法，最终实现了所有外部日志框架到`Mybatis`日志包的适配

**8、装饰者模式**

装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。

在`Mybatis`中，缓存的功能由根接口`Cache（org.apache.ibatis.cache.Cache）`定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由`PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）`永久缓存实现，然后通过一系列的装饰器来对`PerpetualCache`永久缓存进行缓存策略等方便的控制

用于装饰`PerpetualCache`的标准装饰器共有8个（全部在`org.apache.ibatis.cache.decorators`包中）：

1. `FifoCache`：先进先出算法，缓存回收策略
2. `LoggingCache`：输出缓存命中的日志信息
3. `LruCache`：最近最少使用算法，缓存回收策略
4. `ScheduledCache`：调度缓存，负责定时清空缓存
5. `SerializedCache`：缓存序列化和反序列化存储
6. `SoftCache`：基于软引用实现的缓存管理策略
7. `SynchronizedCache`：同步的缓存装饰器，用于防止多线程并发访问
8. `WeakCache`：基于弱引用实现的缓存管理策略

另外，还有一个特殊的装饰器`TransactionalCache`：事务性的缓存

正如大多数持久层框架一样，`Mybatis`缓存同样分为一级缓存和二级缓存

- 一级缓存，又叫本地缓存，是`PerpetualCache`类型的永久缓存，保存在执行器中（`BaseExecutor`），而执行器又在`SqlSession（DefaultSqlSession）`中，所以一级缓存的生命周期与`SqlSession`是相同的。
- 二级缓存，又叫自定义缓存，实现了`Cache`接口的类都可以作为二级缓存，所以可配置如`encache`等的第三方缓存。二级缓存以`namespace`名称空间为其唯一标识，被保存在`Configuration`核心配置对象中。

二级缓存对象的默认类型为`PerpetualCache`，如果配置的缓存是默认类型，则`Mybatis`会根据配置自动追加一系列装饰器。

`Cache`对象之间的引用顺序为：

`SynchronizedCache–>LoggingCache–>SerializedCache–>ScheduledCache–>LruCache–>PerpetualCache`

**9、迭代器模式**

迭代器（Iterator）模式，又叫做游标（Cursor）模式。GOF给出的定义为：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。

Java的Iterator就是迭代器模式的接口，只要实现了该接口，就相当于应用了迭代器模式

比如`Mybatis`的`PropertyTokenizer`是`property`包中的重量级类，该类会被`reflection`包中其他的类频繁的引用到。这个类实现了`Iterator`接口，在使用时经常被用到的是`Iterator`接口中的`hasNext`这个函数。



# 10. 乐观锁和悲观锁

## 实现方式

乐观锁和悲观锁是两种思想，它们的使用是非常广泛的，不局限于某种编程语言或数据库。

悲观锁的实现方式是加锁，加锁既可以是对代码块加锁（如`Java`的`synchronized`关键字），也可以是对数据加锁（如`MySQL`中的排它锁）

**乐观锁的实现方式主要有两种：CAS机制和版本号机制**

**（1）CAS（Compare And Swap）**

CAS操作包括了3个操作数：

```text
 1) 需要读写的内存位置(V)
 2) 进行比较的预期值(A)
 3) 拟写入的新值(B)
```

**CAS操作逻辑如下：**

如果内存位置 V 的值等于预期的 A 值，则将该位置更新为新值 B，否则不进行任何操作。

许多 CAS 的操作是自旋的：如果操作不成功，会一直重试，直到操作成功为止。

> 这里引出一个新的问题，既然CAS包含了Compare和Swap两个操作，它又如何保证原子性呢？
> 答案是：CAS是由CPU支持的原子操作，其原子性是在硬件层面进行保证的。

以`Java`中的自增操作(`i++`)为例，看一下悲观锁和`CAS`分别是如何保证线程安全的。

我们知道，在Java中自增操作不是原子操作，它实际上包含三个独立的操作：

```text
1) 读取i值；
2) 加1；
3) 将新值写回i
```

因此，如果并发执行自增操作，可能导致计算结果的不准确。

在下面的代码示例中：`value1`没有进行任何线程安全方面的保护，`value2`使用了乐观锁(CAS)，`value3`使用了悲观锁(synchronized)。

运行程序，使用`1000`个线程同时对`value1`、`value2`和`value3`进行自增操作，可以发现：`value2`和`value3`的值总是等于`1000`，而`value1`的值常常小于`1000`。

```java
public class Test {

        //value1：线程不安全  
        private static int value1 = 0;
        //value2：使用乐观锁  
        private static AtomicInteger value2 = new AtomicInteger(0);
        //value3：使用悲观锁  
        private static int value3 = 0;

        private static synchronized void increaseValue3() {
            value3++;
        }

        public static void main(String[] args) throws Exception {
            //开启1000个线程，并执行自增操作  
            for (int i = 0; i < 1000; ++i) {
                new Thread(new Runnable() {
                    @Override
                    public void run() {
                        try {
                            Thread.sleep(100);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                        value1++;
                        value2.getAndIncrement();
                        increaseValue3();
                    }
                }).start();
            }
            //查看活跃线程 ,因守护线程的原因[基于工具问题windows:idea run 启动用 >2,debug 用>1] 
            while (Thread.activeCount() > 2) {
                //Thread.currentThread().getThreadGroup().list();
                Thread.yield();//让出cpu
            }

            //打印结果  
            Thread.sleep(1000);
            System.out.println("线程不安全：" + value1);
            System.out.println("乐观锁(AtomicInteger)：" + value2);
            System.out.println("悲观锁(synchronized)：" + value3);
        }
}
```

上面的代码中:

**1)首先来介绍AtomicInteger**。

`AtomicInteger`是`java.util.concurrent.atomic`包提供的原子类，利用`CPU`提供的`CAS`操作来保证原子性；

除了`AtomicInteger`外，还有`AtomicBoolean`、`AtomicLong`、`AtomicReference`等众多原子类。

下面看一下`AtomicInteger`的源码，了解下它的自增操作`getAndIncrement()`是如何实现的（源码以`Java7`为例，`Java8`有所不同，但思想类似）。

```java
public class AtomicInteger extends Number implements java.io.Serializable { 
//存储整数值，volatile保证可视性 
private volatile int value;
 //Unsafe用于实现对底层资源的访问
 private static final Unsafe unsafe = Unsafe.getUnsafe();

//valueOffset是value在内存中的偏移量  
private static final long valueOffset;  
//通过Unsafe获得valueOffset  
static {  
    try {  
        valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));  
    } catch (Exception ex) { throw new Error(ex); }  
}  

public final boolean compareAndSet(int expect, int update) {  
    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
}  

public final int getAndIncrement() {  
    for (;;) {  
        int current = get();  
        int next = current + 1;  
        if (compareAndSet(current, next))  
            return current;  
    }  
}  
}
```

**源码分析说明如下：**

- `getAndIncrement()`实现的自增操作是自旋CAS操作：在循环中进行`compareAndSet`，如果执行成功则退出，否则一直执行。
- 其中`compareAndSet`是CAS操作的核心，它是利用`Unsafe`对象实现的。
- Unsafe是用来帮助Java访问操作系统底层资源的类（如可以分配内存、释放内存,在`netty`中大量用到它,属于C++层面的native方法,我们一般使用反射获取），通过Unsafe，Java具有了底层操作能力，可以提升运行效率；

强大的底层资源操作能力也带来了安全隐患(类的名字Unsafe也在提醒我们这一点)，因此正常情况下用户无法使用。

`AtomicInteger`在这里使用了`Unsafe`提供的`CAS`功能。

- `valueOffset`可以理解为`value`在内存中的偏移量，对应了`CAS`三个操作数(`V/A/B`)中的V；偏移量的获得也是通过`Unsafe`实现的。
- `value`域的`volatile`修饰符：`Java`并发编程要保证线程安全，需要保证原子性、可视性和有序性；

`CAS`操作可以保证原子性，而`volatile`可以保证可视性和一定程度的有序性；

在`AtomicInteger`中，`volatile`和`CAS`一起保证了线程安全性。

关于`volatile`作用原理的说明涉及到`Java`内存模型(`JMM`)，这里不详细展开。

**2) 说完了`AtomicInteger`，再说synchronized**。

`synchronized`通过对代码块加锁来保证线程安全：在同一时刻，只能有一个线程可以执行代码块中的代码。

`synchronized`是一个重量级的操作，不仅是因为加锁需要消耗额外的资源，还因为线程状态的切换会涉及操作系统核心态和用户态的转换；

不过随着`JVM`对锁进行的一系列优化(如自旋锁、轻量级锁、锁粗化等)，**synchronized**的性能表现已经越来越好。

**（2）版本号机制 除了CAS，版本号机制也可以用来实现乐观锁**

版本号机制的基本思路是在数据中增加一个字段`version`，表示该数据的版本号，每当数据被修改，版本号加1。

- 当某个线程查询数据时，将该数据的版本号一起查出来；
- 当该线程更新数据时，判断当前版本号与之前读取的版本号是否一致，如果一致才进行操作。

需要注意的是，这里使用了版本号作为判断数据变化的标记，实际上可以根据实际情况选用其他能够标记数据版本的字段，如时间戳等。

下面以“更新玩家金币数”为例，看看悲观锁和版本号机制是如何应对并发问题的。

考虑这样一种场景：游戏系统需要更新玩家的金币数，更新后的金币数依赖于当前状态(如金币数、等级等)，因此更新前需要先查询玩家当前状态。

下面的实现方式，没有进行任何线程安全方面的保护。如果有其他线程在`query`和`update`之间更新了玩家的信息，会导致玩家金币数的不准确。

```java
@Transactional
public void updateCoins(Integer playerId){
    //根据player_id查询玩家信息
    Player player = query("select coins, level from player where player_id = {0}", playerId);
    //根据玩家当前信息及其他信息，计算新的金币数
    Long newCoins = ……;
    //更新金币数
    update("update player set coins = {0} where player_id = {1}", newCoins, playerId);
}
```

为了避免这个问题，悲观锁通过加锁解决这个问题，代码如下所示。在查询玩家信息时，使用`select …… for update`进行查询；

该查询语句会为该玩家数据加上排它锁，直到事务提交或回滚时才会释放排它锁；

在此期间，如果其他线程试图更新该玩家信息或者执行`select for update`，会被阻塞(所以...如果你`for update`了,但是没有`commit`,那就一直锁着...锁住了青春~~~)。

```java
@Transactional
public void updateCoins(Integer playerId){
    //根据player_id查询玩家信息（加排它锁）
    Player player = queryForUpdate("select coins, level from player where player_id = {0} for update", playerId);
    //根据玩家当前信息及其他信息，计算新的金币数
    Long newCoins = ……;
    //更新金币数
    update("update player set coins = {0} where player_id = {1}", newCoins, playerId);
}
```

版本号机制则是另一种思路，它为玩家信息增加一个字段：version。在初次查询玩家信息时，同时查询出version信息；

在执行update操作时，校验version是否发生了变化，如果version变化，则不进行更新。

```java
@Transactional
public void updateCoins(Integer playerId){
    //根据player_id查询玩家信息，包含version信息
    Player player = query("select coins, level, version from player where player_id = {0}", playerId);
    //根据玩家当前信息及其他信息，计算新的金币数
    Long newCoins = ……;
    //更新金币数，条件中增加对version的校验
    update("update player set coins = {0} where player_id = {1} and version = {2}", newCoins, playerId, player.version);
}
```

## 优缺点和适用场景

乐观锁和悲观锁并没有优劣之分，它们有各自适合的场景；下面从两个方面进行说明。

- **功能限制 ：与悲观锁相比，乐观锁适用的场景受到了更多的限制，无论是CAS还是版本号机制。**

例如，CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。

再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。

- **竞争激烈程度： 如果悲观锁和乐观锁都可以使用，那么选择就要考虑竞争的激烈程度：**

当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。

当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源。

## 乐观锁加锁吗？

下面是我对这个问题的理解：

1. 乐观锁本身是不加锁的，只是在更新时判断一下数据是否被其他线程更新了；`AtomicInteger`便是一个例子。
2. 有时乐观锁可能与加锁操作合作，例如，在前述`updateCoins()`的例子中，`MySQL`在执行`update`时会加排它锁。

但这只是乐观锁与加锁操作合作的例子，不能改变“乐观锁本身不加锁”这一事实。

##  CAS的缺点？

**1.ABA问题——假设有两个线程、线程1和线程2，两个线程按照顺序进行以下操作：**

- (1)线程1读取内存中数据为A；
- (2)线程2将该数据修改为B；
- (3)线程2将该数据修改为A；
- (4)线程1对数据进行CAS操作

在第(4)步中，由于内存中数据仍然为A，因此CAS操作成功，但实际上该数据已经被线程2修改过了。这就是ABA问题。

在`AtomicInteger`的例子中，`ABA`似乎没有什么危害。

但是在某些场景下，`ABA`却会带来隐患，例如栈顶问题：一个栈的栈顶经过两次(或多次)变化又恢复了原值，但是栈可能已发生了变化。

​	对于`ABA`问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都`+1`；

​	在进行`CAS`操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。

`Java`中的`AtomicStampedReference`类便是使用版本号来解决`ABA`问题的。

**2.高竞争下的开销问题——在并发冲突概率大的高竞争环境下，如果CAS一直失败，会一直重试，CPU开销较大。**

针对这个问题的一个思路是引入退出机制，如重试次数超过一定阈值后失败退出。

当然，更重要的是避免在高竞争环境下使用乐观锁。

**3.功能限制——CAS的功能是比较受限的，例如CAS只能保证单个变量（或者说单个内存值）操作的原子性，这意味着：**

(1)原子性不一定能保证线程安全，例如在Java中需要与`volatile`配合来保证线程安全；

(2)当涉及到多个变量(内存值)时，`CAS`也无能为力。

除此之外，`CAS`的实现需要硬件层面处理器的支持，在`Java`中普通用户无法直接使用，只能借助`atomic`包下的原子类使用，灵活性受到限制。



# 11. MySQL事务及隔离级别

// TODO 补充事务传播

## ACID特性

> 数据库管理系统中**事务(transaction)**的四个特性（分析时根据首字母缩写依次解释）：**原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）**
>
> 所谓事务，它是一个**操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位**。（执行单个逻辑功能的一组指令或操作称为事务）

1. <span style="background:#f9eda6;">原子性</span>

   > 原子性是指事务是一个**不可再分割的工作单元**，事务中的操作要么都发生，要么都不发生。
   >
   > 可采用“**A向B转账**”这个例子来说明解释
   >
   > 在DBMS中，默认情况下**一条SQL就是一个单独事务**，事务是**自动提交**的。只有显式的使用**start transaction**开启一个事务，才能将一个代码块放在事务中执行。

2. <span style="background:#f9eda6;">一致性</span>

   > 一致性是指在**事务开始之前和事务结束以后**，**数据库的完整性约束没有被破坏**。这是说数据库事务不能破坏**关系数据的完整性**以及**业务逻辑上的一致性**。
   >
   > 如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。
   >
   > 保障机制（也从两方面着手）：**数据库层面**会在一个事务执行之前和之后，数据会符合你设置的**约束**（**唯一约束，外键约束,check约束**等)和触发器设置；此外，数据库的内部数据结构（如 B 树索引或双向链表）都必须是正确的。业务的一致性一般由开发人员进行保证，亦可转移至数据库层面。

3. <span style="background:#f9eda6;">隔离性</span>

   > **多个事务并发访问时，事务之间是隔离的**，一个事务不应该影响其它事务运行效果。
   >
   > 在并发环境中，当**不同的事务同时操纵相同的数据**时，每个事务都有**各自的完整数据空间**。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，**事务不会查看到中间状态的数据**。
   >
   > 事务最复杂问题都是由事务隔离性引起的。完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务，这样会严重影响性能。
   >
   > 关于隔离性中的事务隔离等级（事务之间影响），参见相应博文

4. <span style="background:#f9eda6;">持久性</span>

   > 持久性，意味着在事务完成以后，**该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。**（完成的事务是**系统永久的部分**，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持）

## 隔离级别

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429111039.jpg" alt="img" style="zoom: 67%;" />

**脏读**

脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了最终并不一定存在的数据，这就是脏读。

**可重复读**

可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据**更新（UPDATE）**操作。

**不可重复读**

事务B读取了两次数据资源，在这两次读取的过程中事务A修改了数据，导致事务B在这两次读取出来的数据不一致。这种在同一个事务中，前后两次读取的数据不一致的现象就是不可重复读。通常针对数据**更新（UPDATE）**操作。

**幻读**

幻读是针对数据**插入（INSERT）**操作来说的。事务B前后两次读取同一个范围的数据，在事务B两次读取的过程中事务A新增了数据，导致事务B后一次读取到前一次查询没有看到的行。

幻读和不可重复读有些类似，但是幻读强调的是集合的增减，而不是单条数据的更新。

## 事务传播机制

Spring 对事务的传播机制在 [Propagation](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fblob%2Fmain%2Fspring-tx%2Fsrc%2Fmain%2Fjava%2Forg%2Fspringframework%2Ftransaction%2Fannotation%2FPropagation.java) 枚举中定义了7个分类：

- REQUIRED 默认

  - **如果当前不存在事务，就新建一个事务。如果存在事务，就加入到当前事务。这是一个默认的事务**。如果有发生异常，则全部都回滚

- SUPPORTS 支持

  - 如果当前没有事务，则以非事务的方式运行。如果存在事务，就加入到当前事务。

- MANDATORY 强制

  - **如果存在事务，就加入到当前事务。如果不存在事务，就报错**。如果想调用 MANDATORY 传播属性的方法，一定要有事务，不然就会报错。

- REQUIRES_NEW 新建

  - **创建一个新的事务。如果存在事务，就将事务挂起。**

    > 无论是否有事务，都会创建一个新的事务。

- NOT_SUPPORTED 不支持

  - **无论是否存在当前事务，都是以非事务的方式运行**。

- NEVER 从不

  - **不使用事务，如果存在事务，就抛出异常**。

    > NEVER 的方法不使用事务，调用 NEVER 方法如果有事务，就抛出异常。

- NESTED 嵌套

  - 如果当前事务存在，就运行一个嵌套事务。如果不存在事务，就和 REQUIRED 一样新建一个事务。

> - NESTED 和 REQUIRED_NEW 的区别：
>   - REQUIRED_NEW 是开启一个新的事务，和调用的事务无关。调用方回滚，不会影响到 REQUIRED_NEW 事务。
>   - NESTED 是一个嵌套事务，是调用方的一个子事务，如果调用方事务回滚，NESTED 也会回滚。

| 传播属性      | 总结                                                         |
| :------------ | :----------------------------------------------------------- |
| REQUIRED      | 默认属性，所有的事务都处于同一个事务下，出现异常，不管是否捕获所有事务回滚 |
| SUPPORTS      | 如果不存事务，就以非事务的方式运行，存在事务就加入该事务     |
| MANDATORY     | 强制调用方添加事务，如果不存在事务就报错，存在事务就加入该事务 |
| REQUIRES_NEW  | 无论调用方是否存在事务，都会创建新的事务，并且调用方异常不会影响 REQUIRES_NEW事务 |
| NOT_SUPPORTED | 无论是否调用方是否存在事务，都是以非事务的方式执行，出现异常也会回滚 |
| NEVER         | 不用事务，存在事务就报错，和 MANDATORY 相反                  |
| NESTED        | 嵌套事务，新建一个子事务，事务执行相互独立，如果调用方出现异常，直接回滚 |

事务的传播机制，是 Spring 规定的。因为在开发中，最简单的事务是，业务代码都处于同一个事务下，这也是默认的传播机制，如果出现的报错，所有的数据回滚。但是在处理复杂的业务逻辑时，方法之间的调用，有以下的需求：

- 调用的方法需要新增一个事务，新事务和原来的事务各自独立。
- 调用的方法不支持事务
- 调用的方法是一个嵌套的事务

# 12. `URL`解析过程

~~~markdown
1. URL组成
	协议（http/https）
	域名 （有时候也是ip）
	端口号（数字表示，若为HTTP的默认值“:80”可省略）
	路径（以“/”字符区别路径中的每一个目录名称）
	查询（GET模式的窗体参数，以“?”字符为起点，每个参数以“&”隔开，再以“=”分开参数名称与数据，通常以UTF8的URL编码，避开字符冲突的问题）
	
第 1 步
用户在浏览器中输入 URL 并回车。首先是将 URL 转换为 IP 地址。从 URL 到 IP 地址的映射通常存储在缓存中，因此浏览器会在多层缓存中查找 IP 地址：浏览器缓存、操作系统缓存、本地缓存和 ISP 缓存。如果浏览器在缓存中找不到映射，就会请求 DNS（Domain Name System）解析器进行解析。
第 2 步
如果在任何缓存中都找不到 IP 地址，浏览器就会转到 DNS 服务器进行递归 DNS 查找，直到找到 IP 地址为止。
第 3 步
有了服务器的 IP 地址，浏览器就会向服务器发送 HTTP 请求。为了安全访问服务器资源，我们应始终使用 HTTPS。浏览器首先通过 TCP 三次握手与服务器建立 TCP 连接。然后向客户端发送公钥（Public Key）。客户端使用公钥加密会话密钥（Session Key）并发送给服务器。服务器使用私钥（Private Key）解密会话密钥。然后，客户端和服务器就可以使用会话密钥来交换加密数据。
第 4 步
服务器处理请求并发回响应。响应成功时，状态代码为 200。响应包含 3 个部分：HTML、CSS 和 Javascript。浏览器会解析 HTML 并生成 DOM 树。浏览器还会解析 CSS 并生成 CSSOM 树。然后，浏览器将 DOM 树和 CSSOM 树合并为渲染树。浏览器渲染内容并显示给用户。
~~~



# 13. 七层协议

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429111426.jpg" alt="img" style="zoom:67%;" />

- **物理层**：

解决两个硬件之间怎么通信的问题，常见的物理媒介有光纤、电缆、中继器等。它主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。

它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输，到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换）。这一层的数据叫做比特。

- **数据链路层：**

在计算机网络中由于各种干扰的存在，物理链路是不可靠的。该层的主要功能就是：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。

它的具体工作是接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层的数据叫做帧。

- **网络层：**

计算机网络中如果有多台计算机，怎么找到要发的那台？如果中间有多个节点，怎么选择路径？这就是路由要做的事。

该层的主要任务就是：通过路由选择算法，为报文（该层的数据单位，由上一层数据打包而来）通过通信子网选择最适当的路径。这一层定义的是IP地址，通过IP地址寻址，所以产生了IP协议。

- **传输层：**

当发送大量数据时，很可能会出现丢包的情况，另一台电脑要告诉是否完整接收到全部的包。如果缺了，就告诉丢了哪些包，然后再发一次，直至全部接收为止。

简单来说，传输层的主要功能就是：监控数据传输服务的质量，保证报文的正确传输。

- **会话层：**

虽然已经可以实现给正确的计算机，发送正确的封装过后的信息了。但我们总不可能每次都要调用传输层协议去打包，然后再调用IP协议去找路由，所以我们要建立一个自动收发包，自动寻址的功能。于是会话层出现了：它的作用就是建立和管理应用程序之间的通信。

- **表示层：**

表示层负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。

- **应用层：**

应用层是计算机用户，以及各种应用程序和网络之间的接口，其功能是直接向用户提供服务，完成用户希望在网络上完成的各种工作。前端同学对应用层肯定是最熟悉的。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429111532.jpg" alt="img" style="zoom:67%;" />

# 14. 为什么要三次握手

三次握手 建立起 TCP连接 的 reliable，**分配初始序列号**和**资源**，在相互确认之后开始数据的传输。有 主动打开(一般是client) 和 被动打开(一般是server)。

TCP使用3次握手建立一条连接，该握手初始化了传输可靠性以及数据顺序性必要的信息，这些信息包括两个方向的初始序列号，确认号由初始序列号生成，使用3次握手是因为3次握手已经准备好了传输可靠性以及数据顺序性所必要的信息，该握手的第3次实际上并不是需要单独传输的，完全可以和数据一起传输。详细过程如下所示：

> 第一步，Client会进入SYN_SENT状态，并发送Syn 消息给Server端，SYN标志位在此场景下被设置为1，同时会带上Client这端分配好的Seq号，这个序列号是一个U32的整型数，该数值的分配是根据时间产生的一个随机值，通常情况下每间隔4ms会加1。除此之外还会带一个MSS，也就是最大报文段长度，表示Tcp传往另一端的最大数据块的长度。
>
> 第二步，Server端在收到，Syn消息之后，会进入SYN_RCVD状态，同时返回Ack消息给Client，用来通知Client，Server端已经收到SYN消息并通过了确认。这一步Server端包含两部分内容，一部分是回复Client的Syn消息，其中ACK=1，Seq号设置为Client的Syn消息的Seq数值+1；另一部分是主动发送Sever端的Syn消息给Client，Seq号码是Server端上面对应的序列号，当然Syn标志位也会设置成1，MSS表示的是Server这一端的最大数据块长度。
>
> 第三步，Client在收到第二步消息之后，首先会将Client端的状态从SYN_SENT变换成ESTABLISHED,此时Client发消息给Server端，这个方向的通道已经建立成功，Client可以发送消息给Server端了，Server端也可以成功收到这些消息。其次，Client端需要回复ACK消息给Server端，消息包含ACK状态被设置为1，Seq号码被设置成Server端的序列号+1。（备注：这一步往往会与Client主动发起的数据消息，合并到一起发送给Server端。）
>
> 第四步，Server端在收到这个Ack消息之后，会进入ESTABLISHED状态，到此时刻Server发向Client的通道连接建立成功，Server可以发送数据给Client，TCP的全双工连接建立完成。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429114110" alt="img" style="zoom: 50%;" />

## 不能两次握手

如果客户端想建立连接，给服务端发了一个连接请求（SYN），但是由于网络中种种情况，导致没有及时到达服务端，这就导致客户端在很长一段时间中没有收到回复消息（ACK），这时客户端又给服务端发送一个SYN，这次的发送和接收的很顺利，很快就收到了ACK，但是这时之前的SYN终于到了服务端，服务端规规矩矩的为这个SYN申请资源，然后返回ACK。由于之前的SYN已经失效了，所以客户端也不会去理会这个ACK，但是傻乎乎的服务端并不知道这个SYN已经失效了，一直为他委会着资源，这就造成了资源的浪费。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429140150" alt="img" style="zoom:50%;" />

## 四次挥手

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502172106" alt="img" style="zoom:50%;" />

1. 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。

2. 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。

3. 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。

4. 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1， Server进入CLOSED状态，完成四次挥手。

如果有大量的连接，每次在连接、关闭时都要三次握手，四次挥手，会很明显会造成性能低下，因此，

HTTP有一种叫做 keep connection 的机制，它可以在传输数据后仍然保持连接，当客户端再次获取数据时，直接使用刚刚空闲下的连接而无需再次握手

![preview](https://gitee.com/qc_faith/picture/raw/master/image/20220502172156.jpg)

## HTTP&HTTPS

| 区别     | HTTP                                                         | HTTPS                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协议     | 运行在 TCP 之上，明文传输，**客户端与服务器端都无法验证对方的身份** | 基于 HTTP，额外增加了TLS/SSL连接加密， **是添加了加密和认证机制的 HTTP**。 |
| 端口     | 80                                                           | 443                                                          |
| 性能     | 通常较高                                                     | 可能略低，由于加解密处理，会消耗更多的 CPU 和内存资源，但随着技术进步，差异逐渐减小 |
| 证书     | 无需证书                                                     | 需要 SSL 证书，由可信任的证书颁发机构（CA）颁发，用于验证服务器身份 |
| 加密机制 | 无                                                           | 共享密钥加密和公开密钥加密并用的混合加密机制                 |
| 安全性   | 不安全，数据以明文形式传输，易被第三方截取和查看             | 安全，使用 TLS/SSL 协议加密数据包，防止拦截和篡改            |

### 区别

1. `https`需要证书，一般不免费
2. `http`明文传输、`https`运用`SSL`加密传输
3. `http`和`https`使用的是完全不同的连接方式，用的端口也不一样，`http`是`80`，`https`是`443`
4. `http`无状态，`https`是由`SSL+http`构建的可进行**加密传输、身份认证**的网络协议，比`http`安全

### HTTP存在的问题和HTTPS解决的问题

1. 被监听

   `http`明文传输，通信过程数据容易被劫持。`https`是加密传输

2. 被伪装

   `http`通信时，无法保证通行双方是合法的，通信方可能是伪装的。比如你请求www.taobao.com,你怎么知道返回的数据就是来自淘宝，中间人可能返回数据伪装成淘宝。`https`用证书区分合法非法，相当于身份证

3. 被篡改

   `http`通信时易被篡改数据，接收方不知道数据已被修改。`https`对数据做了摘要，数据修改易被感知

### HTTPS缺点

`https`保证了通信的安全，但带来了**加密解密消耗计算机cpu资源**的问题 ，不过，有专门的`https`加解密硬件服务器

### HTTP 状态码

状态码第一位数字决定了不同的响应状态，有如下：

- 1 表示消息
- 2 表示成功
- 3 表示重定向
- 4 表示客户端错误
- 5 表示服务器错误

<span style="background:#f9eda6;">1xx（信息性状态码）</span>

表示请求已被接受，需要继续处理。这类响应是临时响应，只包含状态行和某些可选的响应头信息，并以空行结束

> 常见的有：
>
> - 100（客户端继续发送请求，这是临时响应）：这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应
> - 101：服务器根据客户端的请求切换协议，主要用于websocket或http2升级

<span style="background:#f9eda6;">2xx（成功状态码）</span>

表示请求已成功被服务器接收、理解、并接受

> 常见的有：
>
> - 200（成功）：请求已成功，请求所希望的响应头或数据体将随此响应返回
> - 201（已创建）：请求成功并且服务器创建了新的资源
> - 202（已创建）：服务器已经接收请求，但尚未处理完成
> - 203（非授权信息）：服务器已成功处理请求，但返回的信息可能来自另一来源
> - 204（无内容）：服务器成功处理请求，但没有返回任何内容
> - 205（重置内容）：服务器成功处理请求，但没有返回任何内容
> - 206（部分内容）：表示服务器成功处理了部分请求，通常在断点续传或分块下载时使用

<span style="background:#f9eda6;">3xx（重定向状态码）</span>

表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向

> 常见的有：
>
> - 300（多种选择）：针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择
> - 301（永久移动）：请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置
> - 302（临时移动）： 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求
> - 303（查看其他位置）：请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码
> - 304（协商缓存）：服务器通过返回状态码304可以告诉客户端请求资源成功，但是这个资源不是由服务器提供返回给客户端的，而是客户端本地浏览器缓存中就有的这个资源，因为可以从缓存中获取这个资源，从而节省传输的开销。（也有可能是前端没有配置`nginx`代理）
> - 305 （使用代理）： 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理
> - 307 （临时重定向）： 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求

<span style="background:#f9eda6;">4xx（客户端错误状态码）</span>

表示服务器无法处理请求，客户端出现错误。

> 常见的有：
>
> - 400（错误请求）： 服务器不理解请求的语法
> - 401（未授权）： 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。
> - 403（禁止）： 服务器拒绝请求
> - 404（未找到）： 请求的资源不存在
> - 405（方法禁用）： 禁用请求中指定的方法
> - 406（不接受）： 无法使用请求的内容特性响应请求的网页
> - 407（需要代理授权）： 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理
> - 408（请求超时）： 服务器等候请求时发生超时

<span style="background:#f9eda6;">5xx（服务器错误状态码）</span>

表示服务器无法完成明显有效的请求。这类状态码代表了服务器在处理请求的过程中有错误或者异常状态发生

> 常见的有：
>
> - 500（服务器内部错误）：服务器遇到错误，无法完成请求
> - 501（尚未实施）：服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码
> - 502（错误网关）： 服务器作为网关或代理，从上游服务器收到无效响应
> - 503（服务不可用）： 服务器目前无法使用（由于超载或停机维护）
> - 504（网关超时）： 服务器作为网关或代理，但是没有及时从上游服务器收到请求
> - 505（HTTP 版本不受支持）： 服务器不支持请求中所用的 HTTP 协议版本

#### 502排查

502 Bad Gateway 是指服务器作为网关或代理服务器时，未能从上游服务器（如 Tomcat、Nginx、Apache 等）接收到有效的响应。

针对 502 错误，可以从以下几个方面进行排查：

1. **服务状态检查：** 检查服务器的运行状态，确认服务是否正常运行。可以通过访问服务的端点（URL、IP 地址）来确认服务是否可访问。
2. **日志分析：** 查看服务器的日志，如 Nginx、Tomcat、应用程序的日志等，检查是否有相关的错误或异常信息。
3. **网络问题：** 检查网络连接是否正常，可能的网络故障或者代理配置错误也可能导致 502 错误。
4. **服务配置：** 检查服务器的配置文件是否正确，尤其是代理、反向代理或负载均衡器的配置。
5. **后端服务故障：** 如果是代理服务器出现问题，检查上游服务（如后端应用服务器）是否出现故障、负载过高或者超时。
6. **负载均衡器问题：** 如果使用了负载均衡器，检查负载均衡器的状态、配置和日志，确认是否出现故障或配置错误。
7. **数据库连接：** 如果服务依赖数据库，检查数据库连接是否正常，是否存在数据库连接池超时、数据库异常等问题。
8. **系统资源：** 检查服务器的系统资源，如 CPU 使用率、内存占用等，确认是否达到系统资源限制。

### 反向代理

反向代理代表服务器接收客户端的请求，并将这些请求转发到其他服务器上。客户端感知到的是与代理服务器直接通信，而不知道请求实际上是被代理服务器代理转发到了其他服务器上。

**工作原理：**

1. 接收请求： 反向代理服务器接收到客户端的请求。
2. 选择目标服务器： 根据配置或算法选择合适的后端服务器，这可以基于负载均衡算法，比如轮询、加权轮询、最小连接数等。
3. 请求转发： 将接收到的请求转发到选定的后端服务器。
4. 返回结果： 代理服务器接收到后端服务器的响应后，再将结果返回给客户端。

正向代理是代理客户端, 服务端不知道实际发起请求的客户端.

> <font color='Apricot'>作用：</font>
>
> 1. 访问原来无法访问的资源，如google
> 1. 可以做缓存，加速访问资源
> 1. 对客户端访问授权，上网进行认证
> 1. 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

反向代理是代理服务端, 客户端不知道实际提供服务的服务端.

> <font color='Apricot'>作用：</font>
>
> 1. 保证服务器内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。
> 2. 负载均衡，通过反向代理服务器来优化网站的负载。
> 3. 缓存加速：反向代理可以缓存请求结果，减轻后端服务器压力，提高响应速度。
> 4. 协议转换：反向代理可以将不同的协议进行转换，例如将 HTTP 请求转换成 HTTPS 请求。

### 请求过程（工作原理）

`HTTP`和`HTTPS`都需要在建立连接的基础上来进行数据传输,是基本操作，也就是经典`TCP`三次握手建连

1、`http`原理 （`http----->tcp`）

​	建立连接完毕以后客户端会发送请求给服务端

​	服务端接受请求并且做出响应发送给客户端

​	客户端收到响应并且解析响应显示给客户

2、**https原理**（`http------>SSL----->tcp`）

​	1）、在使用`HTTPS`时需要保证服务端配置正确了对应的安全证书，相当于身份证

​	2）、客户端发送请求到服务器端（包括客户端支持的加密协议及版本）

​	3）、服务器端返回证书和公钥到客户端，公钥作为证书的一部分而存在

​	4）、客户端验证证书和公钥的有效性，如果有效，则会随机生成一个随机数，用公钥对其加密，发送到服务端

​	5）、服务端接受到这个加密后的随机数后会用私钥对其解密得到真正的随机数，随后用这个随机数当做私钥对需要发送的数据进行对称加密

​	6）、客户端在接收到加密后的数据使用私钥（即生成的随机值）对数据进行解密并且解析数据呈现结果给客户

​	7）、SSL加密建立

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502172855.png" alt="image-20220502172854241" style="zoom:50%;" />

### 其他问题

1. 怎样保证公开密钥的有效性

   怎么保证公钥是合法的，不是伪造的，证书解决了这个问题，证书由权威的第三方机构颁发，并对公钥做了签名。

2. 金融机构出于安全考虑使用https，那么为什么百度、知乎也使用https？

   为防止运营商（移动、电信等）劫持，运营商可能会在数据中插入各种广告，用了https，数据无法被劫持。

3. **网络七层协议**

   网络七层协议由下往上分别为**物理层**、**数据链路层**、**网络层**、**传输层**、**会话层**、**表示层**、**应用层**。

   其中：HTTP协议对应于应用层，TCP协议对应于传输层、IP协议对应于网络层。HTTP协议是基于TCP连接的，三者本质上没有可比性。

4. TCP/IP、HTTP主要是干什么的？有什么用？

   TCP/IP主要解决数据如何在网络中传输。

   HTTP主要解决如何包装数据。

5. TCP与UDP异同

   二者都是传输层协议，主要区别是可靠服务/不可靠服务

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502173035" alt="img" style="zoom:50%;" />

7. `tcp`三次握手，第三次，客户端怎么知道服务端有没有收到

   > TCP用三次握手（或称三路握手，three-way handshake）过程创建一个连接。在连接创建过程中，很多参数要被初始化，例如序号被初始化以保证按序传输和连接的强壮性。
   >
   > 一对终端同时初始化一个它们之间的连接是可能的。但通常是由一端（服务器端）打开一个套接字（socket）然后监听来自另一方（客户端）的连接，这就是通常所指的被动打开（passive open）。服务器端被被动打开以后，客户端就能开始创建主动打开（active open）。 
   >
   > 服务器端执行了listen函数后，就在服务器上创建起两个队列： 
   >
   > - SYN队列：存放完成了二次握手的结果。 队列长度由listen函数的参数backlog指定。
   > - ACCEPT队列：存放完成了三次握手的结果。队列长度由listen函数的参数backlog指定。 
   >
   > 三次握手协议的过程： 
   >
   > - 客户端（通过执行connect函数）向服务器端发送一个SYN包，请求一个主动打开。该包携带客户端为这个连接请求而设定的随机数A作为消息序列号。
   > - 服务器端收到一个合法的SYN包后，把该包放入SYN队列中；回送一个SYN/ACK。ACK的确认码应为A+1，SYN/ACK包本身携带一个随机产生的序号B。 
   > - 客户端收到SYN/ACK包后，发送一个ACK包，该包的序号被设定为A+1，而ACK的确认码则为B+1。然后客户端的connect函数成功返回。当服务器端收到这个ACK包的时候，把请求帧从SYN队列中移出，放至ACCEPT队列中；这时accept函数如果处于阻塞状态，可以被唤醒，从ACCEPT队列中取出ACK包，重新创建一个新的用于双向通信的sockfd，并返回。
   > -  如果服务器端接到了客户端发的SYN后回了SYN-ACK后客户端掉线了，服务器端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功，也没失败。于是，服务器端如果在一定时间内没有收到的TCP会重发SYN-ACK。
   > - 在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s，TCP才会断开这个连接。使用三个TCP参数来调整行为：tcp_synack_retries 减少重试次数；tcp_max_syn_backlog，增大SYN连接数；tcp_abort_on_overflow决定超出能力时的行为。 “三次握手”的目的是“为了防止已失效的连接(connect)请求报文段传送到了服务端，因而产生错误”，也即为了解决“网络中存在延迟的重复分组”问题。例如：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client发出的一个新的连接请求。于是就向client发出确认报文段，同意创建连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就创建了。由于现在client并没有发出创建连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经创建，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求创建连接。

# 15.进程之间的通信方式？

<span style="background:#f9eda6;">管道( pipe )</span>

管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

<span style="background:#f9eda6;">有名管道 (namedpipe)</span>

有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

<span style="background:#f9eda6;">信号量(semophore )</span>

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

<span style="background:#f9eda6;">消息队列( messagequeue )</span>

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

<span style="background:#f9eda6;">信号 (sinal )</span>

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

<span style="background:#f9eda6;">共享内存(shared memory )</span>

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

<span style="background:#f9eda6;">套接字(socket )</span>

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

## 线程间的通信方式

**锁机制：包括互斥锁、条件变量、读写锁**

- 互斥锁提供了以排他方式防止数据结构被并发修改的方法。
- 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
- 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

**信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量**

**信号机制(Signal)：类似进程间的信号处理**

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

# 写个死锁？怎么解决？

~~~java
public class DeadlockExample {
    private static final Object resource1 = new Object();
    private static final Object resource2 = new Object();

    public static void main(String[] args) {
        Thread thread1 = new Thread(() -> {
            synchronized (resource1) {
                System.out.println("Thread 1: Holding resource 1");
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("Thread 1: Waiting for resource 2");
                synchronized (resource2) {
                    System.out.println("Thread 1: Holding resource 1 and resource 2");
                }
            }
        });

        Thread thread2 = new Thread(() -> {
            synchronized (resource2) {
                System.out.println("Thread 2: Holding resource 2");
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("Thread 2: Waiting for resource 1");
                synchronized (resource1) {
                    System.out.println("Thread 2: Holding resource 1 and resource 2");
                }
            }
        });

        thread1.start();
        thread2.start();
    }
}
~~~

在这个例子中，两个线程分别持有 `resource1` 和 `resource2`，并且互相等待对方释放资源。这会导致两个线程陷入无限的互相等待状态，形成死锁。

<span style="background:#f9eda6;">解决方案</span>

改变获取锁的顺序来避免死锁

~~~java
Thread thread1 = new Thread(() -> {
    synchronized (resource1) {
        System.out.println("Thread 1: Holding resource 1");
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("Thread 1: Waiting for resource 2");
        synchronized (resource2) {
            System.out.println("Thread 1: Holding resource 1 and resource 2");
        }
    }
});

Thread thread2 = new Thread(() -> {
    synchronized (resource1) { // Change the order of locks
        System.out.println("Thread 2: Holding resource 1");
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("Thread 2: Waiting for resource 2");
        synchronized (resource2) {
            System.out.println("Thread 2: Holding resource 1 and resource 2");
        }
    }
});

~~~

# 16.线上 CPU 100%的排查方式

> ①通过 top 命令查看 CPU 情况，如果 CPU 比较高，则通过 top -Hp 命令查看当前进程的各个线程运行情况。
>
> 找出 CPU 过高的线程之后，将其线程 id 转换为十六进制的表现形式，然后在 jstack 日志中查看该线程主要在进行的工作。
>
> 这里又分为两种情况：
>
> 如果是正常的用户线程，则通过该线程的堆栈信息查看其具体是在哪处用户代码处运行比较消耗 CPU。
> 如果该线程是 VM Thread，则通过 jstat -gcutil 命令监控当前系统的 GC 状况。然后通过 jmap dump:format=b,file= 导出系统当前的内存数据。导出之后将内存情况放到 Eclipse 的 Mat 工具中进行分析即可得出内存中主要是什么对象比较消耗内存，进而可以处理相关代码。
>
> ②如果通过 top 命令看到 CPU 并不高，并且系统内存占用率也比较低。此时就可以考虑是否是由于另外三种情况导致的问题。
>
> 具体的可以根据具体情况分析：
>
> 如果是接口调用比较耗时，并且是不定时出现，则可以通过压测的方式加大阻塞点出现的频率，从而通过 jstack 查看堆栈信息，找到阻塞点。
> 如果是某个功能突然出现停滞的状况，这种情况也无法复现，此时可以通过多次导出 jstack 日志的方式对比哪些用户线程是一直都处于等待状态，这些线程就是可能存在问题的线程。
> 如果通过 jstack 可以查看到死锁状态，则可以检查产生死锁的两个线程的具体阻塞点，从而处理相应的问题。

# 17.内存溢出的场景和处理方式、排查手段

<font color='RedOrange'>内存溢出原因：</font>

JVM 虚拟机是使用<font color='Tasma'>引用计数法</font>和<font color='Tasma'>可达性分析</font>来判断对象是否可回收，本质是判断一个对象是否还被引用，如果没有引用则回收。在开发的过程中，由于代码的实现不同就会出现很多种内存泄漏问题，让gc 系统误以为此对象还在引用中，无法回收，造成内存泄漏

<font color='Apricot'>**排查手段**</font>

1. 查看错误信息：

   - 首先，查看控制台或日志中的错误信息，根据错误类型和发生位置初步了解内存溢出的原因。

2. 观察内存溢出发生时的情况：

   - 可以使用`jstat`或`jcmd`命令观察Java堆和方法区的使用情况，了解内存溢出时各个区域的内存占用情况。

   ```
   bashCopy code
   jstat -gcutil <pid> 1000
   ```

3. 检查大对象：

   - 如果存在大对象，尤其是长时间存活的大对象，考虑是否需要调整新生代和老年代的比例，以及调整新生代的大小。
   - 使用`-XX:PretenureSizeThreshold`参数设置大对象直接进入老年代的阈值。

4. 分析GC日志：

   - 对GC日志进行深入分析，关注GC的停顿时间、频率、吞吐量等信息。低吞吐量和频繁的Full GC可能是性能问题的标志。

5. 分析线程Dump：

   - 在分析线程Dump时，注意查看是否存在死锁、竞争条件等多线程问题。

6. 使用内存压测工具：

   - 使用一些内存压测工具（如`jemalloc`、`MAT`工具中的`OQL`查询）对内存进行更深入的分析。

7. 定位资源泄漏：

   - 通过堆转储文件和内存分析工具，定位到具体的对象，查看对象的引用关系，以找出是否存在资源泄漏。

8. 分析业务代码：

   - 分析业务代码，关注可能导致内存溢出的模块，特别是那些频繁创建对象或长时间持有对象引用的地方。

9. 使用GC分析工具：

   - 使用GC分析工具（如`GCEasy`、`GCViewer`）对GC日志进行可视化分析，更直观地了解GC的情况。

10. 代码Review：

    - 进行代码Review，特别是关注一些敏感资源的使用，如数据库连接、文件流等。

<font color='Apricot'>**场景**</font>

1. ThreadLocal 没有 remove

2. 资源未关闭造成的内存泄漏

   > 各种连接，如数据库连接、网络连接和 IO 连接等，文件读写等，可以使用 try-with-resources 读取完文件，自动资源释放

3. 静态集合类和缓存

   > 静态集合或缓存过多，一直占用内存。
   >
   > 如List、Map等。如果这些容器为静态的，那么它们的生命周期与程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。<font color='Magenta'>生命周期长的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。</font>

4. 堆外内存无法回收

   >堆外内存不受gc的管理，可能因为第三方的bug出现内存泄漏

5. 创建大量对象

   >例如在循环中创建对象、递归调用导致栈溢出等

6. 持有大数据集合

   >在内存中保持大的集合，特别是没有及时清理的情况。

<font color='Apricot'>**解决方案**</font>：

1. 尽量减少使用静态变量，或者使用完及时赋值为 null。
2. 明确内存对象的有效作用域，尽量缩小对象的作用域，能用局部变量处理的不用成员变量，因为局部变量栈会自动回收；
3. 减少长生命周期的对象持有短生命周期的引用；
4. 使用StringBuilder和StringBuffer进行字符串连接，Sting和StringBuilder以及StringBuffer等都可以代表字符串，其中String字符串代表的是不可变的字符串，后两者表示可变的字符串。如果使用多个String对象进行字符串连接运算，在运行时可能产生大量临时字符串，这些字符串会保存在内存中从而导致程序性能下降。
5. 对于不需要使用的对象手动设置null值，不管GC何时会开始清理，我们都应及时的将无用的对象标记为可被清理的对象；
6. 各种连接（数据库连接，网络连接，IO连接）操作，务必显式调用close关闭。

# 18.并发量较大的 JVM 优化

1. 选择合适的垃圾收集器：
   - G1垃圾收集器： 适用于大堆和低延迟要求的场景，可以通过参数`-XX:+UseG1GC`启用。
   - CMS垃圾收集器： 适用于对响应时间要求较高的应用，可以通过参数`-XX:+UseConcMarkSweepGC`启用。
   - ZGC垃圾收集器： 高吞吐量和低延迟的选择，适用于大堆场景，可以通过参数`-XX:+UseZGC`启用。
2. 调整堆大小：
   - 使用`-Xms`和`-Xmx`参数调整堆大小，确保合适的堆大小，避免频繁GC。例如，`-Xms2g -Xmx4g`表示初始堆为2GB，最大堆为4GB。
3. 调整新生代比例：
   - 使用参数`-XX:NewRatio`调整新生代与老年代的比例，默认为2。例如，`-XX:NewRatio=1`表示新生代与老年代大小相等。
4. 合理设置线程池：
   - 使用`ThreadPoolExecutor`类创建线程池，通过合理设置`corePoolSize`、`maximumPoolSize`、`keepAliveTime`等参数来控制线程池大小和线程数。
5. 使用本地线程存储（ThreadLocal）：
   - 使用`ThreadLocal`确保每个线程的局部变量，避免共享数据引起的竞争和同步问题。
6. 性能调优和代码Review：
   - 使用性能分析工具，如VisualVM、YourKit等，对应用进行性能调优。通过代码Review找出潜在的性能问题并进行优化。
7. 使用高性能的数据结构和算法：
   - 选择性能较好的数据结构和算法，避免使用低效的集合类。例如，使用`ConcurrentHashMap`代替`Hashtable`。
8. 避免锁竞争：
   - 使用细粒度锁，避免全局锁。使用无锁数据结构，如`java.util.concurrent`包中提供的原子类。
9. 使用缓存：
   - 对于频繁读取的数据，使用缓存技术，如Guava Cache或Caffeine，减少对数据库或其他资源的访问。
10. 并发安全的设计：
    - 设计并发安全的代码，使用合适的同步手段，如`volatile`、`synchronized`、`Lock`等，确保数据一致性。
11. 异步编程：
    - 使用异步框架，如CompletableFuture、RxJava等，以提高并发处理能力。可以考虑使用异步I/O操作，避免线程阻塞。
12. 监控和调优：
    - 部署监控工具，如Prometheus、Grafana等，监控应用的性能指标和资源使用情况。通过监控数据定位性能瓶颈，进行及时调优。
