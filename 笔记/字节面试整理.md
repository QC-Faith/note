# 7. `JAVA`的一些锁

## 锁分类

一种是关键字 `Synchronized`，一种是对象 `lock`，还有一种 `volatile `关键字。

- `Synchronized `用于代码块或方法中，他能使一段代码处于同步执行。
- `lock `跟 `synchronized `类似，但需要自行加锁和释放锁。必须手动释放锁，不然会造成死锁。
  - `lock `比 `synchronized` 更有优势，因为他比 `synchronized `多了嗅探锁定，多路分支通知，判断锁的状态等功能。
  - 嗅探锁定：`lock` 可以使用 `tryLock()` 方法尝试获取锁，若获取不到就继续执行，不会造成线程的阻塞。而 `synchronized `只能进入阻塞他。
  - 多路分支通知：`lock `可以创建多个 `condition`，然后可以将线程对应一个 `condition`，当要唤醒此线程时可以用对应的 `condition `来唤醒。
- `volatile `作用范围小，只作用在一个变量上。`volatile `具有以下三个特性：
  - 可见性：他会从工作内存中复制一份到主内存中，并且每次更新也会随之更新到主内存。当不同线程需要获取其值时，可以从主内存中获取，从而达到一致性。
  - 禁止指令重排：添加了 volatile 关键字的变量，其前面的代码不能运行在此变量后，在后面的代码不能运行在此变量前。
  - `volatile `实际上并不是锁，不具备加锁，阻塞等操作。他使用的方式是根据 `volatile `对象是否变化来判断接下来如何执行。
  - `volatile `也存在缺陷，有时在改变变量时可能还会取到先前的值，但这是非常小的小概率事件。

## Java锁机制

### 1. 公平锁/非公平锁

​	公平锁就是按照先到先得的顺序获得锁。当一个线程获得锁并且没有释放，接下来的线程就会进入阻塞队列等待，并按照队列的方式顺序的获取锁。

​	非公平锁就是新来的线程可以跟阻塞队列的队头争夺一把锁，争夺不过才会添加到队尾。这种情况下，后到的线程有可能无需进入等待队列直接获取锁。

​	`Synchronized `和 `lock `默认都是非公平锁。`lock `可以通过构造函数的方式改为公平锁。

​	非公平锁性能高于公平锁。因为当一个线程执行完释放锁时，阻塞的线程需要被唤醒，这个过程有些漫长。在等待的时间如果有一个活跃的线程想争夺这把锁，就把锁让给他，减少等待的时间。

### 2. 乐观锁/悲观锁

乐观锁和悲观锁是一种概念。

​		乐观锁：很乐观，每次拿数据时都认为数据没有被修改，所以先不加锁。通过判断其版本号来判断此数据是否发生改变。

​		悲观锁：很悲观，每次拿数据时都认为别人会修改数据，这时就要上锁来阻止别人进行修改。

悲观锁比较暴力，直接加锁。

乐观锁一般采用` CAS（compare and swapper）`比较并交换的方式来实现。

- 使用 `volatile` 关键字修饰的变量作为版本号，这是因为 `volatile `具有可见性。

​		实现思路：参考 `AtomicInteger `的实现：

> - 先通过 `get()` 方式从内存中获取到变量的原先值，（这个值当成版本号）。
> - 接下来修改值时调用 `unsafe `里的 `compareAndSwapper()` 方法。
> - 该方法需要传入内存中的基址，偏移量，旧值（版本号），更新的值）
> - 如果旧值和内存里的值一样，就进行交换，如果不一样，说明被人改了，则停止交换，返回 `false`。
> - 交换失败后若还想改变，则必须重新 `get()` 内存里的新值，在进行 `CAS`。

上述有种缺陷：因为该思路将自身值作为版本号，可以任意改变，而正常的版本号是不断增加的。造成的 `ABA ` 的问题：

- 若两个线程同时从内存种取值，取到都是 A。
- 第一个线程停止，第二个线程把 A 换为 B。
- 再来一个线程，把 B 重新换回 A。
- 这时第一个线程执行，他会认为此变量根本没有发生变化。

解决方法：不把自身作为版本号，而是再新建一个字段作为版本号，此版本只能增加，不能回溯。但此时只是版本号来进行 `CAS`，而需要同步的变量只是做普通的改变，这也会造成并发异常。解决方法还是得加锁。

```java
if (version == UNSAFE.getObject()){ // 版本号相比较，比较成功修改
    synchronized(对象){
        // 对象赋值    // 赋值完再更改版本号
        // 更改版本号
    }
}
```

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220502162729.jpg)

### 3. 自旋锁

由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短。所以当一个线程需要等待锁时没有必要挂起，因为用户态和内核态之间的切换十分影响性能。

自旋的利用 `CAS `操作，比较版本号是否相同，如果相同则得到锁，不相同就一直循环获取锁，让其处于活跃态，从而不用挂起线程。

// TODO 自旋锁会自旋多久 一直拿不到会一直自旋吗？ 常问问题

> 自旋锁避免了操作系统进程调度和线程切换，所以自旋锁通常适用在时间比较短的情况下。由于这个原因，**操作系统的内核经常使用自旋锁**。但是，如果长时间上锁的话，自旋锁会非常耗费性能，它阻止了其他线程的运行和调度。线程持有锁的时间越长，则持有该锁的线程将被 `OS(Operating System)` 调度程序中断的风险越大。如果发生中断情况，那么其他线程将保持旋转状态(反复尝试获取锁)，而持有该锁的线程并不打算释放锁，这样导致的结果是无限期推迟，直到持有锁的线程可以完成并释放它为止。
>
> 解决上面这种情况一个很好的方式是给自旋锁设定一个自旋时间，等时间一到立即释放自旋锁。自旋锁的目的是占着CPU资源不进行释放，等到获取锁立即进行处理。如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。JDK在1.6 引入了适应性自旋锁，适应性自旋锁意味着自旋时间不是固定的，而是由前一次在同一个锁上的自旋时间以及锁拥有的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162730.jpg" alt="img" style="zoom: 33%;" />

### 4. 自适应自旋锁

由于一直循环也十分耗费资源。自旋的时间并不是固定的，于是采取了一种方法，当超过了时间就不再进行循环，而是直接将线程挂起。

`jdk1.7` 中 `concurrentHashMap `添加就是采用此操作。

```java
private HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {
    HashEntry<K,V> first = entryForHash(this, hash);   // 得到链表的第一个节点
    HashEntry<K,V> e = first;
    HashEntry<K,V> node = null;
    int retries = -1;      // 重复尝试
    while (!tryLock()) {         // 自旋操作，没有获取到锁
        HashEntry<K,V> f; 
        if (retries < 0) {
            if (e == null) {         // 首节点为 null
                if (node == null) 
                    node = new HashEntry<K,V>(hash, key, value, null);   // 给 node 创建对象
                retries = 0;     // 重复尝试
            }
            else if (key.equals(e.key))   // 添加的节点已存在
                retries = 0;
            else
                e = e.next;
        }
        else if (++retries > MAX_SCAN_RETRIES) {
            // 如果尝试次数大于默认的最大尝试次数，就使用 lock 阻塞。减少资源消耗，自适应自旋
            lock();
            break;
        }
        else if ((retries & 1) == 0 && (f = entryForHash(this, hash)) != first) {
            // 判断首节点是否已经改变，已经改变
            e = first = f;   // 更换首节点
            retries = -1;    // 重新进行尝试，查看当前线程添加的节点是否是新添加的节点
        }
    }
    return node;    // 获得锁时退出循环，并返回此节点
}
```

### 5. 可重入锁

可重入锁就是当线程已获取到了 A 锁，当在执行阶段又需要获取 A 锁，并不会因为 A 锁被人拿走了而进行阻塞，而是因为自己有此锁继续执行。

`Synchronized `和 `ReentrantLock `都是可重入锁，只不过 `Synchronized `自动获取和自动释放锁。`ReentrantLock `得手动获取和释放，并且获取锁的次数必须和释放锁的次数相同，否则会造成死锁。

### 6. 读写锁（共享锁/互斥锁）

`ReentrantLock `类具有完全互斥的效果，同一时间只有一个线程在执行，效率低下。

`JDK `提供了一种读写锁 -- `ReentrantReadWriteLock `类，使用它可以在进行一些操作时不需要同步执行，提高效率。

读锁之间不互斥，读锁和写锁互斥，写锁和写锁互斥（只要出现写锁就互斥）。

## Synchronized 的锁机制

从 `JDK1.6 `版本后，`Synchronized `本身也在不断优化锁的机制，有些情况下它并不是一个很重量级的锁。优化机制包括自适应锁，自旋锁，轻量级锁，重量级锁。

### Java 对象头

java 对象分为三部分：对象头，实体数据，对齐填充符。

- 对象头：
  - `Mark Word`
    - 对象的 `HashCode`
    - 分代年龄
    - GC 标记
    - 锁的标记
  - 指向类的指针
  - 数组长度
- 实例数据
- 对齐填充符

在无锁的状态下，`Mark Word `会记录：对象的 `HashCode`，分代年龄，是否是偏向锁，锁标志。

### 偏向锁

1. 偏向锁的设计理念：

- 由于每次进入和退出同步块都需要获取和释放锁，十分浪费资源。
- 经过大量的验证，发现很多情况下都是同一个线程来获取锁。
- 于是就理想化的让这个锁一直给这个线程。

​	要保证锁是由一个线程来获取，就必须在锁的对象头上添加此线程的 `ID`。于是偏向锁状态下，`Mark Word` 会记录：线程对象的 `HashCode`，分代年龄，是否偏向锁，锁标志。

2. 执行流程：

- 当锁第一次被线程获取，就将线程 `Hashcode `添加到锁的对象头里。
- 线程执行完后并不释放锁。
- 当第二次获取锁，会先判断此线程是否和对象头记录的线程一致，一致的话就直接运行同步代码。
- 若不一致，则锁会升级/膨胀，变成轻量级锁。

​	优点：在没有竞争或者只有一个线程使用锁的情况下，偏向锁节省了获取和释放锁对性能的损耗。

### 轻量级锁

轻量级锁状态下，`Mark Word` 会记录：指向线程栈中锁记录的指针，锁标志位。

- 虚拟机会在线程栈中创建一块内存 `Lock Record` 来存放信息。（从锁的 `Mark Word` 中 `copy`）
- 当线程要获取锁时，会进行 `CAS `操作，将锁的 `Mark Word` 更新为指向栈中锁记录的指针。
- 如果 `CAS `操作成功，则表示该线程获取到锁。
- `CAS `失败，表示锁被别的线程获取到，采用自旋锁的方式来等待获取锁。

优点：避免在了线程的阻塞，当线程获取不到锁时，会进行自旋，而不会阻塞，造成系统调用内核态和用户态。

缺点：如果存在大量竞争，轻量锁采用的 CAS 和自旋操作会大量的消耗资源，程序的性能反而会下降。

适用场景：在没有多线程竞争 IO 少量线程竞争的前提下，使用轻量级锁会减少系统在用户态和内核态之间的转换，提高性能。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170152455.png" alt="image-20241117015258325" style="zoom: 50%;" />

### 重量级锁

重量级锁是依赖对象内部的 `monitor `锁来实现的，而 `monitor `又依赖操作系统的 `MutexLock`（互斥锁）来实现，所以重量级锁也称为互斥锁。

重量级锁需要阻塞线程，唤醒线程，释放锁，消耗资源很大。

// TODO 补充AQS数据结构+实际使用场景+源码分析

## AQS

`AQS` 是多线程同步器，它是 `JUC` 包中多个组件的底层实现，如 `Lock、 CountDownLatch、Semaphore `等都用到了 `AQS`.

从本质上来说，`AQS` 提供了两种锁机制，分别是 排它锁 和 共享锁。 排它锁，就是存在多线程竞争同一共享资源时，同一时刻只允许一个线程访问该共享资源，也就是多个线程中只能有一个线程获得锁资源，比如 `Lock` 中的 `ReentrantLock` 重入锁实现就是用到了 `AQS` 中的排它锁功能。 共享锁也称为读锁，就是在同一时刻允许多个线程同时获得锁资源，比如 `CountDownLatch` 和 `Semaphore` 都是用到了 `AQS` 中的共享锁功能。

1. `AQS` 在内部定义了一个 `volatile int state` 变量，表示同步状态:当线程调用 `lock` 方法时 ，如果 `state=0`，说明没有任何线程占有共享资源的锁，可以获得锁并将 `state=1`;如果 `state=1`，则说明有线程目前正在 使用共享变量，其他线程必须加入同步队列进行等待。
2. `AQS` 通过 `Node` 内部类构成的一个双向链表结构的同步队列，来完成线程获取锁的排队工作，当有线程获取锁失败后，就被添加到队列末尾。`Node` 类是对要访问同步代码的线程的封装，包含了线程本身及其状态叫`waitStatus`(有五种不同 取值，分别表示是否被阻塞，是否等待唤醒， 是否已经被取消等)，每个 `Node` 结点关联其 `prev` 结点和 `next` 结 点，方便线程释放锁后快速唤醒下一个在等待的线程，是一个 `FIFO` 的过 程。`Node` 类有两个常量，`SHARED` 和 `EXCLUSIVE`，分别代表共享模式和独占模式。所谓共享模式是一个锁允许多条线程同时操作(信号量`Semaphore` 就是基于 `AQS` 的共享模式实现的)，独占模式是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待 ( 如 `ReentranLock`) 。
3. `AQS` 通过内部类 `ConditionObject` 构建等待队列(可有多个)，当`Condition` 调用 `wait()` 方法后，线程将会加入等待队列中，而当`Condition` 调用 `signal()` 方法后，线程将从等待队列转移动同步队列中进行锁竞争。
4. `AQS` 和 `Condition` 各自维护了不同的队列，在使用 `Lock` 和`Condition` 的时候，其实就是两个队列的互相移动。

# 写个死锁？怎么解决？

~~~java
public class DeadlockExample {
    private static final Object resource1 = new Object();
    private static final Object resource2 = new Object();

    public static void main(String[] args) {
        Thread thread1 = new Thread(() -> {
            synchronized (resource1) {
                System.out.println("Thread 1: Holding resource 1");
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("Thread 1: Waiting for resource 2");
                synchronized (resource2) {
                    System.out.println("Thread 1: Holding resource 1 and resource 2");
                }
            }
        });

        Thread thread2 = new Thread(() -> {
            synchronized (resource2) {
                System.out.println("Thread 2: Holding resource 2");
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("Thread 2: Waiting for resource 1");
                synchronized (resource1) {
                    System.out.println("Thread 2: Holding resource 1 and resource 2");
                }
            }
        });

        thread1.start();
        thread2.start();
    }
}
~~~

在这个例子中，两个线程分别持有 `resource1` 和 `resource2`，并且互相等待对方释放资源。这会导致两个线程陷入无限的互相等待状态，形成死锁。

<span style="background:#f9eda6;">解决方案</span>

改变获取锁的顺序来避免死锁

~~~java
Thread thread1 = new Thread(() -> {
    synchronized (resource1) {
        System.out.println("Thread 1: Holding resource 1");
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("Thread 1: Waiting for resource 2");
        synchronized (resource2) {
            System.out.println("Thread 1: Holding resource 1 and resource 2");
        }
    }
});

Thread thread2 = new Thread(() -> {
    synchronized (resource1) { // Change the order of locks
        System.out.println("Thread 2: Holding resource 1");
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("Thread 2: Waiting for resource 2");
        synchronized (resource2) {
            System.out.println("Thread 2: Holding resource 1 and resource 2");
        }
    }
});

~~~



# 8. JVM

## Java内存模型

Java内存模型，是Java虚拟机规范中所定义的一种内存模型，Java内存模型是标准化的，屏蔽掉了底层不同计算机的区别。 Java内存模型是一套规范，描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量存储到内存和从内存中读取变量这样的底层细节，根据官方的解释，主要是在说两个关键字，一个是`volatile`，一个是`synchronized`。

<font color='Apricot'>主内存</font>：主内存是所有线程都共享的，都能访问的。所有的共享变量都存储于主内存。

<font color='Apricot'>工作内存</font>：每一个线程有自己的工作内存，工作内存只存储该线程对共享变量的副本。线程对变量的所有的操 作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量，不同线程之间也不能直接访问对方工作内存中的变量。Java的线程不能直接在主内存中操作共享变量。而是首先将主内存中的共享变量赋值到自己的工作内存中，再进行操作，操作完成之后，刷回主内存。

<font color='Apricot'>Java内存模型的作用</font>：Java内存模型是一套在多线程读写共享数据时，对共享数据的可见性、有序性、和原子性的规则和保障。 synchronized,volatile



<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428162220.jpg" alt="img" style="zoom:67%;" />

## Java内存结构

- <font color='Magenta'>堆：</font>线程共享。所有的对象实例以及数组都要在堆上分配。是垃圾回收的主要操作区域。

  - 从结构上来分，可以分为新生代(`1/3`)和老年代(`2/3`)。而新生代又可以分为Eden 空间(`8/10`)、From Survivor 空间（`1/10`）、To Survivor 空间（`1/10`）。 所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。
  - Java 虚拟机规范规定，堆可以处于物理上不连续的内存空间，只要逻辑上连续即可。在实现时，即可实现成固定大小也可以是可扩展的，当前主流虚拟机都是按照可扩展来实现的
  - 控制参数：`-Xms`设置堆的最小空间大小。`-Xmx`设置堆的最大空间大小。`-XX:NewSize`设置新生代最小空间大小。`-XX:MaxNewSize`设置新生代最大空间大小。

  - 异常情况：
    - 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出`OutOfMemoryError `异常

- <font color='Magenta'>方法区：</font>线程共享。主要存储已被虚拟机加载的**类信息、常量、静态变量、即时编译器编译后的代码**等数据。

  - Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择<font color='Peach'>不实现垃圾收集</font>。相对而言垃圾收集在此区域较少出现，但并非数据进了方法区就永久存在了。这个区域的垃圾回收目标主要是针对常量池的回收和对类型的卸载。
  - 运行时常量池是方法区的一部分，用于存放编译期生成的各种字面常量和符号引用
  - 控制参数：`-XX:PermSize` 设置最小空间 `-XX:MaxPermSize` 设置最大空间。

  - 异常情况： 当方法区无法满足内存分配需求时，将抛出`OutOfMemoryError`。

- <font color='Magenta'>Java 虚拟机栈：</font>线程私有，生命周期与线程相同。它描述的是 `Java` 方法执行的内存模型，每个方法在执行的时候都会创建一个栈帧用于**存储局部变量表、操作数栈、动态链接、方法返回地址**等信息，每个方法从被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

  - 控制参数：`-Xss`控制每个线程栈的大小。

  - 异常情况：
    - `- StackOverflowError`： 异常线程请求的栈深度大于虚拟机所允许的深度时抛出；
    - `- OutOfMemoryError` ： 虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出。
    
    > **局部变量表和操作数栈的区别**
    >
    > 1. **局部变量表**：
    >    - 局部变量表是JVM栈中的一部分，用于存储方法的参数和局部变量。
    >    - 每个方法在运行时都会创建一个新的局部变量表，用于存储该方法的参数和局部变量。
    >    - 局部变量表的容量在编译时确定，并且是一个固定的槽位数，其中包括方法参数和方法体中定义的局部变量。
    >    - 局部变量表的槽位是按索引访问的，索引从0开始，对应不同的参数和局部变量。
    >    - 局部变量表的大小在编译时确定，并且与方法的签名和方法体中定义的局部变量数量有关。
    > 2. **操作数栈**：
    >    - 操作数栈是JVM栈中的一部分，用于执行方法中的操作指令。
    >    - 操作数栈是一个后进先出（LIFO）的数据结构，用于临时存储方法执行过程中的操作数和中间结果。
    >    - 操作数栈的容量在编译时确定，并且根据方法的字节码指令确定每个操作数的类型和数量。
    >    - 操作数栈的操作包括压栈（push）、弹栈（pop）等，用于执行算术运算、逻辑运算、方法调用等操作。
    >    - 操作数栈的容量通常比局部变量表小，因为它主要用于存储方法执行过程中的临时数据，而不是方法的参数和局部变量。

- <font color='Magenta'>本地方法栈：</font>线程私有。与`Java` 虚拟机栈作用相似（包括控制参数和异常情况），`Java` 虚拟机栈是为 `Java` 方法服务，本地方法栈为虚拟机使用到的`Native` 方法服务。如 Java 使用 `c` 或者 `c++` 编写的接口服务时，代码在此区运行。

- <font color='Magenta'>程序计数器：</font>线程私有。它可以看作是当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。如果执行的是方法，这里记录的是虚拟机字节码指令的地址，当执行 `Native` 方法的时候为空（`Undefined`）。因为只存储一个指令，所以它也是唯一一个在 `Java` 虚拟机规范中没有规定任何`OutOfMemory Error`情况的区域。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428162439.jpg" alt="img" style="zoom:67%;" />

## 常见内存溢出错误

```text
Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space
```

原因：对象不能被分配到堆内存中。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space
```

原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit
```

原因：创建的数组大于堆内存的空间。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: request <size> bytes for <reason>. Out of swap space?
```

原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。

```text
Exception in thread “main”: java.lang.OutOfMemoryError: <reason> <stack trace>（Native method）
```

原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现。

## 堆的划分

**1、堆结构分代的意义**

JVM的内存分代策略：Java虚拟机根据对象存活的周期不同，一般把堆内存划分为新生代、老年代和永久代（对HotSpot虚拟机而言）。

> 堆内存是虚拟机管理的内存中最大的一块，也是垃圾回收最频繁的一块区域，我们程序所有的对象实例都存放在堆内存中。给堆内存分代是为了提高对象内存分配和垃圾回收的效率。试想一下，如果堆内存没有区域划分，所有新创建的对象和生命周期很长的对象放在一起，随着程序的执行，堆内存需要频繁进行垃圾收集，而每次回收都要遍历所有的对象，遍历这些对象所花费的时间代价是巨大的，会严重影响我们的GC效率。
>
> 有了内存分代，情况就不同了，新创建的对象会在新生代中分配内存，经过多次回收仍然存活下来的对象存放在老年代中，静态属性、类信息等存放在永久代中，新生代中的对象存活时间短，只需要在新生代区域中频繁进行GC，老年代中对象生命周期长，内存回收的频率相对较低，不需要频繁进行回收，永久代中回收效果太差，一般不进行垃圾回收，还可以根据不同年代的特点采用合适的垃圾收集算法。分代收集大大提升了收集效率，这些都是内存分代带来的好处。

**2、堆结构分代**

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220428163721.jpg" alt="img" style="zoom:50%;" />

　　Java虚拟机将堆内存划分为新生代、老年代和永久代，永久代是`HotSpot`虚拟机特有的概念（`JDK1.8`之后为`metaspace`替代永久代），它采用永久代的方式来实现方法区，其他的虚拟机实现没有这一概念，而且`HotSpot`也有取消永久代的趋势，在`JDK 1.7`中`HotSpot`已经开始了“去永久化”，把原本放在永久代的字符串常量池移出。永久代主要存放常量、类信息、静态变量等数据，与垃圾回收关系不大，新生代和老年代是垃圾回收的主要区域。

1. 新生代（Young Generation）

   > - 新生成的对象优先存放在新生代中，新生代对象朝生夕死，存活率很低，在新生代中，常规应用进行一次垃圾收集一般可以回收`70% ~ 95%` 的空间，回收效率很高。
   > - `HotSpot`将新生代划分为三块，一块较大的Eden（伊甸）空间和两块较小的Survivor（幸存者）空间，默认比例为`8：1：1`。划分的目的是因为`HotSpot`采用复制算法来回收新生代，设置这个比例是为了充分利用内存空间，减少浪费。新生成的对象在`Eden`区分配（大对象除外，大对象直接进入老年代），当`Eden`区没有足够的空间进行分配时，虚拟机将发起一次`Minor GC`。
   > - GC开始时，对象只会存在于`Eden`区和`From Survivor`区，`To Survivor`区是空的（作为保留区域）。GC进行时，`Eden`区中所有存活的对象都会被复制到`To Survivor`区，而在`From Survivor`区中，仍存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阀值（默认为15，新生代中的对象每熬过一轮垃圾回收，年龄值就加1，GC分代年龄存储在对象的`header`中）的对象会被移到老年代中，没有达到阀值的对象会被复制到`To Survivor`区。接着清空`Eden`区和`From Survivor`区，新生代中存活的对象都在`To Survivor`区。接着， `From Survivor`区和`To Survivor`区会交换它们的角色，也就是新的`To Survivor`区就是上次`GC`清空的`From Survivor`区，新的`From Survivor`区就是上次`GC`的`To Survivor`区，总之，不管怎样都会保证`To Survivor`区在一轮`GC`后是空的。`GC`时当`To Survivor`区没有足够的空间存放上一次新生代收集下来的存活对象时，需要依赖老年代进行分配担保，将这些对象存放在老年代中。

2. 老年代（Old Generationn）

   > 在新生代中经历了多次（具体看虚拟机配置的阀值）GC后仍然存活下来的对象会进入老年代中。老年代中的对象生命周期较长，存活率比较高，在老年代中进行GC的频率相对而言较低，而且回收的速度也比较慢。

3. 永久代（Permanent Generationn）

   > 永久代存储类信息、常量、静态变量、即时编译器编译后的代码等数据，对这一区域而言，Java虚拟机规范指出可以不进行垃圾收集，一般而言不会进行垃圾回收。

## 永久代和方法区

1、方法区

　　方法区（Method Area）是`jvm`规范里面的运行时数据区的一个组成部分，`jvm`规范中的运行时数据区还包含了：pc寄存器、虚拟机栈、堆、方法区、运行时常量池、本地方法栈。主要用来存储`class`、运行时常量池、字段、方法、代码、`JIT`代码等。运行时数据区跟内存不是一个概念，方法区是运行时数据区的一部分。方法区是`jvm`规范中的一部分，并不是实际的实现，切忌将规范跟实现混为一谈。

2、永久代

　　永久带又叫`Perm`区，只存在于`hotspot jvm`中，并且只存在于`jdk7`和之前的版本中，`jdk8`中已经彻底移除了永久带，`jdk8`中引入了一个新的内存区域叫`metaspace`。并不是所有的`jvm`中都有永久带，`ibm`的`j9`，`oracle`的`JRocket`都没有永久带，永久带是实现层面的东西，永久带里面存的东西基本上就是方法区规定的那些东西。

3、区别

　　方法区是规范层面的东西，规定了这一个区域要存放哪些东西，永久带或者是`metaspace`是对方法区的不同实现，是实现层面的东西。

4、`hotspot jdk8`中移除了永久带以后的内存结构

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502162939.jpg" alt="img" style="zoom:50%;" />

// TODO 分别补充G1&CMS内存区别

## 类加载过程

Java类加载过程是Java虚拟机（JVM）将.class文件中的字节码装载到内存中，分为五个部分：加载，检验，准备，解析，初始化，在类加载的过程中，这些阶段会互相混合，交叉运行，最终完成类的加载和初始化。

> 例如在加载阶段，需要使用验证的能力去校验字节码正确性。在解析阶段，也要使用验证的能力去校验符号引用的正确性。或者加载阶段生成Class对象的时候，需要解析阶段符号引用转直接引用的能力等等......

1. <font color='RedOrange'>加载阶段</font>

   > 这个过程主要由加载器完成三件事情：
   >
   > 1. 通过类的全限定名来获取定义此类的二进制字节流
   > 2. 将这个类字节流代表的静态存储结构转为方法区的运行时数据结构
   > 3. 在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。
   >
   > Java虚拟机并没有规定类的字节流必从.class文件中加载，在加载阶段，程序员可以通过自定义的类加载器，自行定义读取的地方，例如通过网络、数据库等。

2. <font color='RedOrange'>检验阶段</font>

   > 此阶段主要确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机的自身安全。
   >
   > 1. 文件格式验证：基于字节流验证。
   > 2. 元数据验证：基于方法区的存储结构验证。
   > 3. 字节码验证：基于方法区的存储结构验证。
   > 4. 符号引用验证：基于方法区的存储结构验证。

3. <font color='RedOrange'>准备阶段</font>

   > 为类变量分配内存，并将其初始化为默认值。（此时为默认值，在初始化的时候才会给变量赋值）即在方法区中分配这些变量所使用的内存空间。例如：
   >
   > ```csharp
   > public static int value = 123;
   > ```
   >
   > 此时在准备阶段过后的初始值为0而不是123；将value赋值为123的putstatic指令是程序被编译后，存放于类构造器<client>方法之中
   >
   > ```java
   > // 特例：
   > public static final int value = 123;
   > ```
   >
   > 此时value的值在准备阶段过后就是123。

4. <font color='RedOrange'>解析阶段</font>

   > 把类型中的符号引用转换为直接引用。
   >
   > - 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。
   > - 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在
   >
   > 主要有以下四种：
   >
   > 1. 类或接口的解析
   > 2. 字段解析
   > 3. 类方法解析
   > 4. 接口方法解析

5. <font color='RedOrange'>初始化阶段</font>

   > 初始化阶段是执行类构造器<client>方法的过程。<client>方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证<client>方法执行之前，父类的<client>方法已经执行完毕。如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成<client>()方法。
   >
   > Java 中，对于初始化阶段，有且只有以下五种情况才会要求类立刻“初始化”（加载，验证，准备，自然需要在此之前开始）：
   >
   > 1. 使用new关键字实例化对象、访问或者设置一个类的静态字段（被final修饰、编译器优化时已经放入常量池的例外）、调用类方法，都会初始化该静态字段或者静态方法所在的类。
   > 2. 初始化类的时候，如果其父类没有被初始化过，则要先触发其父类初始化。
   > 3. 使用java.lang.reflect包的方法进行反射调用的时候，如果类没有被初始化，则要先初始化。
   > 4. 虚拟机启动时，用户会先初始化要执行的主类（含有main）
   > 5. jdk 1.7后，如果java.lang.invoke.MethodHandle的实例最后对应的解析结果是 REF_getStatic、REF_putStatic、REF_invokeStatic方法句柄，并且这个方法所在类没有初始化，则先初始化。

**类加载器**

> 把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作交给虚拟机之外的类加载器来完成。这样的好处在于，我们可以自行实现类加载器来加载其他格式的类，只要是二进制字节流就行，这就大大增强了加载器灵活性。系统自带的类加载器分为三种：
>
> 1. 启动类加载器。
> 2. 扩展类加载器。
> 3. 应用程序类加载器。

### 双亲委派机制

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170154952.png" alt="image-20241117015408830" style="zoom:67%;" />

双亲委派机制工作过程：

> <font color='RedOrange'>工作过程</font>：如果一个类加载器收到了类加载的请求，它首先会将这个任务委派给父加载器去完成，每个层次的类加载器都是如此。因此所有的加载请求最终都会传送到Bootstrap类加载器(启动类加载器)中。只有父类加载反馈自己无法加载这个请求(它的搜索范围中没有找到所需的类)时。子加载器才会尝试自己去加载。
>
> <font color='RedOrange'>优点</font>：<font color='Peach'>使用双亲委派模式，可以保证，每一个类只会有一个类加载器</font>。
>
> <font color='RedOrange'>注意</font>：不同的类加载器，加载同一个类，结果是虚拟机里会存在两份这个类的信息，所以当判断这两个类是否“相等”时，必定是不相等的。
>
> <font color='RedOrange'>举例</font>：例如类java.lang.Object，它存放在`rt.jar`之中。无论哪一个类加载器都要加载这个类。最终都是双亲委派模型最顶端的Bootstrap类加载器去加载。因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户编写了一个称为“java.lang.Object”的类，并存放在程序的ClassPath中，那系统中将会出现多个不同的Object类，java类型体系中最基础的行为也就无法保证，应用程序也将会一片混乱。

## 垃圾回收算法

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202401081446835.png" alt="img" style="zoom: 40%;" />

**1. 标记-清除算法**：

- 标志清除算法有两个阶段：

  > 1. 标记阶段：找到所有可访问的对象，做个标记
  > 2. 清除阶段：遍历堆，把未被标记的对象回收

- 应用场景：

  一般应用于老年代,因为老年代的对象生命周期比较长

- 优缺点:

  > 优点:
  >
  > 1. 可以解决循环引用的问题
  > 2. 内存不足时才回收
  >
  > 缺点：
  >
  > 1. 回收时，应用需要挂起。
  > 2. 标记和清除的效率不高，尤其是要扫描的对象比较多的时候
  > 3. 会造成内存碎片(会导致明明有内存空间,但是由于不连续,申请稍微大一些的对象无法做到)

**2. 复制算法**：

- 一开始就会将可用内存分为两块，from域和to域， 每次只是使用from域，to域空闲。当from域内存不够开始执行GC操作时，会把from域存活的对象拷贝到to域然后直接对from域进行内存清理。

- 应用场景：一般是使用在**新生代**中，因为新生代中的对象一般都是朝生夕死的，存活对象的数量并不多，这样使用coping算法进行拷贝时效率比较高。

  > JVM 将 Heap 内存划分为新生代与老年代，又将新生代划分为Eden(伊甸园) 与2块Survivor Space(幸存者区) ,然后在Eden –>Survivor Space 以及From Survivor Space 与To Survivor Space 之间实行Copying 算法。
  >
  > 不过jvm在应用coping算法时，并不是把内存按照1:1来划分的，这样太浪费内存空间了。一般的jvm都是8:1。也即是说:
  >
  > ```
  > Eden区:From区:To区域 = 8:1:1
  > ```
  >
  > 始终有90%的空间是可以用来创建对象的,而剩下的10%用来存放回收后存活的对象。

  ![image-20240108143122702](https://gitee.com/qc_faith/picture/raw/master/image/202401081431883.png)

- 图中流程解析：

  > 1.当Eden区满的时候，会触发第一次young gc，把还活着的对象拷贝到Survivor From区；当Eden区再次触发young gc的时候，会扫描Eden区和From区域，对两个区域进行垃圾回收，经过这次回收后还存活的对象，则直接复制到To区域，并将Eden和From区域清空。
  >
  > 2.当后续Eden又发生young gc的时候，会对Eden和To区域进行垃圾回收，存活的对象复制到From区域，并将Eden和To区域清空。
  >
  > 3.可见部分对象会在From和To区域中复制来复制去，如此交换15次(由JVM参数MaxTenuringThreshold决定，这个参数默认是15)，最终如果还是存活，就存入到老年代

- 注意: 万一存活对象数量比较多，那么To域的内存可能不够存放，这个时候会借助老年代的空间。

- 优缺点：

  > 优点：在存活对象不多的情况下，性能高，能解决内存碎片和java垃圾回收算法 - 标记清除 中导致的引用更新问题。
  >
  > 缺点：会造成一部分的内存浪费。不过可以根据实际情况，将内存块大小比例适当调整；如果存活对象的数量比较大，coping的性能会变得很差。

**3. 标记-压缩（整理）算法**：

- 标记压缩算法 和 标记清除算法非常相似，但是标记压缩算法 在 标记清除算法 之上解决了内存碎片化。

- 压缩算法压缩对象的顺序主要分为如下几类：

  > - 任意顺序 : 即不考虑原先对象的排列顺序，也不考虑对象之间的引用关系，随意移动对象；
  > - 线性顺序 : 考虑对象的引用关系，例如a对象引用了b对象，则尽可能将a和b移动到一块；
  > - 滑动顺序 : 按照对象原来在堆中的顺序滑动到堆的一端。

- 优点是解决内存碎片问题。缺点是压缩阶段由于移动了可用对象，需要去更新引用。

**4. 分代算法**：

- 这种算法，根据对象的存活周期的不同将内存划分成几块，新生代和老年代，<font color='Peach'>新生代基本采用复制算法，老年代采用标记整理算法</font>。

  > **新生代** ：在新生代，每次垃圾收集器都发现有大批对象死去，只有少量存活，采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集；
  >
  > **老年代** ：而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须“标记－清除－压缩”算法进行回收。新创建的对象被分配在新生代，如果对象经过几次回收后仍然存活，那么就把这个对象划分到老年代。老年代区存放Young区Survivor满后触发minor GC后仍然存活的对象，当Eden区满后会将存活的对象放入Survivor区域，如果Survivor区存不下这些对象，GC收集器就会将这些对象直接存放到Old区中，如果Survivor区中的对象足够老，也直接存放到Old区中。如果Old区满了，将会触发Full GC回收整个堆内存。

### Minor GC 和Full GC

新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。

老年代 GC（Major GC/Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC慢10倍以上。

Minor GC触发机制：

> 当年轻代满时就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发

Full GC触发机制:

> 当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代，当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载

虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁）时，就会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold (阈值)来设置。

## CMS收集器

CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，基于并发“标记清理”实现，在标记清理过程中不会导致用户线程无法定位引用对象。仅作用于老年代收集。分为以下四个流程：

1. 初始标记（CMS initial mark <font color='Apricot'>STW</font>）：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。
2. 并发标记（CMS concurrent mark）：对「初始标记阶段」标记的对象进行整个引用链的扫描，它在整个回收过程中耗时最长，可能发生漏标。不需要停顿。
3. 重新标记（CMS remark <font color='Apricot'>STW</font>）：对「并发标记」阶段出现的问题进行校正，需要停顿。
4. 并发清理（CMS concurrent sweep）：可以和用户线程并发执行，清理在重复标记中被标记为可回收的对象。不需要停顿。

### CMS的优点：

- 支持并发收集.
- 低停顿，因为`CMS`可以控制将耗时的两个`stop-the-world`操作保持与用户线程恰当的时机并发执行，并且能保证在短时间执行完成，这样就达到了近似并发的目的.

### CMS的缺点：

- 吞吐量低: 低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。
- 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。
- 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。

### 使用场景

​	

## G1收集器

堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。G1 把堆划分成多个大小相等的独立区域(Region)，新生代和老年代不再物理隔离。通过引入 Region 的概念，将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。通过记录每个 Region 垃圾回收时间以及回收所获得的空间(这两个值是通过过去回收的经验获得)，并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。

<font color='Apricot'>G1 回收流程：</font>

1. 初始标记（Initial Marking <font color='RedOrange'>STW</font>）：所有应用线程会被暂停，标记出从 GC Root 开始直接可达的对象。

   > 标记一下`GC Roots`能直接关联到的对象，伴随着一次普通的`Young GC`发生，并修改`NTAMS`（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，此阶段是`stop-the-world`操作，但是耗时很短，而且是借用进行 Minor GC 的时候同步完成的，所以在这个阶段实际并没有额外的停顿。

2. 并发标记（Concurrent Marking）：是从`GC Roots`开始堆中对象进行可达性分析，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行，该阶段可以被`Young GC`中断。

3. 最终标记（Final Marking <font color='RedOrange'>STW</font>）：标记那些在并发标记阶段发生变化的对象，将被回收。

   > 是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程`Remembered Set Logs`里面，最终标记阶段需要把`Remembered Set Logs`的数据合并到`Remembered Set`中。这阶段需要停顿线程，但是可并行执行。

4. 筛选回收（Live Data Counting and Evacuation <font color='RedOrange'>STW</font>）：对各个 Region 的回收价值和成本进行排序，根据用户所期待的 GC 停顿时间来指定回收计划，可以自由选择多个 Region 构成回收集，然后把决定回收的那一部分 Region 的存活对象复制到空的 Region 中，再清理掉整个旧 Region 的全部空间。这里的操作涉及存活对象的移动，必须暂停用户线程，由多条收集器线程并行完成

### G1 的 GC 模式

G1 中提供了 <font color='Peach'>Young GC</font>、<font color='Peach'>Mixed GC</font> 两种垃圾回收模式，这两种垃圾回收模式，都是 Stop The World(STW) 的。

1. <font color='Apricot'>YoungGC 年轻代收集</font>

   > 在分配一般对象（非巨型对象）时，当所有 eden 区使用达到最大阀值、并且无法申请足够内存时，会触发一次 YoungGC 。
   >
   > 每次 YoungGC 会回收所有 Eden 、以及 Survivor 区，并且将存活对象复制到 Old 区以及另一部分的 Survivor 区。
   >
   > <font color='Magenta'>YoungGC 的回收过程</font>：
   >
   > - 根扫描，跟 CMS 类似，Stop the world，扫描 GC Roots 对象；
   > - 处理 Dirty card，更新 RSet；
   > - 扫描 RSet ，扫描 RSet 中所有 old 区，对扫描到的 young 区或者 survivor 区的引用；
   > - 拷贝扫描出的存活的对象到 survivor2/old 区；
   > - 处理引用队列、软引用、弱引用、虚引用。

2. <font color='RedOrange'>Mixed GC</font>

   > 当越来越多的对象晋升到老年代 old 区时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 Mixed GC，该算法并不是一个 old gc ，除了回收整个 young 区，还会回收一部分的 old 区。
   >
   > 这里需要注意：是一部分老年代，而不是全部老年代，可以选择哪些 old region 进行收集，从而可以对垃圾回收的耗时时间进行控制。
   >
   > G1 没有 Full GC 概念，需要 Full GC 时，调用 serialOldGC 进行全堆扫描（包括 eden、survivor、o、perm）。

### G1的特点

- 算法： G1 基于标记--整理算法，不会产生空间碎片，在分配大对象时，不会因无法得到连续的空间，而提前触发一次 FULL GC 。
- 并行与并发：G1充分发挥多核性能，使用多CPU来缩短Stop-The-world的时间，
- 分代收集：G1能够自己管理不同分代内已创建对象和新对象的收集。
- 停顿时间可控： G1 可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象。

### 使用场景

- 实时数据占用超过一半的堆空间
- 对象分配或者晋升的速度变化大
- 希望消除长时间的GC停顿（超过0.5-1秒）

## FullGC

哪些因素会影响fullGC的卡顿时间，以及如何减少fullGC卡顿时间

>
> Full GC（Full Garbage Collection）卡顿时间的影响因素主要包括以下几个方面：
>
> 1. **堆内存大小**：如果堆内存过小，会导致频繁的垃圾回收，增加了 Full GC 的发生频率；如果堆内存过大，会增加 Full GC 的执行时间，因为垃圾回收器需要扫描更多的对象。
> 2. **对象存活时间**：长时间存活的对象会进入老年代，当老年代空间不足时，会触发 Full GC。因此，优化对象的存活时间，尽量使对象的存活时间较短，可以减少 Full GC 的频率和执行时间。
> 3. **堆内存分配策略**：不同的堆内存分配策略会影响 Full GC 的执行时间。例如，使用并发标记清除算法（CMS）或 G1 垃圾收集器可以在垃圾收集的同时允许程序继续执行，从而减少 Full GC 的停顿时间。
> 4. **垃圾回收器的选择**：例如，CMS 垃圾收集器适用于对响应时间要求较高的应用，而 G1 垃圾收集器适用于大堆内存的应用。
> 5. **并发和并行度设置**：垃圾回收器的并发和并行度设置会影响 Full GC 的执行效率。合理设置并发和并行度参数可以提高垃圾回收的效率，减少 Full GC 的卡顿时间。
> 6. **内存分区和内存管理**：合理使用内存分区和内存管理技术，如将堆内存分成多个区域（新生代、老年代和永久代或元空间），可以针对不同区域采用不同的垃圾收集策略，从而减少 Full GC 的执行时间。
> 7. **应用程序的特点和行为**：应用程序的特点和行为也会影响 Full GC 的卡顿时间。例如，频繁创建和销毁大量对象、长时间持有对象的引用、内存泄漏等问题都会导致 Full GC 的频繁触发和执行时间的增加。
>
> 为了减少 Full GC 的卡顿时间，可以采取以下措施：
>
> - 合理设置堆内存大小，避免堆内存过小或过大；
> - 优化对象的创建和销毁，减少临时对象的创建和长时间存活的对象；
> - 选择合适的垃圾回收器和垃圾回收策略，根据应用场景和性能需求进行调优；
> - 使用并发和并行垃圾收集器，提高垃圾回收的效率；
> - 优化内存分区和内存管理，合理使用内存分区和内存分配策略；
> - 优化应用程序的设计和实现，避免频繁触发 Full GC 的情况发生。

## 四种引用类型

JVM 垃圾回收中，GC判断堆中的对象实例或数据是不是垃圾的方法有 <font color='Apricot'>引用计数法</font> 和 <font color='Apricot'>可达性算法</font> 两种。

**引用计数器法**：为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。缺点是不能解决循环引用的问题。

**可达性分析算法**：从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是可以被回收的。

无论是通过引用计数算法判断对象的引用数量，还是通过根搜索算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。

- 强引用（Strong Reference）：一个对象通过一串强引用链接可到达，即使内存不足抛出OutOfMemoryError，也不会回收该对象。
- 软引用（Soft Reference）：对于一些非必须，但仍有用的对象，内存不足时，系统会回收软引用对象
- 弱引用（Weak Reference）：随时可能被垃圾回收器回收，无论内存是否足够，只要JVM开始进行垃圾回收，被弱引用关联的对象都会被回收。
- 虚引用（Phantom Reference）：所有引用类最脆弱的一个，如果一个对象持有虚引用，那么这个对象随时可能被回收，甚至不能通过get方法来获得其指向的对象。虚引用唯一的作用是，当其指向的对象被回收后，自己被加入到引用队列，用做记录该引用指向的对象已被销毁。

这四种引用强度依次逐渐减弱。

Java 中引入四种引用的目的是让程序自己决定对象的生命周期，JVM 是通过垃圾回收器对这四种引用做不同的处理，来实现对象生命周期的改变。

<font color='RedOrange'>强引用</font>

> 最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。类似 `“Object obj = new Object()”` 这类的引用。
>
> 当一个对象被强引用变量引用时，它处于可达状态，是不可能被垃圾回收器回收的，即使该对象永远不会被用到也不会被回收。
>
> 当内存不足，JVM 开始垃圾回收，对于强引用的对象，就算是出现了 OOM 也不会对该对象进行回收。因此强引用有时也是造成 Java 内存泄露的原因之一。
>
> 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，一般认为就是可以被垃圾收集器回收。（具体回收时机还要要看垃圾收集策略）。

<font color='RedOrange'>软引用</font>

> 软引用是一种相对强引用弱化了一些的引用，需要用`java.lang.ref.SoftReference` 类来实现，可以让对象豁免一些垃圾收集。
>
> 软引用用来描述一些还有用，但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。
>
> 对于只有软引用的对象来说：<font color='Peach'>当系统内存充足时它不会被回收，当系统内存不足时它才会被回收</font>。

<font color='RedOrange'>弱引用</font>

> 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。
>
> 弱引用需要用`java.lang.ref.WeakReference`类来实现，它比软引用的生存期更短。
>
> 对于只有弱引用的对象来说，<font color='Peach'>只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，都会回收该对象占用的内存</font>。

<font color='RedOrange'>虚引用</font>

> 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。
>
> 虚引用，顾名思义，就是形同虚设，与其他几种引用都不太一样，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。
>
> 虚引用需要`java.lang.ref.PhantomReference` 来实现。
>
> 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，它不能单独使用也不能通过它访问对象，虚引用必须和引用队列（RefenenceQueue）联合使用。
>
> 虚引用的主要作用是跟踪对象垃圾回收的状态。仅仅是提供了一种确保对象被 `finalize` 以后，做某些事情的机制。
>
> `PhantomReference` 的 `get` 方法总是返回 null，因此无法访问对应的引用对象。其意义在于说明一个对象已经进入 `finalization` 阶段，可以被 GC 回收，用来实现比 `finalization` 机制更灵活的回收操作。
>
> 换句话说，<font color='Peach'>设置虚引用的唯一目的，就是在这个对象被回收的时候收到一个系统通知或者后续添加进一步的处理</font>。
>
> Java 允许使用 `finalize()` 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。

<font color='RedOrange'>引用队列</font>

> `ReferenceQueue` 是用来配合引用工作的，没有`ReferenceQueue` 一样可以运行。
>
> `SoftReference`、`WeakReference`、`PhantomReference` 都有一个可以传递 `ReferenceQueue` 的构造器。
>
> 创建引用的时候，可以指定关联的队列，当 GC 释放对象内存的时候，会将引用加入到引用队列。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动，这相当于是一种通知机制。
>
> 当关联的引用队列中有数据的时候，意味着指向的堆内存中的对象被回收。通过这种方式，JVM 允许我们在对象被销毁后，做一些我们自己想做的事情

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202401081341680.jpeg" alt="img" style="zoom:50%;" />

## 卡表（Card Table）

有个场景，老年代的对象可能引用新生代的对象，由于新生代的垃圾收集通常很频繁，那标记存活对象的时候，需要扫描从老年代到新生代的所有引用对象。因为该对象拥有对新生代对象的引用，那么这个引用也会被称为`GC Roots`。那不是每次`YGC`时又得做全堆扫描？显然不是，对于`HotSpot JVM`，使用了*卡标记（Card Marking）*技术来解决老年代到新生代的引用问题。具体是，使用卡表（Card Table）和写屏障（Write Barrier）来进行标记并加快对`GC Roots`的扫描。卡表的设计师将堆内存平均分成  2的N次方大小（默认512字节）个卡，并且维护一个卡表，用来储存每个卡的标识位。当对一个对象引用进行写操作时（对象引用改变），写屏障逻辑将会标记对象所在的卡页为脏页。在`YGC`只需要扫描卡表中的脏卡，将脏中的对象加入到`YGC`的`GC Roots`里面。当完成所有脏卡扫描时候，虚拟机会将卡表的脏卡标志位清空。

> 在高并发环境下，每次对引用的更新，无论是否更新了老年代对新生代对象的引用，都会进行一次写屏障操作，频繁的写屏障很容易发生虚共享(false sharing),从而带来性能开销。举 个例子：假设CPU缓存行大小为64字节，由于一个卡表项占1个字节，这意味着，64个卡表项将共享同一个缓存行。`HotSpot`每个卡页为512字节，那么一个缓存行将对应64个卡页一共 64*512=32KB。如果不同线程对对象引用的更新操作，恰好位于同一个32KB区域内，这将导致同时更新卡表的同一个缓存行，从而造成缓存行的写回、无效化或者同步操作，间接影响程序 性能。

在`JDK 7`中引入了VM参数`-XX:+UseCondCardMark` ，意思就是现在不采用无条件写屏障，而是先检查此卡是否已经是脏页，如果是将不再标记。这样就减少了并发下的虚共享问题。但是这样却不能避免对未标记的页进行并发标记。



## 新生代晋升老年代

对象优先在`Eden`分配，且新生代对象晋升到老年代有多种情况，

1. 分配担保。
   `Eden`区满时，进行`Minor GC`，当`Eden`和一个`Survivor`区中依然存活的对象无法放入到`Survivor`中，则通过分配担保机制提前转移到老年代中。

2. 大对象直接进入年老代

   - 大对象即需要大量连续内存空间的`Java`对象，如长字符串及数组。经常出现大对象导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来安置他们。 

   - 虚拟机提供了一个`-XX：PretenureSizeThreshold`参数，令大于这个设置值的对象直接在老年代分配。 这样做的目的是避免在`Eden`区及两个`Survivor`区之间发生大量的内存复制（新生代采用复制算法收集内存）。

3. 长期存活的对象将进入老年代。
   虚拟机给每个对象定义了一个对象年龄计数器，在对象在`Eden`创建并经过第一次`Minor GC`后仍然存活，并能被`Suivivor`容纳的话，将会被移动到`Survivor`空间，并对象年龄设置为1。每经历过`Minor GC`，年龄就增加1岁，当到一定程度（默认15岁，可以通过参数`-XXMaxTenuringThreshold`设置），就将会晋升年老代。

4. 动态对象年龄判定。
   虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升到老年代，如果在`Survivor`区中相同年龄（设年龄为`age`）的对象的所有大小之和超过`Survivor`空间的一半，年龄大于或等于该年龄（`age`）的对象就可以直接进入老年代，无需等到`MaxTenuringThreshold`中要求的年龄。



// TODO 补充G1&CMS参数优化  （注重高并发如何优化，大量计算情况下如何优化）

## JVM调优

### 调优的时机

- Heap内存（老年代）持续上涨达到设置的最大内存值；
- Full GC 次数频繁；
- GC 停顿时间过长（超过1秒）；
- 应用出现OutOfMemory 等内存异常；
- 应用中有使用本地缓存且占用大量内存空间；
- 系统吞吐量与响应性能不高或下降。

### 调优的目标

吞吐量、延迟、内存占用三者类似CAP，构成了一个不可能三角，只能选择其中两个进行调优，不可三者兼得。

- 延迟：GC低停顿和GC低频率；
- 低内存占用；
- 高吞吐量;

选择了其中两个，必然会会以牺牲另一个为代价。

下面展示了一些JVM调优的量化目标参考实例：

- Heap 内存使用率 <= 70%;
- Old generation内存使用率<= 70%;
- Avg Pause（平均暂停时间） <= 1秒;
- Full GC 次数0 或 Avg Pause interval >= 24小时 ;

注意：不同应用的JVM调优量化目标是不一样的。

### 并发量较大的 JVM 优化

1. 选择合适的垃圾收集器：

   - CPU单核，那么毫无疑问Serial 垃圾收集器是你唯一的选择。

   - CPU多核，关注吞吐量 ，那么选择PS+PO组合。

   - CPU多核，关注用户停顿时间，JDK版本1.6或者1.7，那么选择CMS。它适用于对响应时间要求较高的应用，可以通过参数`-XX:+UseConcMarkSweepGC`启用。

   - CPU多核，关注用户停顿时间，JDK1.8及以上，JVM可用内存6G以上，那么选择G1。它适用于大堆和低延迟要求的场景，可以通过参数`-XX:+UseG1GC`启用。

     ~~~sh
      //设置Serial垃圾收集器（新生代）
      开启：-XX:+UseSerialGC
      
      //设置PS+PO,新生代使用功能Parallel Scavenge 老年代将会使用Parallel Old收集器
      开启 -XX:+UseParallelOldGC
      
      //CMS垃圾收集器（老年代）
      开启 -XX:+UseConcMarkSweepGC
      
      //设置G1垃圾收集器
      开启 -XX:+UseG1GC
     ~~~

     

2. 调整堆大小：

   > 现象：垃圾收集频率非常频繁。
   >
   > 原因：如果内存太小，就会导致频繁的需要进行垃圾收集才能释放出足够的空间来创建新的对象，所以增加堆内存大小的效果是非常显而易见的。
   >
   > <font color='Apricot'>**注意**</font>：如果垃圾收集次数非常频繁，但是每次能回收的对象非常少，那么这个时候并非内存太小，而可能是内存泄露导致对象无法回收，从而造成频繁GC。

   ~~~sh
    //设置堆初始值
    指令1：-Xms2g
    指令2：-XX:InitialHeapSize=2048m
    
    //设置堆区最大值
    指令1：`-Xmx2g` 
    指令2： -XX:MaxHeapSize=2048m
    
    //新生代内存配置
    指令1：-Xmn512m
    指令2：-XX:MaxNewSize=512m
   ~~~

   

3. 设置符合预期的停顿时间：

   > 现象：程序间接性的卡顿
   >
   > 原因：如果没有确切的停顿时间设定，垃圾收集器以吞吐量为主，那么垃圾收集时间就会不稳定。
   >
   > <font color='Apricot'>**注意**</font>：不要设置不切实际的停顿时间，单次时间越短也意味着需要更多的GC次数才能回收完原有数量的垃圾.

   参数配置：

   ~~~sh
   //GC停顿时间，垃圾收集器会尝试用各种手段达到这个时间
    -XX:MaxGCPauseMillis 
   ~~~

   

4. 调整内存区域大小比率

   > 现象：某一个区域的GC频繁，其他都正常。
   >
   > 原因：如果对应区域空间不足，导致需要频繁GC来释放空间，在JVM堆内存无法增加的情况下，可以调整对应区域的大小比率。
   >
   > <font color='Apricot'>**注意**</font>：也许并非空间不足，而是因为内存泄露造成内存无法回收。从而导致GC频繁。

   参数配置：

   ~~~sh
   //survivor区和Eden区大小比率
    指令：-XX:SurvivorRatio=6  //S区和Eden区占新生代比率为1:6,两个S区2:6
    
    //新生代和老年代的占比
    -XX:NewRatio=4  //表示新生代:老年代 = 1:4 即老年代占整个堆的4/5；默认值=2
   ~~~

   

5. 调整对象升老年代的年龄

   > 现象：老年代频繁GC，每次回收的对象很多。
   >
   > 原因：如果升代年龄小，新生代的对象很快就进入老年代了，导致老年代对象变多，而这些对象其实在随后的很短时间内就可以回收，这时候可以调整对象的升级代年龄，让对象不那么容易进入老年代解决老年代空间不足频繁GC问题。
   >
   > <font color='Apricot'>**注意**</font>：增加了年龄之后，这些对象在新生代的时间会变长可能导致新生代的GC频率增加，并且频繁复制这些对象新生的GC时间也可能变长。

   配置参数：

   ```sh
   //进入老年代最小的GC年龄,年轻代对象转换为老年代对象最小年龄值，默认值7
    -XX:InitialTenuringThreshol=7 
   ```

   

6. 调整大对象的标准

   > 现象：老年代频繁GC，每次回收的对象很多,而且单个对象的体积都比较大。
   >
   > 原因：如果大量的大对象直接分配到老年代，导致老年代容易被填满而造成频繁GC，可设置对象直接进入老年代的标准。
   >
   > <font color='Apricot'>**注意**</font>：这些大对象进入新生代后可能会使新生代的GC频率和时间增加。

   配置参数：

   ```sh
    //新生代可容纳的最大对象,大于则直接会分配到老年代，0代表没有限制。
     -XX:PretenureSizeThreshold=1000000 
   ```

   

7. 调整GC的触发时机

   > 现象：CMS，G1 经常 Full GC，程序卡顿严重。
   >
   > 原因：G1和CMS  部分GC阶段是并发进行的，业务线程和垃圾收集线程一起工作，也就说明垃圾收集的过程中业务线程会生成新的对象，所以在GC的时候需要预留一部分内存空间来容纳新产生的对象，如果这个时候内存空间不足以容纳新产生的对象，那么JVM就会停止并发收集暂停所有业务线程（STW）来保证垃圾收集的正常运行。这个时候可以调整GC触发的时机（比如在老年代占用60%就触发GC），这样就可以预留足够的空间来让业务线程创建的对象有足够的空间分配。
   >
   > <font color='Apricot'>**注意**</font>：提早触发GC会增加老年代GC的频率。

   配置参数：

   ```sh
    //使用多少比例的老年代后开始CMS收集，默认是68%，如果频繁发生SerialOld卡顿，应该调小
    -XX:CMSInitiatingOccupancyFraction
    
    //G1混合垃圾回收周期中要包括的旧区域设置占用率阈值。默认占用率为 65%
    -XX:G1MixedGCLiveThresholdPercent=65 
   ```

   

8. 调整 JVM本地内存大小

   > 现象：GC的次数、时间和回收的对象都正常，堆内存空间充足，但是报OOM
   >
   > 原因： JVM除了堆内存之外还有一块堆外内存，这片内存也叫本地内存，可是这块内存区域不足了并不会主动触发GC，只有在堆内存区域触发的时候顺带会把本地内存回收了，而一旦本地内存分配不足就会直接报OOM异常。
   >
   > <font color='Apricot'>**注意**</font>：本地内存异常的时候除了上面的现象之外，异常信息可能是OutOfMemoryError：Direct buffer memory。 解决方式除了调整本地内存大小之外，也可以在出现此异常时进行捕获，手动触发GC（System.gc()）。

   配置参数：

   ~~~sh
    -XX:MaxDirectMemorySize
   ~~~

### 调优案例

#### CPU 100%问题定位

问题分析：既然是CPU飙升，肯定是查一下耗CPU的线程，然后看看GC。排查步骤如下：

1. 先需要找出哪个进程占用CPU高。

   ~~~shell
   top   #列出系统各个进程的资源占用情况。
   ~~~

2. 根据进程找到对应哪个线程占用CPU高。

   ~~~shell
   top -Hp 进程ID   #列出对应进程里面的线程占用资源情况
   ~~~

3. 找到对应线程ID后，把线程ID转换为16进制

   ~~~shell
   printf "%x\n"  PID    #把线程ID转换为16进制(后续查看线程堆栈信息展示的都是十六进制，为了找到线程堆栈信息，需要把线程号转成16进制。)。 
   ~~~

4. 查找某进程下某线程ID的线程状态，打印出对应线程的堆栈信息

   ~~~shell
   jstack 进程号 | grep 线程ID
   ~~~

5. 查看某进程GC持续变化情况，如果发现返回中Full GC很大且一直增大即可确认是Full GC！

   也可以使用"jmap -heap 进程ID”查看一下进程的堆内存是不是要溢出了，特别是老年代内存使用情况一般是达到阈值(具体看垃圾回收器和启动时配置的阈值)就会进程Full GC。

   ~~~shell
   jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一直统计）
   ~~~

6. 导出某进程下内存heap输出到文件中，可以通过eclipse的mat工具查看内存中有哪些对象比较多

   ~~~shell
   jmap -dump:format=b,file=filename 进程ID
   ~~~

##### 原因分析

1. <font color='Chestnut Red'>内存消耗过大，导致Full GC次数过多</font>

   > 如果是此项原因导致，那么执行步骤1-5会发现：
   >
   > - 多个线程的CPU都超过了100%，通过 jstack 命令可以看到这些线程主要是垃圾回收线程。（步骤2）
   > - 通过 jstat 命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。（步骤5）
   >
   > 确定是Full GC，接下来找到**具体原因**：
   >
   > - 如果是生成大量的对象，导致内存溢出就执行步骤6，查看具体内存对象占用情况。
   > - 如果内存占用不高，但是Full GC次数还是比较多，此时可能是代码中手动调用 System.gc()导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。

2. <font color='Chestnut Red'>代码中有大量消耗CPU的操作，导致CPU过高，系统运行缓慢</font>

   > 执行步骤1-4：在步骤4 jstack，可直接定位到代码行。例如某些复杂算法，甚至算法BUG，无限循环递归等等。

3. <font color='Chestnut Red'>由于锁使用不当，导致死锁</font>

   > 执行步骤1-4： 如果有死锁，会直接提示。关键字：deadlock。步骤4，会打印出业务死锁的位置。
   >
   > 造成死锁的原因：最典型的就是2个线程互相等待对方持有的锁。

4. <font color='Chestnut Red'>随机出现大量线程访问接口缓慢</font>

   > 代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；平时消耗的CPU不多，而且占用的内存也不高。
   >
   > 思路：首先找到该接口，通过压测工具不断加大访问力度，大量线程将阻塞于该阻塞点。

   执行步骤1-4：

   ~~~java
   "http-nio-8080-exec-4" #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000]
      java.lang.Thread.State: TIMED_WAITING (sleeping)-》期限等待
       at java.lang.Thread.sleep(Native Method)
       at java.lang.Thread.sleep(Thread.java:340)
       at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
       at com.*.user.controller.UserController.detail(UserController.java:18)-》业务代码阻塞点
   ~~~

   如上，找到业务代码阻塞点，这里业务代码使用了TimeUnit.sleep()方法，使线程进入了TIMED_WAITING(期限等待)状态。

   

5. <font color='Chestnut Red'>某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现</font>

   > 执行步骤1-4：jstack多查询几次，每次间隔30秒，对比一直停留在parking 导致的WAITING状态的线程。例如CountDownLatch倒计时器，使得相关线程等待

   ~~~java
   "Thread-0" #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000]   
   	java.lang.Thread.State: WAITING (parking) ->无期限等待
   		at sun.misc.Unsafe.park(Native Method)    
   		at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)    
   		at com.*.SyncTask.lambda$main$0(SyncTask.java:8)-》业务代码阻塞点
   		at com.*.SyncTask$$Lambda$1/1791741888.run(Unknown Source)    
   		at java.lang.Thread.run(Thread.java:748)
   ~~~

#### 内存溢出

> **内存溢出：**（Out Of Memory）通俗理解就是内存不够，指程序要求的内存超出了系统所能分配的范围，比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。或者是创建一个大的对象，而堆内存放不下这个对象，这也是内存溢出。内存溢出就是要求分配的内存超出了系统能给的，系统不能满足需求，于是产生溢出。
>
> **内存泄漏：**（Memory Leak）是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。
>
> **内存泄露可能会导致内存溢出**。

##### 原因：

JVM 虚拟机是使用<font color='Tasma'>引用计数法</font>和<font color='Tasma'>可达性分析</font>来判断对象是否可回收，本质是判断一个对象是否还被引用，如果没有引用则回收。在开发的过程中，由于代码的实现不同就会出现很多种内存泄漏问题，让gc 系统误以为此对象还在引用中，无法回收，造成内存泄漏

##### 排查手段

1. 查看错误信息：

   - 首先，查看控制台或日志中的错误信息，根据错误类型和发生位置初步了解内存溢出的原因。

2. 观察内存溢出发生时的情况：

   - 可以使用`jstat`或`jcmd`命令观察Java堆和方法区的使用情况，了解内存溢出时各个区域的内存占用情况。

   ```sh
   jstat -gcutil <pid> 1000
   ```
   
3. 检查大对象：

   - 如果存在大对象，尤其是长时间存活的大对象，考虑是否需要调整新生代和老年代的比例，以及调整新生代的大小。
   - 使用`-XX:PretenureSizeThreshold`参数设置大对象直接进入老年代的阈值。

4. 分析GC日志：

   - 对GC日志进行深入分析，关注GC的停顿时间、频率、吞吐量等信息。低吞吐量和频繁的Full GC可能是性能问题的标志。

5. 分析线程Dump：

   - 在分析线程Dump时，注意查看是否存在死锁、竞争条件等多线程问题。

6. 使用内存压测工具：

   - 使用一些内存压测工具（如`jemalloc`、`MAT`工具中的`OQL`查询）对内存进行更深入的分析。

7. 定位资源泄漏：

   - 通过堆转储文件和内存分析工具，定位到具体的对象，查看对象的引用关系，以找出是否存在资源泄漏。

8. 分析业务代码：

   - 分析业务代码，关注可能导致内存溢出的模块，特别是那些频繁创建对象或长时间持有对象引用的地方。

9. 使用GC分析工具：

   - 使用GC分析工具（如`GCEasy`、`GCViewer`）对GC日志进行可视化分析，更直观地了解GC的情况。

10. 代码Review：

    - 进行代码Review，特别是关注一些敏感资源的使用，如数据库连接、文件流等。

##### 场景

1. ThreadLocal 没有 remove

2. 资源未关闭造成的内存泄漏

   > 各种连接，如数据库连接、网络连接和 IO 连接、文件读写等使用后需要释放连接，只有连接被关闭后，垃圾回收器才会回收对应的对象。可以使用 try-with-resources 读取完文件，自动资源释放

3. 静态集合类和缓存

   > 静态集合或缓存过多，一直占用内存。
   >
   > 如List、Map等。如果这些容器为静态的，那么它们的生命周期与程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。<font color='Magenta'>生命周期长的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。</font>

4. 变量不合理的作用域

   > 一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。另一方面，如果没有及时地把对象设置为null，很有可能导致内存泄漏的发生。

5. 内部类持有外部类

   > 如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。

6. 改变哈希值

   > 当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露

7. 创建大量对象

   >例如在循环中创建对象、递归调用导致栈溢出等

8. 持有大数据集合

   >在内存中保持大的集合，特别是没有及时清理的情况。

##### 解决方案

1. 尽量减少使用静态变量，或者使用完及时赋值为 null。
2. 明确内存对象的有效作用域，尽量缩小对象的作用域，能用局部变量处理的不用成员变量，因为局部变量栈会自动回收；
3. 减少长生命周期的对象持有短生命周期的引用；
4. 使用StringBuilder和StringBuffer进行字符串连接，Sting和StringBuilder以及StringBuffer等都可以代表字符串，其中String字符串代表的是不可变的字符串，后两者表示可变的字符串。如果使用多个String对象进行字符串连接运算，在运行时可能产生大量临时字符串，这些字符串会保存在内存中从而导致程序性能下降。
5. 对于不需要使用的对象手动设置null值，不管GC何时会开始清理，我们都应及时的将无用的对象标记为可被清理的对象；
6. 各种连接（数据库连接，网络连接，IO连接）操作，务必显式调用close关闭。

##### 案例

<font color='Apricot'>**后台导出数据引发的OOM**</font>：

**问题描述**：公司的后台系统，偶发性的引发OOM异常，堆内存溢出。

> 1. 因为是偶发性的，所以第一次简单的认为就是堆内存不足导致，所以单方面的加大了堆内存从4G调整到8G。
> 2. 但是问题依然没有解决，只能从堆内存信息下手，通过开启了-XX:+HeapDumpOnOutOfMemoryError参数 获得堆内存的dump文件。
> 3. VisualVM 对堆dump文件进行分析，通过VisualVM查看到占用内存最大的对象是String对象，本来想跟踪着String对象找到其引用的地方，但dump文件太大，跟踪进去的时候总是卡死，而String对象占用比较多也比较正常，最开始也没有认定就是这里的问题，于是就从线程信息里面找突破点。
> 4. 通过线程进行分析，先找到了几个正在运行的业务线程，然后逐一跟进业务线程看了下代码，发现有个引起我注意的方法，导出订单信息。
> 5. 因为订单信息导出这个方法可能会有几万的数据量，首先要从数据库里面查询出来订单信息，然后把订单信息生成EXCEL，这个过程会产生大量的String对象。
> 6. 为了验证自己的猜想，于是准备登录后台去测试下，结果在测试的过程中发现导出订单的按钮前端居然没有做点击后按钮置灰交互事件，结果按钮可以一直点，因为导出订单数据本来就非常慢，使用的人员可能发现点击后很久后页面都没反应，结果就一直点，结果就大量的请求进入到后台，堆内存产生了大量的订单对象和EXCEL对象，而且方法执行非常慢，导致这一段时间内这些对象都无法被回收，所以最终导致内存溢出。
> 7. 知道了问题就容易解决了，最终没有调整任何JVM参数，只是在前端的导出订单按钮上加上了置灰状态，等后端响应之后按钮才可以进行点击，然后减少了查询订单信息的非必要字段来减少生成对象的体积，然后问题就解决了。

### CMS参数优化

1. <span style="background:#f9eda6;">-XX:+UseConcMarkSweepGC</span>

   > CMS全称 `Concurrent Mark Sweep`，是一款并发的、使用标记-清除算法的垃圾回收器，
   > 如果老年代使用CMS垃圾回收器，需要添加虚拟机参数-"XX:+UseConcMarkSweepGC"。

2. <span style="background:#f9eda6;">- XX:CMSInitiatingOccupancyFraction =n</span>

   > CMS的另一个缺点是它需要更大的堆空间。因为CMS标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在CMS回 收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。也就是说，CMS不会在老年代满的时候才开始收集。相反，它会尝试更早的开始收集，已 避免上面提到的情况：在回收完成之前，堆没有足够空间分配！默认当老年代使用68%的时候，CMS就开始行动了。 
   >
   > `– XX:CMSInitiatingOccupancyFraction =n` 来设置这个阀值。

3. <span style="background:#f9eda6;">Old GC触发条件</span>

   > 周期性`Old GC`，执行的逻辑也叫`Background Collect`，对老年代进行回收，在GC日志中比较常见，由后台线程`ConcurrentMarkSweepThread`循环判断（默认2s）是否需要触发。
   >
   > 触发条件
   >
   > 1、如果没有设置`-XX:+UseCMSInitiatingOccupancyOnly`，虚拟机会根据收集的数据决定是否触发（建议线上环境带上这个参数，不然会加大问题排查的难度）。
   > 2、老年代使用率达到阈值 `CMSInitiatingOccupancyFraction`，默认92%。
   > 3、永久代的使用率达到阈值 `CMSInitiatingPermOccupancyFraction`，默认92%，前提是开启 `CMSClassUnloadingEnabled`。
   > 4、新生代的晋升担保失败。
   >
   > `CMS GC`要决定是否在`full GC`时做压缩，会依赖几个条件。其中: 
   >
   > 1. 第一种条件，`UseCMSCompactAtFullCollection `与 `CMSFullGCsBeforeCompaction `是搭配使用的；前者目前默认就是`true`了，也就是关键在后者上。 
   > 2. 第二种条件是用户调用了`System.gc()`，而且`DisableExplicitGC`没有开启。 
   > 3. 第三种条件是`young gen`报告接下来如果做增量收集会失败；简单来说也就是`young gen`预计`old gen`没有足够空间来容纳下次`young GC`晋升的对象。 
   > 4. 上述三种条件的任意一种成立都会让`CMS`决定这次做`full GC`时要做压缩。 

   > 1. `CMSFullGCsBeforeCompaction `说的是，在上一次`CMS`并发`GC`执行过后，到底还要再执行多少次`full GC`才会做压缩。默认是`0`，也就是在默认配置下每次`CMS GC`顶不住了而要转入`full GC`的时候都会做压缩。 把`CMSFullGCsBeforeCompaction`配置为`10`，就会让上面说的第一个条件变成每隔`10`次真正的`full GC`才做一次压缩（而不是每`10`次`CMS`并发`GC`就做一次压缩，目前VM里没有这样的参数）。这会使`full GC`更少做压缩，也就更容易使`CMS`的`old gen`受碎片化问题的困扰。 本来这个参数就是用来配置降低`full GC`压缩的频率，以期减少某些`full GC`的暂停时间。`CMS`回退到`full GC`时用的算法是`mark-sweep-compact`，但`compaction`是可选的，不做的话碎片化会严重些但这次`full GC`的暂停时间会短些；这是个取舍。
   >
   > 2. `-XX:CMSInitiatingOccupancyFraction=70` 和`-XX:+UseCMSInitiatingOccupancyOnly`
   >
   >    这两个设置一般配合使用,一般用于『降低`CMS GC`频率或者增加频率、减少`GC`时长』的需求
   >
   >    ` -XX:CMSInitiatingOccupancyFraction=70` 是指设定`CMS`在对内存占用率达到`70%`的时候开始`GC`(因为`CMS`会有浮动垃圾,所以一般都较早启动`GC`);
   >
   >     `-XX:+UseCMSInitiatingOccupancyOnly` 只是用设定的回收阈值(上面指定的`70%`),如果不指定，`JVM`仅在第一次使用设定值，后续则自动调整.
   >
   > 3. `-XX:+CMSScavengeBeforeRemark`
   >
   >    在`CMS GC`前启动一次`ygc`，目的在于减少`old gen`对`ygc gen`的引用，降低`remark`时的开销-----一般`CMS`的`GC`耗时 `80%`都在`remark`阶段
   >
   >    `-XX：+UseCMSInitiatingOccupancyOnly`
   >
   >    我们用`-XX+UseCMSInitiatingOccupancyOnly`标志来命令`JVM`不基于运行时收集的数据来启动`CMS`垃圾收集周期。而是，当该标志被开启时，`JVM`通过`CMSInitiatingOccupancyFraction`的值进行每一次`CMS`收集，而不仅仅是第一次。然而，请记住大多数情况下，`JVM`比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。

#### CMS优化方向

1. 原则

   - `cms`的的优势就是低延迟，但是如果出现了长时间的`stw`，则对应用程序有很大的影响
   - 如果出现了`concurrent mode failure`和`promotion failed`，代价都非常昂贵，我们调优应该尽量避免这些情况

2. 针对`concurrent mode failure`的优化

   - 发生该失败的主要原因是由于`CMS`不能以足够快的速度清理老年代空间

   - 当老年代空间的占用达到某个阈值时，并发回收就开始了。一个`CMS`后台线程开始扫描老年代空间，寻找无用的垃圾对象时，竞争就开始了。`CMS`收集器必须在老年代剩余的空间用尽之前，完成老年代空间的扫描及回收工作。否则如果在正常速度的比赛中失效，就会发生该错误

   - 在并发清理阶段，用户线程仍然在运行，必须预留出空间给用户线程使用，会产生’浮动垃圾‘

   - 常规优化途径如下：

     > 以更高的频率执行后台的回收线程，即提高`CMS`并发周期发生的频率
     >
     > - 主要是调低`CMSInitiatingOccupancyFraction`的值
     >
     > - 但是不能太低，太低会导致过于频繁的`gc`，会消耗更多的的`cpu`和停顿
     >
     > - `landon`
     >
     >   > 需要先计算老年代常驻内存大小，如占用`60%`，那么这个阈值则可以设置为约`70%`，否则会比较频繁`gc`
     >   >
     >   > 可以考虑担保机制，只要老年代预留剩余空间大于年轻代大小，比如新生代和老年代的比例是1 : 4，即新生代占用老年代的`25%`，那么这个阈值可以设置为`70`，即老年代还预留出来`30%`的空间
     >   >
     >   > > 注意如果浮动垃圾很多的话，也无法解决该问题，即`cms`并发回收期间，浮动垃圾越来越多，占用预留空间，多次的`ygc`的话，会有填满预留空间的可能，虽然概率较低
     >   >
     >   > 两个条件综合考虑，如果设置了阈值70，但是老年代常驻内存很大，甚至超过70，那么此时的建议要提高堆内存，增加老年代的大小或者减少新生代的大小

3. 针对`promotion failed`的优化

   - 这个是`cms`最为严重的’碎片问题‘，我们要尽量避免这个发生后引起的`fgc`

   - 所以优化这个问题，也可以描述为'如何解决碎片问题'

   - 常规优化途径如下

     > - 增大堆内存，增加老年代大小，但要注意不要超过`32g(the HotSpot JVM uses a trick to compress object pointers when heaps are less than around 32 GB)`
     > - 尽早执行`cms gc`，合理设置`CMSInitiatingOccupancyFraction`，会合并老生代中相邻的`free`空间，可分配给较大的对象
     > - 和上面一样，也可以做一个老年代预留空间大于年轻代
     >
     > > 到了阈值后，就会触发`cms gc`，但还是和上面说的，会产生浮动垃圾 + 碎片，还是会出现
     >
     > - 另外一个比较“挫”的办法，是在每天凌晨访问量低的时候，主动执行一下`fgc`，执行一下'碎片压缩'
     > - 如`System.gc`，但是要注意是否开启了`-XX:+ExplicitGCInvokesConcurrent`
     > - 所以建议办法是用`jmap -histo:live`

   - 另外晋升还包括`to space`空间小，可以根据情况尝试提高`Survivor`

### G1参数优化

1. **暂停时间**：

   > 用`-XX:MaxGCPauseMillis`来指定，默认值200ms。这是一个软性目标，G1会尽量达成，如果达不成，会逐渐做自我调整。对于`Young GC`来说，会逐渐减少`Eden`区个数，减少Eden空间那么`Young GC`的处理时间就会相应减少；对于`Mixed GC`，G1会调整每次`Choose Cset`的比例，默认最大值是10%，当然每次选择的`Cset`少了，所要经历的`Mixed GC`的次数会相应增加。同时减少Eden的总空间时，就会更加频繁的触发`Young GC`，也就是会加快Mixed GC的执行频率，因为Mixed GC是由Young GC触发的，或者说借机同时执行的。频繁GC会对对应用的吞吐量造成影响，每次Mixed GC回收时间太短，回收的垃圾量太少，可能最后GC的垃圾清理速度赶不上应用产生的速度，那么可能会造成串行的Full GC，这是要极力避免的。所以暂停时间肯定不是设置的越小越好，当然也不能设置的偏大，转而指望G1自己会尽快的处理，这样可能会导致一次全部并发标记后触发的Mixed GC次数变少，但每次的时间变长，STW时间变长，对应用的影响更加明显。

2. **Region大小**：

   > 用`-XX:G1HeapRegionSize`来指定，若未指定则默认最多生成2048块，每块的大小需要为2的幂次方，如1,2,4,8,16,32，最大值为32M。Region的大小主要是关系到Humongous Object的判定，当一个对象超过Region大小的一半时，则为巨型对象，那么其会至少独占一个Region，如果一个放不下，会占用连续的多个Region。当一个`Humongous Region`放入了一个巨型对象，可能还有不少剩余空间，但是不能用于存放其他对象，这些空间就浪费了。所以如果应用里有很多大小差不多的巨型对象，可以适当调整Region的大小，尽量让他们以普通对象的形式分配，合理利用Region空间。

3. **新生代比例**：

   > 新生代比例有两个数值指定，下限：`-XX:G1NewSizePercent`，默认值5%，上限：`-XX:G1MaxNewSizePercent`，默认值60%。G1会根据实际的GC情况(主要是暂停时间)来动态的调整新生代的大小，主要是Eden Region的个数。最好是Eden的空间大一点，毕竟Young GC的频率更大，大的Eden空间能够降低Young GC的发生次数。但是Mixed GC是伴随着Young GC一起的，如果暂停时间短，那么需要更加频繁的Young GC，同时也需要平衡好Mixed GC中新生代和老年代的Region，因为新生代的所有Region都会被回收，如果Eden很大，那么留给老年代回收空间就不多了，最后可能会导致Full GC。

4. **并发GC线程数**：

   > 通过 `-XX:ConcGCThreads`来指定，默认是`-XX:ParallelGCThreads/4`，也就是在非STW期间的GC工作线程数，当然其他的线程很多工作在应用上。当并发周期时间过长时，可以尝试调大GC工作线程数，但是这也意味着此期间应用所占的线程数减少，会对吞吐量有一定影响。

5. **并行GC线程数**：

   > 通过 `-XX:ParallelGCThreads`来指定，也就是在STW阶段工作的GC线程数，其值遵循以下原则：
   > ① 如果用户显示指定了ParallelGCThreads，则使用用户指定的值。
   > ② 否则，需要根据实际的CPU所能够支持的线程数来计算ParallelGCThreads的值，计算方法见步骤③和步骤④。
   > ③ 如果物理CPU所能够支持线程数小于8，则ParallelGCThreads的值为CPU所支持的线程数。这里的阀值为8，是因为JVM中调用nof_parallel_worker_threads接口所传入的switch_pt的值均为8。
   > ④ 如果物理CPU所能够支持线程数大于8，则ParallelGCThreads的值为8加上一个调整值，调整值的计算方式为：物理CPU所支持的线程数减去8所得值的5/8或者5/16，JVM会根据实际的情况来选择具体是乘以5/8还是5/16。
   > 比如，在64线程的x86 CPU上，如果用户未指定ParallelGCThreads的值，则默认的计算方式为：ParallelGCThreads = 8 + (64 - 8) * (5/8) = 8 + 35 = 43。

6. **被纳入Cset的Region的存活空间占比阈值**：

   > 通过 `-XX:G1MixedGCLiveThresholdPercent`指定，不同版本默认值不同，有65%和85%。在全局并发标记阶段，如果一个Region的存活对象的空间占比低于此值，则会被纳入Cset。此值直接影响到Mixed GC选择回收的区域，当发现GC时间较长时，可以尝试调低此阈值，尽量优先选择回收垃圾占比高的Region，但此举也可能导致垃圾回收的不够彻底，最终触发Full GC。

7. **触发全局并发标记的老年代使用占比**：

   > 通过`-XX:InitiatingHeapOccupancyPercent`指定，默认值45%，也就是老年代占堆的比例超过45%。如果Mixed GC周期结束后老年代使用率还是超过45%,那么会再次触发全局并发标记过程，这样就会导致频繁的老年代GC，影响应用吞吐量。同时老年代空间不大，Mixed GC回收的空间肯定是偏少的。可以适当调高IHOP的值，当然如果此值太高，很容易导致年轻代晋升失败而出发Full GC，所以需要多次调整测试。

8. **触发Mixed GC的堆垃圾占比**：

   > 通过`-XX:G1HeapWastePercent`指定，默认值5%，也就是在全局标记结束后能够统计出所有Cset内可被回收的垃圾占整对的比例值，如果超过5%，那么就会触发之后的多轮Mixed GC，如果不超过，那么会在之后的某次Young GC中重新执行全局并发标记。可以尝试适当的调高此阈值，能够适当的降低Mixed GC的频率。

9. **每轮Mixed GC回收的Region最大比例**：

   > 通过`-XX:G1OldCSetRegionThresholdPercent`指定，默认10%，也就是每轮Mixed GC附加的Cset的Region`不超过`全部Region的10%，最多10%，如果暂停时间短，那么可能会少于10%。一般这个值不需要额外调整。

10. **一个周期内触发Mixed GC最大次数**：

    > 通过`-XX:G1MixedGCCountTarget`指定，默认值8。也就是在一次全局并发标记后，最多接着8此Mixed GC，也就是会把全局并发标记阶段生成的Cset里的Region拆分为最多8部分，然后在每轮Mixed GC里收集一部分。这个值要和上一个参数配合使用，8*10%=80%，应该来说会大于每次标记阶段的Cset集合了。一般此参数也不需额外调整。

11. **G1为分配担保预留的空间比例**：

    > 通过`-XX:G1ReservePercent`指定，默认10%。也就是老年代会预留10%的空间来给新生代的对象晋升，如果经常发生新生代晋升失败而导致Full GC，那么可以适当调高此阈值。但是调高此值同时也意味着降低了老年代的实际可用空间。

12. **谨慎使用Soft Reference**

    > 如果SoftReference过多，会有频繁的老年代收集。-XX:SoftRefLRUPolicyMSPerMB参数，可以指定每兆堆空闲空间的软引用的存活时间，默认值是1000，也就是1秒。可以调低这个参数来触发更早的回收软引用。如果调高的话会有更多的存活数据，可能在GC后堆占用空间比会增加。 对于软引用，还是建议尽量少用，会增加存活数据量，增加GC的处理时间。

13. **晋升年龄阈值**：

    > 通过`-XX:MaxTenuringThreshold`指定，默认值15。一般新生对象经过15次Young GC会晋升到老年代，巨型对象会直接分配在老年代，同时在Young GC时，如果相同age的对象占Survivors空间的比例超过 `-XX:TargetSurvivorRatio`的值(默认50%)，则会自动将此次晋升年龄阈值设置为此age的值，所有年龄超过此值的对象都会被晋升到老年代，此举可能会导致老年代需要不少空间应对此种晋升。一般这个值不需要额外调整。

# 9. 框架中的设计模式

## Spring:

> **工厂模式：**
>
> Spring使用工厂模式可以通过 `BeanFactory `或 `ApplicationContext` 创建`bean`对象。
>
> -  `BeanFactory` ：延迟注入(使用到某个 `bean` 的时候才会注入)，程序启动速度更快。是`Spring`里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能；
> -  `ApplicationContext `：继承`BeanFactory`接口，容器启动的时候，不管你用没用到，一次性创建所有 `bean` 。还可以为`Bean`配置`lazy-init=true`来让`Bean`延迟实例化； 
>
> **单例模式**
>
> `Spring`中`bean`的默认作用域就是`singleton`。
>
> 除了`singleton`作用域，`Spring bean`还有下面几种作用域：
>
> -  `prototype` : 每次请求都会创建一个新的 `bean `实例。
> -  `request `: 每一次`HTTP`请求都会产生一个新的`bean`，该`bean`仅在当前`HTTP request`内有效。
> -  `session` : 每一次`HTTP`请求都会产生一个新的 `bean`，该`bean`仅在当前 `HTTP session` 内有效。
> -  `global-session`： 全局`session`作用域，仅仅在基于`portlet`的`web`应用中才有意义，`Spring5`已经没有了。
>
> **代理模式**
>
> `Spring AOP`就是基于动态代理的，如果要代理的对象，实现了某个接口，那么`Spring AOP`会使用`JDK Proxy`，去创建代理对象，而对于没有实现接口的对象，这时候`Spring AOP`会使用`Cglib`生成一个被代理对象的子类来作为代理。
>
> **模板设计模式**
>
> `Spring`中的`jdbcTemplate`、`hibernateTemplate`等以`Template`结尾的对数据库操作的类，它们就使用到了模板模式。一般情况下，我们都是使用继承的方式来实现模板模式，但是Spring并没有使用这种方式，而是使用Callback模式与模板方法配合，既达到了代码复用的效果，同时增加了灵活性。
>
> **观察者模式**
>
> 观察者模式是一种对象行为模式。它表示的是一种对象与对象之间具有依赖关系，当一个对象发生改变时，这个对象所依赖的对象也会做出反应。`Spring`事件驱动模型就是观察者模式很经典的应用。
>
> 事件角色：`ApplicationEvent`（`org.springframework.context`包下）充当事件的角色，这是一个抽象类。
>
> 事件监听者角色：`ApplicationListener`充当了事件监听者的角色，它是一个接口，里面只定义了一个`onApplicationEvent（）`方法来处理`ApplicationEvent`。
>
> 事件发布者角色：`ApplicationEventPublisher`充当了事件的发布者，它也是个接口。
>
> `Spring`事件流程总结：
>
> 1.  定义一个事件: 实现一个继承自 `ApplicationEvent`，并且写相应的构造函数；
> 2.  定义一个事件监听者：实现 `ApplicationListener `接口，重写 `onApplicationEvent() `方法；
> 3.  使用事件发布者发布消息: 可以通过 `ApplicationEventPublisher` 的 `publishEvent()` 方法发布消息。
>
> **适配器设计模式**
>
> 适配器设计模式将一个接口转换成客户希望的另一个接口，适配器模式使得接口不兼容的那些类可以一起工作，其别名为包装器。在`Spring MVC`中，`DispatcherServlet`根据请求信息调用`HandlerMapping`，解析请求对应的`Handler`，解析到对应的`Handler`（也就是我们常说的`Controller`控制器）后，开始由`HandlerAdapter`适配器处理。
>
> **装饰者设计模式**
>
> 装饰者设计模式可以动态地给对象增加些额外的属性或行为。相比于使用继承，装饰者模式更加灵活。`Spring `中配置`DataSource`的时候，`DataSource`可能是不同的数据库和数据源。我们能否根据客户的需求在少修改原有类的代码下切换不同的数据源，这个时候据需要用到装饰者模式。
>
> **策略设计模式**
>
> `Spring `框架的资源访问接口就是基于策略设计模式实现的。该接口提供了更强的资源访问能力，`Spring`框架本身大量使用了`Resource`接口来访问底层资源。`Resource`接口本身没有提供访问任何底层资源的实现逻辑，针对不同的额底层资源，`Spring`将会提供不同的`Resource`实现类，不同的实现类负责不同的资源访问类型。
>
> `Spring `为 `Resource `接口提供了如下实现类： 
>
> - UrlResource：访问网络资源的实现类。
>
> - ClassPathResource：访问类加载路径里资源的实现类。
>
> - FileSystemResource：访问文件系统里资源的实现类。
>
> - ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类.
>
> - InputStreamResource：访问输入流资源的实现类。
>
> - ByteArrayResource：访问字节数组资源的实现类。 
>
>   这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。

## Mybatis

> 1. Builder模式，例如`SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder`；
> 2. 工厂模式，例如`SqlSessionFactory、ObjectFactory、MapperProxyFactory`；
> 3. 单例模式，例如`ErrorContext`和`LogFactory`；
> 4. 代理模式，`Mybatis`实现的核心，比如`MapperProxy`、`ConnectionLogger`，用的`jdk`的动态代理；还有`executor.loader`包使用了`cglib`或者`javassist`达到延迟加载的效果；
> 5. 组合模式，例如`SqlNode`和各个子类`ChooseSqlNode`等；
> 6. 模板方法模式，例如`BaseExecutor`和`SimpleExecutor`，还有`BaseTypeHandler`和所有的子类例如`IntegerTypeHandler`；
> 7. 适配器模式，例如`Log`的`Mybatis`接口和它对`jdbc`、`log4j`等各种日志框架的适配实现；
> 8. 装饰者模式，例如`Cache`包中的`cache.decorators`子包中等各个装饰者的实现；
> 9. 迭代器模式，例如迭代器模式`PropertyTokenizer`；

**1、Builder模式**

`Builder`模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和`Builder`模式，相对于工厂模式会产出一个完整的产品，`Builder`应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。

在`Mybatis`环境的初始化过程中，`SqlSessionFactoryBuilder`会调用`XMLConfigBuilder`读取所有的`MybatisMapConfig.xml`和所有的`*Mapper.xml`文件，构建`Mybatis`运行的核心对象`Configuration`对象，然后将该`Configuration`对象作为参数构建一个`SqlSessionFactory`对象。

其中`XMLConfigBuilder`在构建`Configuration`对象时，也会调用`XMLMapperBuilder`用于读取`*Mapper`文件，而`XMLMapperBuilder`会使用`XMLStatementBuilder`来读取和`build`所有的`SQL`语句。

在这个过程中，有一个相似的特点，就是这些`Builder`会读取文件或者配置，然后做大量的`XpathParser`解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了`Builder`模式来解决。

**2、工厂模式**

在Mybatis中比如SqlSessionFactory使用的是工厂模式，该工厂没有那么复杂的逻辑，是一个简单工厂模式。

简单工厂模式`(Simple Factory Pattern)`：又称为静态工厂方法`(Static Factory Method)`模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。

`SqlSession`可以认为是一个`Mybatis`工作的核心的接口，通过这个接口可以执行执行`SQL`语句、获取`Mappers`、管理事务。类似于连接`MySQL`的`Connection`对象。`SqlSessionFactory`的`openSession`方法重载了很多个，分别支持`autoCommit`、`Executor`、`Transaction`等参数的输入，来构建核心的`SqlSession`对象。

**3、单例模式**

单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。

单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。

在`Mybatis`中有两个地方用到单例模式，`ErrorContext`和`LogFactory`，其中`ErrorContext`是用在每个线程范围内的单例，用于记录该线程的执行环境错误信息，而`LogFactory`则是提供给整个`Mybatis`使用的日志工厂，用于获得针对项目配置好的日志对象。

**4、代理模式**

代理模式可以认为是`Mybatis`的核心使用的模式，正是由于这个模式，我们只需要编写`Mapper.java`接口，不需要实现，由`Mybatis`后台帮我们完成具体`SQL`的执行。

代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用，它是一种对象结构型模式。

代理模式包含如下角色：

- `Subject`: 抽象主题角色
- `Proxy`: 代理主题角色
- `RealSubject`: 真实主题角色

**5、组合模式**

组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。

组合模式对单个对象(叶子对象)和组合对象(组合对象)具有一致性，它将对象组织到树结构中，可以用来描述整体与部分的关系。同时它也模糊了简单元素(叶子对象)和复杂元素(容器对象)的概念，使得客户能够像处理简单元素一样来处理复杂元素，从而使客户程序能够与复杂元素的内部结构解耦。

在使用组合模式中需要注意一点也是组合模式最关键的地方：叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。

**6、模板方法模式**

模板方法模式是所有模式中最为常见的几个模式之一，是基于继承的代码复用的基本技术。

模板方法模式需要开发抽象类和具体子类的设计师之间的协作。一个设计师负责给出一个算法的轮廓和骨架，另一些设计师则负责给出这个算法的各个逻辑步骤。代表这些具体逻辑步骤的方法称做基本方法(primitive method)；而将这些基本方法汇总起来的方法叫做模板方法(template method)，这个设计模式的名字就是从此而来。

模板类定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。

在`Mybatis`中，`sqlSession`的`SQL`执行，都是委托给`Executor`实现的，`Executor`包含以下结构：

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220428172422.jpg)

其中的`BaseExecutor`就采用了模板方法模式，它实现了大部分的`SQL`执行逻辑，然后把以下几个方法交给子类定制化完成：

```java
protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException;

protected abstract List<BatchResult> doFlushStatements(boolean isRollback) throws SQLException;

protected abstract <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds,
     ResultHandler resultHandler, BoundSql boundSql) throws SQLException;
```

该模板方法类有几个子类的具体实现，使用了不同的策略：

- 简单`SimpleExecutor`：每执行一次`update`或`select`，就开启一个`Statement`对象，用完立刻关闭`Statement`对象。（可以是`Statement`或`PrepareStatement`对象）
- 重用`ReuseExecutor`：执行`update`或`select`，以`sql`作为`key`查找`Statement`对象，存在就使用，不存在就创建，用完后，不关闭`Statement`对象，而是放置于`Map<String, Statement>`内，供下一次使用。（可以是`Statement`或`PrepareStatement`对象）
- 批量`BatchExecutor`：执行`update`（没有`select`，`JDBC`批处理不支持select`）`，将所有`sql`都添加到批处理中（`addBatch()`），等待统一执行（`executeBatch()`），它缓存了多个`Statement`对象，每个`Statement`对象都是`addBatch()`完毕后，等待逐一执行`executeBatch()`批处理的；`BatchExecutor`相当于维护了多个桶，每个桶里都装了很多属于自己的`SQL`，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库。（可以是`Statement`或`PrepareStatement`对象）

**7、适配器模式**

适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。

在`Mybatsi`的`logging`包中，有一个`Log`接口：

该接口定义了`Mybatis`直接使用的日志方法，而`Log`接口具体由谁来实现呢？`Mybatis`提供了多种日志框架的实现，这些实现都匹配这个`Log`接口所定义的接口方法，最终实现了所有外部日志框架到`Mybatis`日志包的适配

**8、装饰者模式**

装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。

在`Mybatis`中，缓存的功能由根接口`Cache（org.apache.ibatis.cache.Cache）`定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由`PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）`永久缓存实现，然后通过一系列的装饰器来对`PerpetualCache`永久缓存进行缓存策略等方便的控制

用于装饰`PerpetualCache`的标准装饰器共有8个（全部在`org.apache.ibatis.cache.decorators`包中）：

1. `FifoCache`：先进先出算法，缓存回收策略
2. `LoggingCache`：输出缓存命中的日志信息
3. `LruCache`：最近最少使用算法，缓存回收策略
4. `ScheduledCache`：调度缓存，负责定时清空缓存
5. `SerializedCache`：缓存序列化和反序列化存储
6. `SoftCache`：基于软引用实现的缓存管理策略
7. `SynchronizedCache`：同步的缓存装饰器，用于防止多线程并发访问
8. `WeakCache`：基于弱引用实现的缓存管理策略

另外，还有一个特殊的装饰器`TransactionalCache`：事务性的缓存

正如大多数持久层框架一样，`Mybatis`缓存同样分为一级缓存和二级缓存

- 一级缓存，又叫本地缓存，是`PerpetualCache`类型的永久缓存，保存在执行器中（`BaseExecutor`），而执行器又在`SqlSession（DefaultSqlSession）`中，所以一级缓存的生命周期与`SqlSession`是相同的。
- 二级缓存，又叫自定义缓存，实现了`Cache`接口的类都可以作为二级缓存，所以可配置如`encache`等的第三方缓存。二级缓存以`namespace`名称空间为其唯一标识，被保存在`Configuration`核心配置对象中。

二级缓存对象的默认类型为`PerpetualCache`，如果配置的缓存是默认类型，则`Mybatis`会根据配置自动追加一系列装饰器。

`Cache`对象之间的引用顺序为：

`SynchronizedCache–>LoggingCache–>SerializedCache–>ScheduledCache–>LruCache–>PerpetualCache`

**9、迭代器模式**

迭代器（Iterator）模式，又叫做游标（Cursor）模式。GOF给出的定义为：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。

Java的Iterator就是迭代器模式的接口，只要实现了该接口，就相当于应用了迭代器模式

比如`Mybatis`的`PropertyTokenizer`是`property`包中的重量级类，该类会被`reflection`包中其他的类频繁的引用到。这个类实现了`Iterator`接口，在使用时经常被用到的是`Iterator`接口中的`hasNext`这个函数。

# 12. `URL`解析过程

~~~markdown
1. URL组成
	协议（http/https）
	域名 （有时候也是ip）
	端口号（数字表示，若为HTTP的默认值“:80”可省略）
	路径（以“/”字符区别路径中的每一个目录名称）
	查询（GET模式的窗体参数，以“?”字符为起点，每个参数以“&”隔开，再以“=”分开参数名称与数据，通常以UTF8的URL编码，避开字符冲突的问题）
	
第 1 步
用户在浏览器中输入 URL 并回车。首先是将 URL 转换为 IP 地址。从 URL 到 IP 地址的映射通常存储在缓存中，因此浏览器会在多层缓存中查找 IP 地址：浏览器缓存、操作系统缓存、本地缓存和 ISP 缓存。如果浏览器在缓存中找不到映射，就会请求 DNS（Domain Name System）解析器进行解析。
第 2 步
如果在任何缓存中都找不到 IP 地址，浏览器就会转到 DNS 服务器进行递归 DNS 查找，直到找到 IP 地址为止。
第 3 步
有了服务器的 IP 地址，浏览器就会向服务器发送 HTTP 请求。为了安全访问服务器资源，我们应始终使用 HTTPS。浏览器首先通过 TCP 三次握手与服务器建立 TCP 连接。然后向客户端发送公钥（Public Key）。客户端使用公钥加密会话密钥（Session Key）并发送给服务器。服务器使用私钥（Private Key）解密会话密钥。然后，客户端和服务器就可以使用会话密钥来交换加密数据。
第 4 步
服务器处理请求并发回响应。响应成功时，状态代码为 200。响应包含 3 个部分：HTML、CSS 和 Javascript。浏览器会解析 HTML 并生成 DOM 树。浏览器还会解析 CSS 并生成 CSSOM 树。然后，浏览器将 DOM 树和 CSSOM 树合并为渲染树。浏览器渲染内容并显示给用户。
~~~

> 1. **DNS解析**：
>    - 浏览器首先会解析输入的网址，提取其中的主机名部分。发起 DNS 请求，向 DNS 服务器查询该主机名对应的 IP 地址。
> 2. **建立TCP连接**：
>    - 浏览器通过获取到的 IP 地址与目标服务器通过三次握手，建立 TCP 连接
> 3. **发送HTTP请求**：
>    - 一旦建立了 TCP 连接，浏览器就会向服务器发送 HTTP 请求。
>    - 请求中包含了要访问的资源路径、请求方法（GET、POST等）、请求头等信息。
> 4. **服务器处理请求，返回网页内容**：
>    - 服务器接收到请求后，会根据请求的内容进行处理。
>    - 如果请求的资源存在并且服务器能够响应，则服务器会返回相应的资源内容；否则返回相应的状态码，表示请求失败或资源不存在等情况。
> 5. **接收响应并渲染页面**：
>    - 浏览器接收到服务器响应后，开始解析响应内容。
>    - 如果响应的内容是 HTML 页面，则浏览器会逐步解析页面结构、加载页面所需的外部资源（如样式表、脚本、图片等）。
>    - 浏览器根据解析的内容逐步渲染页面，直至完全加载完成。
> 6. **TCP四次挥手，连接结束**：
>    - 页面加载完成后，浏览器会关闭与服务器之间的 TCP 连接，释放资源。

# 13. 七层协议

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429111426.jpg" alt="img" style="zoom:67%;" />

- **物理层**：

解决两个硬件之间怎么通信的问题，常见的物理媒介有光纤、电缆、中继器等。它主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。

它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输，到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换）。这一层的数据叫做比特。

- **数据链路层：**

在计算机网络中由于各种干扰的存在，物理链路是不可靠的。该层的主要功能就是：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。

它的具体工作是接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层的数据叫做帧。

- **网络层：**

该层的主要任务就是：通过路由选择算法，为报文（该层的数据单位，由上一层数据打包而来）通过通信子网选择最适当的路径。这一层定义的是IP地址，通过IP地址寻址，所以产生了IP协议。

- **传输层：**

当发送大量数据时，很可能会出现丢包的情况，另一台电脑要告诉是否完整接收到全部的包。如果缺了，就告诉丢了哪些包，然后再发一次，直至全部接收为止。

简单来说，传输层的主要功能就是：监控数据传输服务的质量，保证报文的正确传输。

- **会话层：**

虽然已经可以实现给正确的计算机，发送正确的封装过后的信息了。但我们总不可能每次都要调用传输层协议去打包，然后再调用IP协议去找路由，所以我们要建立一个自动收发包，自动寻址的功能。于是会话层出现了：它的作用就是建立和管理应用程序之间的通信。

- **表示层：**

表示层负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。

- **应用层：**

应用层是计算机用户，以及各种应用程序和网络之间的接口，其功能是直接向用户提供服务，完成用户希望在网络上完成的各种工作。前端同学对应用层肯定是最熟悉的。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220429111532.jpg" alt="img" style="zoom:67%;" />

# 14. 为什么要三次握手

- 三次握手是在安全可靠的基础上最少握手次数的方案，而两次握手并不能保证可靠性，四次握手又浪费了传输效率。
- TCP 传输控制协议，是一个面向连接的协议。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。

三次握手 建立起 TCP连接 的 reliable，**分配初始序列号**和**资源**，在相互确认之后开始数据的传输。有 主动打开(一般是client) 和 被动打开(一般是server)。

TCP使用3次握手建立一条连接，该握手初始化了传输可靠性以及数据顺序性必要的信息，这些信息包括两个方向的初始序列号，确认号由初始序列号生成，使用3次握手是因为3次握手已经准备好了传输可靠性以及数据顺序性所必要的信息，该握手的第3次实际上并不是需要单独传输的，完全可以和数据一起传输。详细过程如下所示：

> 第一步，Client会进入SYN_SENT状态，并发送Syn 消息给Server端，SYN标志位在此场景下被设置为1，同时会带上Client这端分配好的Seq号，这个序列号是一个U32的整型数，该数值的分配是根据时间产生的一个随机值，通常情况下每间隔4ms会加1。除此之外还会带一个MSS，也就是最大报文段长度，表示Tcp传往另一端的最大数据块的长度。
>
> 第二步，Server端在收到，Syn消息之后，会进入SYN_RCVD状态，同时返回Ack消息给Client，用来通知Client，Server端已经收到SYN消息并通过了确认。这一步Server端包含两部分内容，一部分是回复Client的Syn消息，其中ACK=1，Seq号设置为Client的Syn消息的Seq数值+1；另一部分是主动发送Sever端的Syn消息给Client，Seq号码是Server端上面对应的序列号，当然Syn标志位也会设置成1，MSS表示的是Server这一端的最大数据块长度。
>
> 第三步，Client在收到第二步消息之后，首先会将Client端的状态从SYN_SENT变换成ESTABLISHED,此时Client发消息给Server端，这个方向的通道已经建立成功，Client可以发送消息给Server端了，Server端也可以成功收到这些消息。其次，Client端需要回复ACK消息给Server端，消息包含ACK状态被设置为1，Seq号码被设置成Server端的序列号+1。（备注：这一步往往会与Client主动发起的数据消息，合并到一起发送给Server端。）
>
> 第四步，Server端在收到这个Ack消息之后，会进入ESTABLISHED状态，到此时刻Server发向Client的通道连接建立成功，Server可以发送数据给Client，TCP的全双工连接建立完成。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170155324.png" alt="image-20241117015514192" style="zoom:50%;" />

## 不能两次握手

如果客户端想建立连接，给服务端发了一个连接请求（SYN），但是由于网络中种种情况，导致没有及时到达服务端，这就导致客户端在很长一段时间中没有收到回复消息（ACK），这时客户端又给服务端发送一个SYN，这次的发送和接收的很顺利，很快就收到了ACK，但是这时之前的SYN终于到了服务端，服务端规规矩矩的为这个SYN申请资源，然后返回ACK。由于之前的SYN已经失效了，所以客户端也不会去理会这个ACK，但是傻乎乎的服务端并不知道这个SYN已经失效了，一直为他委会着资源，这就造成了资源的浪费。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170155527.png" alt="image-20241117015533399" style="zoom:50%;" />

## 四次挥手

<img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170155954.png" alt="image-20241117015548832" style="zoom:50%;" />

1. 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。

2. 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。

3. 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。

4. 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1， Server进入CLOSED状态，完成四次挥手。

如果有大量的连接，每次在连接、关闭时都要三次握手，四次挥手，会很明显会造成性能低下，因此，

HTTP有一种叫做 keep connection 的机制，它可以在传输数据后仍然保持连接，当客户端再次获取数据时，直接使用刚刚空闲下的连接而无需再次握手

![preview](https://gitee.com/qc_faith/picture/raw/master/image/20220502172156.jpg)

## HTTP&HTTPS

| 区别     | HTTP                                                         | HTTPS                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协议     | 运行在 TCP 之上，明文传输，**客户端与服务器端都无法验证对方的身份** | 基于 HTTP，额外增加了TLS/SSL连接加密， **是添加了加密和认证机制的 HTTP**。 |
| 端口     | 80                                                           | 443                                                          |
| 性能     | 通常较高                                                     | 可能略低，由于加解密处理，会消耗更多的 CPU 和内存资源，但随着技术进步，差异逐渐减小 |
| 证书     | 无需证书                                                     | 需要 SSL 证书，由可信任的证书颁发机构（CA）颁发，用于验证服务器身份 |
| 加密机制 | 无                                                           | 共享密钥加密和公开密钥加密并用的混合加密机制                 |
| 安全性   | 不安全，数据以明文形式传输，易被第三方截取和查看             | 安全，使用 TLS/SSL 协议加密数据包，防止拦截和篡改            |

### 区别

1. `https`需要证书，一般不免费
2. `http`明文传输、`https`运用`SSL`加密传输
3. `http`和`https`使用的是完全不同的连接方式，用的端口也不一样，`http`是`80`，`https`是`443`
4. `http`无状态，`https`是由`SSL+http`构建的可进行**加密传输、身份认证**的网络协议，比`http`安全

### HTTP存在的问题和HTTPS解决的问题

1. 被监听

   `http`明文传输，通信过程数据容易被劫持。`https`是加密传输

2. 被伪装

   `http`通信时，无法保证通行双方是合法的，通信方可能是伪装的。比如你请求www.taobao.com,你怎么知道返回的数据就是来自淘宝，中间人可能返回数据伪装成淘宝。`https`用证书区分合法非法，相当于身份证

3. 被篡改

   `http`通信时易被篡改数据，接收方不知道数据已被修改。`https`对数据做了摘要，数据修改易被感知

### HTTPS缺点

`https`保证了通信的安全，但带来了**加密解密消耗计算机cpu资源**的问题 ，不过，有专门的`https`加解密硬件服务器

### HTTP 状态码

状态码第一位数字决定了不同的响应状态，有如下：

- 1 表示消息
- 2 表示成功
- 3 表示重定向
- 4 表示客户端错误
- 5 表示服务器错误

<span style="background:#f9eda6;">1xx（信息性状态码）</span>

表示请求已被接受，需要继续处理。这类响应是临时响应，只包含状态行和某些可选的响应头信息，并以空行结束

> 常见的有：
>
> - 100（客户端继续发送请求，这是临时响应）：这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应
> - 101：服务器根据客户端的请求切换协议，主要用于websocket或http2升级

<span style="background:#f9eda6;">2xx（成功状态码）</span>

表示请求已成功被服务器接收、理解、并接受

> 常见的有：
>
> - 200（成功）：请求已成功，请求所希望的响应头或数据体将随此响应返回
> - 201（已创建）：请求成功并且服务器创建了新的资源
> - 202（已创建）：服务器已经接收请求，但尚未处理完成
> - 203（非授权信息）：服务器已成功处理请求，但返回的信息可能来自另一来源
> - 204（无内容）：服务器成功处理请求，但没有返回任何内容
> - 205（重置内容）：服务器成功处理请求，但没有返回任何内容
> - 206（部分内容）：表示服务器成功处理了部分请求，通常在断点续传或分块下载时使用

<span style="background:#f9eda6;">3xx（重定向状态码）</span>

表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向

> 常见的有：
>
> - 300（多种选择）：针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择
> - 301（永久移动）：请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置
> - 302（临时移动）： 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求
> - 303（查看其他位置）：请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码
> - 304（协商缓存）：服务器通过返回状态码304可以告诉客户端请求资源成功，但是这个资源不是由服务器提供返回给客户端的，而是客户端本地浏览器缓存中就有的这个资源，因为可以从缓存中获取这个资源，从而节省传输的开销。（也有可能是前端没有配置`nginx`代理）
> - 305 （使用代理）： 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理
> - 307 （临时重定向）： 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求

<span style="background:#f9eda6;">4xx（客户端错误状态码）</span>

表示服务器无法处理请求，客户端出现错误。

> 常见的有：
>
> - 400（错误请求）： 服务器不理解请求的语法
> - 401（未授权）： 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。
> - 403（禁止）： 服务器拒绝请求
> - 404（未找到）： 请求的资源不存在
> - 405（方法禁用）： 禁用请求中指定的方法
> - 406（不接受）： 无法使用请求的内容特性响应请求的网页
> - 407（需要代理授权）： 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理
> - 408（请求超时）： 服务器等候请求时发生超时

<span style="background:#f9eda6;">5xx（服务器错误状态码）</span>

表示服务器无法完成明显有效的请求。这类状态码代表了服务器在处理请求的过程中有错误或者异常状态发生

> 常见的有：
>
> - 500（服务器内部错误）：服务器遇到错误，无法完成请求
> - 501（尚未实施）：服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码
> - 502（错误网关）： 服务器作为网关或代理，从上游服务器收到无效响应
> - 503（服务不可用）： 服务器目前无法使用（由于超载或停机维护）
> - 504（网关超时）： 服务器作为网关或代理，但是没有及时从上游服务器收到请求
> - 505（HTTP 版本不受支持）： 服务器不支持请求中所用的 HTTP 协议版本

#### 502排查

502 Bad Gateway 是指服务器作为网关或代理服务器时，未能从上游服务器（如 Tomcat、Nginx、Apache 等）接收到有效的响应。

针对 502 错误，可以从以下几个方面进行排查：

1. **服务状态检查：** 检查服务器的运行状态，确认服务是否正常运行。可以通过访问服务的端点（URL、IP 地址）来确认服务是否可访问。
2. **日志分析：** 查看服务器的日志，如 Nginx、Tomcat、应用程序的日志等，检查是否有相关的错误或异常信息。
3. **网络问题：** 检查网络连接是否正常，可能的网络故障或者代理配置错误也可能导致 502 错误。
4. **服务配置：** 检查服务器的配置文件是否正确，尤其是代理、反向代理或负载均衡器的配置。
5. **后端服务故障：** 如果是代理服务器出现问题，检查上游服务（如后端应用服务器）是否出现故障、负载过高或者超时。
6. **负载均衡器问题：** 如果使用了负载均衡器，检查负载均衡器的状态、配置和日志，确认是否出现故障或配置错误。
7. **数据库连接：** 如果服务依赖数据库，检查数据库连接是否正常，是否存在数据库连接池超时、数据库异常等问题。
8. **系统资源：** 检查服务器的系统资源，如 CPU 使用率、内存占用等，确认是否达到系统资源限制。

### 反向代理

反向代理代表服务器接收客户端的请求，并将这些请求转发到其他服务器上。客户端感知到的是与代理服务器直接通信，而不知道请求实际上是被代理服务器代理转发到了其他服务器上。

**工作原理：**

1. 接收请求： 反向代理服务器接收到客户端的请求。
2. 选择目标服务器： 根据配置或算法选择合适的后端服务器，这可以基于负载均衡算法，比如轮询、加权轮询、最小连接数等。
3. 请求转发： 将接收到的请求转发到选定的后端服务器。
4. 返回结果： 代理服务器接收到后端服务器的响应后，再将结果返回给客户端。

正向代理是代理客户端, 服务端不知道实际发起请求的客户端.

> <font color='Apricot'>作用：</font>
>
> 1. 访问原来无法访问的资源，如google
> 1. 可以做缓存，加速访问资源
> 1. 对客户端访问授权，上网进行认证
> 1. 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

反向代理是代理服务端, 客户端不知道实际提供服务的服务端.

> <font color='Apricot'>作用：</font>
>
> 1. 保证服务器内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。
> 2. 负载均衡，通过反向代理服务器来优化网站的负载。
> 3. 缓存加速：反向代理可以缓存请求结果，减轻后端服务器压力，提高响应速度。
> 4. 协议转换：反向代理可以将不同的协议进行转换，例如将 HTTP 请求转换成 HTTPS 请求。

### 请求过程（工作原理）

`HTTP`和`HTTPS`都需要在建立连接的基础上来进行数据传输,是基本操作，也就是经典`TCP`三次握手建连

1、`http`原理 （`http----->tcp`）

​	建立连接完毕以后客户端会发送请求给服务端

​	服务端接受请求并且做出响应发送给客户端

​	客户端收到响应并且解析响应显示给客户

2、**https原理**（`http------>SSL----->tcp`）

​	1）、在使用`HTTPS`时需要保证服务端配置正确了对应的安全证书，相当于身份证

​	2）、客户端发送请求到服务器端（包括客户端支持的加密协议及版本）

​	3）、服务器端返回证书和公钥到客户端，公钥作为证书的一部分而存在

​	4）、客户端验证证书和公钥的有效性，如果有效，则会随机生成一个随机数，用公钥对其加密，发送到服务端

​	5）、服务端接受到这个加密后的随机数后会用私钥对其解密得到真正的随机数，随后用这个随机数当做私钥对需要发送的数据进行对称加密

​	6）、客户端在接收到加密后的数据使用私钥（即生成的随机值）对数据进行解密并且解析数据呈现结果给客户

​	7）、SSL加密建立

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20220502172855.png" alt="image-20220502172854241" style="zoom:50%;" />

### 其他问题

1. 怎样保证公开密钥的有效性

   怎么保证公钥是合法的，不是伪造的，证书解决了这个问题，证书由权威的第三方机构颁发，并对公钥做了签名。

2. 金融机构出于安全考虑使用https，那么为什么百度、知乎也使用https？

   为防止运营商（移动、电信等）劫持，运营商可能会在数据中插入各种广告，用了https，数据无法被劫持。

3. **网络七层协议**

   网络七层协议由下往上分别为**物理层**、**数据链路层**、**网络层**、**传输层**、**会话层**、**表示层**、**应用层**。

   其中：HTTP协议对应于应用层，TCP协议对应于传输层、IP协议对应于网络层。HTTP协议是基于TCP连接的，三者本质上没有可比性。

4. TCP/IP、HTTP主要是干什么的？有什么用？

   TCP/IP主要解决数据如何在网络中传输。

   HTTP主要解决如何包装数据。

5. TCP与UDP异同

   二者都是传输层协议，主要区别是可靠服务/不可靠服务

   <img src="https://gitee.com/qc_faith/picture/raw/master/image/202411170157624.png" alt="image-20241117015759496" style="zoom:67%;" />

7. `tcp`三次握手，第三次，客户端怎么知道服务端有没有收到

   > TCP用三次握手（或称三路握手，three-way handshake）过程创建一个连接。在连接创建过程中，很多参数要被初始化，例如序号被初始化以保证按序传输和连接的强壮性。
   >
   > 一对终端同时初始化一个它们之间的连接是可能的。但通常是由一端（服务器端）打开一个套接字（socket）然后监听来自另一方（客户端）的连接，这就是通常所指的被动打开（passive open）。服务器端被被动打开以后，客户端就能开始创建主动打开（active open）。 
   >
   > 服务器端执行了listen函数后，就在服务器上创建起两个队列： 
   >
   > - SYN队列：存放完成了二次握手的结果。 队列长度由listen函数的参数backlog指定。
   > - ACCEPT队列：存放完成了三次握手的结果。队列长度由listen函数的参数backlog指定。 
   >
   > 三次握手协议的过程： 
   >
   > - 客户端（通过执行connect函数）向服务器端发送一个SYN包，请求一个主动打开。该包携带客户端为这个连接请求而设定的随机数A作为消息序列号。
   > - 服务器端收到一个合法的SYN包后，把该包放入SYN队列中；回送一个SYN/ACK。ACK的确认码应为A+1，SYN/ACK包本身携带一个随机产生的序号B。 
   > - 客户端收到SYN/ACK包后，发送一个ACK包，该包的序号被设定为A+1，而ACK的确认码则为B+1。然后客户端的connect函数成功返回。当服务器端收到这个ACK包的时候，把请求帧从SYN队列中移出，放至ACCEPT队列中；这时accept函数如果处于阻塞状态，可以被唤醒，从ACCEPT队列中取出ACK包，重新创建一个新的用于双向通信的sockfd，并返回。
   > -  如果服务器端接到了客户端发的SYN后回了SYN-ACK后客户端掉线了，服务器端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功，也没失败。于是，服务器端如果在一定时间内没有收到的TCP会重发SYN-ACK。
   > - 在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s，TCP才会断开这个连接。使用三个TCP参数来调整行为：tcp_synack_retries 减少重试次数；tcp_max_syn_backlog，增大SYN连接数；tcp_abort_on_overflow决定超出能力时的行为。 “三次握手”的目的是“为了防止已失效的连接(connect)请求报文段传送到了服务端，因而产生错误”，也即为了解决“网络中存在延迟的重复分组”问题。例如：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client发出的一个新的连接请求。于是就向client发出确认报文段，同意创建连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就创建了。由于现在client并没有发出创建连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经创建，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求创建连接。

# 15.进程之间的通信方式？

<span style="background:#f9eda6;">管道( pipe )</span>

管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

<span style="background:#f9eda6;">有名管道 (namedpipe)</span>

有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

<span style="background:#f9eda6;">信号量(semophore )</span>

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

<span style="background:#f9eda6;">消息队列( messagequeue )</span>

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

<span style="background:#f9eda6;">信号 (sinal )</span>

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

<span style="background:#f9eda6;">共享内存(shared memory )</span>

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

<span style="background:#f9eda6;">套接字(socket )</span>

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

## 线程间的通信方式

**锁机制：包括互斥锁、条件变量、读写锁**

- 互斥锁提供了以排他方式防止数据结构被并发修改的方法。
- 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
- 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

**信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量**

**信号机制(Signal)：类似进程间的信号处理**

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。
