# 分布式理论

## CAP定理

在一个分布式系统中，以下三点特性无法同时满足，一个Web应用<font color='RedOrange'>至多只能同时支持下面的两个属性</font>

> - 一致性（C）： 所有节点上的数据在同一时刻是否相同。
> - 可用性（A）： 每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据
> - 分区容错性（P）： 系统在面临网络分区的情况下是否能够继续工作。
>   - 网络分区是常见且不可避免的情况，特别是在大规模系统中。因此，选择 P（Partition tolerance）是非常重要的，以确保系统在面临网络分区的情况下仍然能够继续工作。如果不选择 P，一旦发生网络分区，可能会导致整个系统无法使用，从而影响业务的正常运行。因此，CAP 理论指导下的分布式系统设计通常会优先考虑 P，以保证系统的稳定性和可用性。

<font color='Apricot'>一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。当一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低</font>。

注册中心一般分为两种： 

> - <font color='RedOrange'>CP 注册中心</font>：牺牲可用性来保证数据强一致性，最典型就是 ZooKeeper、etcd、Consul。ZooKeeper 只有一个 Leader 网络出现问题，发生脑裂出现多个 Leader 后，注册中心不可用，etcd 和 Consul 使用 raft 保证强一致性，出现脑裂后，注册中心也不可用。 
>- <font color='RedOrange'>AP 注册中心</font>：牺牲一致性来保证可用性，Nacos可以配置为 AP，最典型的是 Eureka，其无需选举一个 Leader，每个 Eureka 服务器单独保存服务中服务注册地址，可能出现数据不一致，但网络出现问题，每个 Eureka 服务其独立完成服务。 
> 
>对于注册中心，最主要的功能是服务的注册和发现，在网络出现问题的时候，可用性的需求要远远高于数据一致性。即使因为数据不一致，注册中心内引入了不可用的服务节点，也可以通过其他措施来避免，比如客户端的快速失败机制等，只要实现最终一致性，对于注册中心来说就足够了。因此，选择AP型注册中心，一般更加合适

## BASE理论

B：基本可用（响应时间适当增长、功能部分可用），可以通过延迟响应，流量削峰等手段来保障系统的核心功能的正常，从而实现基本可用。

S：软状态（数据同步允许存在一定的延时） ，就是可以变动的状态，强调的是数据状态处于一种短暂的临界状态。

E：最终一致性（系统中的所有副本，在一定的时间内，最终保持一致性）

# 分布式事务

分布式事务的常见解决方案主要分为 <font color='Peach'>强一致性的解决方案</font> 和 <font color='Peach'>最终一致性的解决方案</font>

<img src="https://gitee.com/qc_faith/picture/raw/master/image/20240318110255.png" alt="img" style="zoom: 67%;" />

### 强一致性的解决方案

<font color='Apricot'>**XA 分布式事务协议**</font>：

> XA中大致分为两部分：事务管理器和本地资源管理器。其中本地资源管理器往往由数据库实现，比如mysql、oracle、sqlserver、postgre库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。XA 协议通常包含两阶段提交（2PC）和三阶段提交（3PC）两种实现。XA 并发性能不太好，无法满足高并发场景，在互联网中使用较少。

<font color='Apricot'>**2PC 两阶段提交**</font>：

> 是非常经典的强一致性、中心化的原子提交协议，它通过协调者询问所有参与者是否可以提交，然后再通知所有参与者执行提交或回滚的操作。这种方法的缺点是在第二阶段可能会有阻塞，且协调者单点故障会导致整个系统无法工作。
>
> 1. 每个参与者执行本地事务，但不提交，进入ready状态，并通知协调者已经准备就绪（此阶段失败可以设置超时时间重试，超时按执行失败处理）
>2. 当事务管理器收到所有参与者的 ready 状态后通知参与者发起 commit 操作，否则发出rollback（此阶段失败只能无限重试）

实现方案： `Atomikos `中，严格的两阶段提交（Strict Two-Phase Commit）是默认的事务提交策略。Atomikos 提供了相应的配置选项和 API 来支持这种策略。

> 配置：
> 在 `Atomikos `的配置文件（如 `atomikos.properties` 或 Spring Boot 中的配置文件）中，可以设置以下属性来配置严格的两阶段提交：
> `com.atomikos.icatch.forceTwoPhaseCommit`：设置为 true 表示启用严格的两阶段提交，即使只有一个参与者时也会执行两阶段提交。
> 默认值为 false，表示只有在多个参与者时才执行两阶段提交。

<font color='Apricot'>**3PC 三阶段提交**</font>：

>  相对于2PC来说增加了CanCommit阶段和超时机制。如果段时间内没有收到协调者的commit请求，那么就会自动进行commit，解决了2PC单点故障的问题。
>
> 1、CanCommit阶段：询问事务参与者，你是否有能力完成此次事务；剩余两阶段与 2PC 一致

<font color='Apricot'>**DTS 方案**</font>：

> 阿里有一个分布式事务服务 (Distributed Transaction Service, DTS)， 是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。DTS 从架构上分为 xts-client 和 xts-server 两部分，前者是一个嵌入客户端应用的 JAR 包，主要负责事务数据的写入和处理；后者是一个独立的系统，主要负责异常事务的恢复。

<font color='Apricot'>**本地消息表（Local Message Table）**： </font>

> 在本地数据库中维护一个消息表，用于记录事务的执行状态。当事务需要提交时，先将消息插入消息表，然后再异步处理事务。如果事务失败，可以通过消息表进行回滚。这种方式可以提高性能，但要注意消息表的一致性。

### 最终一致性的解决方案

<font color='Apricot'>**TCC 分段提交【较常用】**</font>：

> 实现分布式事务，最常用的方法是二阶段提交协议和 TCC，这两个算法的适用场景是不同的，二阶段提交协议实现的是数据层面的事务，比如 XA 规范采用的就是二阶段提交协议；TCC 实现的是业务层面的事务，比如当操作不仅仅是数据库操作，还涉及其他业务系统的访问操作时，这时就应该考虑 TCC 了。
>
> <font color='RedOrange'>TCC 是一个分布式事务的处理模型，将事务过程拆分为 Try、Confirm、Cancel 三个步骤，在保证强一致性的同时，最大限度提高系统的可伸缩性与可用性，又被称补偿事务。它的核心思想是针对每个操作都要注册一个与其对应的确认操作和补偿操作（也就是撤销操作）</font>
>
> TCC 实现的是业务层面的事务，TCC 可以理解为是一个业务层面的协议，可以当做为一个编程模型来看待，因此这个的应用还是非常广泛的。TCC 的 3 个操作是需要在业务代码中编码实现的，为了实现一致性，确认操作和补偿操作必须是等幂的，因为这 2 个操作可能会失败重试。
>
> TCC 不依赖于数据库的事务，而是在业务中实现了分布式事务，这样能减轻数据库的压力，但<font color='Chestnut Red'>对业务代码的入侵性也更强，实现的复杂度也更高</font>。

<font color='Apricot'>**MQ（非事务消息）【较常用】**</font>

> 采用非事务消息的这种方式比较常见，一个是由于市面上很多这种成熟的非事务消息的解决方案，一个是由于这些 MQ 的性能和吞吐量都比较好，可以满足大部分的业务场景。
>
> 一个典型流程基本上就是，生产者先执行本地事务并将消息落库，状态标记为待发送，然后发送消息。如果发送成功，则将消息改为发送成功；如果发送失败则不修改标记。然后会起一个定时任务，定时从数据库捞取在一定时间内待发送的消息并将消息发送。为确保消息一定能消费，消费者一般采用手动 ACK 机制，并且最好支持幂等。
>
> 在消费者端，我们可能面临的问题和解决方案是：
>
> 1. 消费者消费消息后，要保证对应的业务操作要执行成功之后才能主动 ACK。如果业务执行失败，消息不能失效或者丢失。目前主流的 MQ 产品都具有持久化消息的功能，如果消费者宕机或者消费失败，都可以执行重试机制的，因此这个比较好解决。
> 2. 消费者消费消息要能够在业务层面保持幂等，因为消费可能会失败，因此只有具有幂等性，才能不影响业务。具体的方案，在业务层可以采用唯一主键来解决，也可以采用其他的日志或库表（去重表）来保证。
>
> 在生产者端，面临的问题是执行本地事务和发送消息是两个异步的操作，他们并不能保证强一致性，因此有一定的概率会出现一些 bug。

<font color='Apricot'>**MQ（事务消息）【没有开源方案】**</font>

> 在分布式事务实践中事务性消息也是比较常使用的，<font color='RedOrange'>所谓的消息事务就是基于消息队列的两阶段提交，本质上是对消息队列的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，本地事务和发送消息这两个步骤是保持了强一致性的，保证要么本地操作成功并且对外发消息成功，要么两者都失败，这种消息就是事务性消息。和不支持事务的消息中间相比，只是消息发送的时候，保证了和本地事务的一致。消费者实现还是不变。</font>
>
> 通过事务消息来实现的话，整体的可靠性会比较高，阿里的 RocketMQ 就是属于事务消息。RocketMQ 的事务消息的设计思路是：RocketMQ 第一阶段发送 Prepared 消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。然后需要定期扫描消息集群中的事物消息，这时候发现了 Prepared 消息，它会向消息发送者确认，RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。<font color='RedOrange'>RocketMQ 中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且 RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。</font>
>
> 目前一些主流的开源消息队列比如 ActiveMQ、RabbitMQ、Kafka 等都没有实现对事务消息的支持，但是可以有类似的实现方式。比如，Kafka 中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。

<font color='Apricot'>**SAGA 长流程分布式事务【较常用】**</font>

> SAGA 用于处理有序的一长串的长流程的事务，相对来说，性能更好，无资源锁定，无流程阻塞，但是不保证事务间的隔离性与原子性，需要业务侧根据需要处理可能的问题。
>
> SAGA 的每个子事务都有一个补偿接口，如果执行到某个阶段失败后，则对已经成功的子事务按栈顺序依次进行补偿操作（补偿不允许失败，失败必须重试直到成功），SAGA 的一阶段为 Do，二阶段是 Undo，每个 Do 都是一个完整的事务，但整个流程并不能保证隔离性与原子性。

<font color='Apricot'>**业务补偿方式：重试(or 回滚)+告警+人工修复【较常用】**</font>

> 另外一个实现弱一致性的比较简单粗暴的方式，就是采用业务补偿方式，通过重试 + 回滚 (自动或手动)的方式，当出现不一致的时候，进行重试，重试还是失败后就进行回滚，或者告警后人工修复。
>
> 补偿事务的缺点在于不同的业务要写不同的补偿事务，不具备通用性；并且如果业务流程很复杂，if/else会嵌套非常多层；同时也没有考虑补偿事务失败的后续流程。总之是一个比较糙的解决方案。在对一致性要求不高的情况下，如果又想要比较简单的实现，可以采用这种业务补偿方式。业务补偿设计的主要核心点在于：
>
> - 将服务做成幂等性的，如果一个事务失败了或是超时了，我们需要不断地重试，努力地达到最终我们想要的状态。
>
> - 如果执行不下去，需要启动补偿机制，回滚业务流程。

# 分布式锁

## 特征

- **「互斥性」**: 任意时刻，只有一个客户端能持有锁。
- **「锁超时释放」**：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。
- **「可重入性」**:一个线程如果获取了锁之后,可以再次对其请求加锁。
- **「高性能和高可用」**：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。
- **「安全性」**：锁只能被持有的客户端删除，不能被其他客户端删除

## 实现方案：

<font color='Chestnut Red'>**单机部署**</font>：

1. <font color='Apricot'>**基于缓存（如Redis）实现**</font>：利用分布式缓存系统（如Redis）的原子性操作，通过SETNX（SET if Not eXists）或者类似的原子操作来实现锁。Redis 还提供了更高级的 SETEX 命令，可以设置锁的过期时间，避免死锁问题。

   1. SETNX + EXPIRE

      - SETNX key value，如果 key不存在，则 SETNX 成功返回1，如果 key 已经存在，则返回0。
      - 但是这个方案中，`setnx`和`expire`两个命令分开了，**「不是原子操作」**。如果执行完`setnx`加锁，正要执行`expire`设置过期时间时，进程**崩溃**或者要重启维护了，那么这个锁就“长生不老”了，**「别的线程永远获取不到」**

   2. SETNX + value值是（系统时间+过期时间）

      可以把过期时间放到`setnx`的value值里面。如果加锁失败，再拿出value值校验一下即可。加锁代码如下：

      ~~~java
      long expires = System.currentTimeMillis() + expireTime; //系统时间+设置的过期时间
      String expiresStr = String.valueOf(expires);
      
      // 如果当前锁不存在，返回加锁成功
      if (jedis.setnx(key_resource_id, expiresStr) == 1) {
              return true;
      } 
      // 如果锁已经存在，获取锁的过期时间
      String currentValueStr = jedis.get(key_resource_id);
      
      // 如果获取到的过期时间，小于系统当前时间，表示已经过期
      if (currentValueStr != null && Long.parseLong(currentValueStr) < System.currentTimeMillis()) {
      
           // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间（
          String oldValueStr = jedis.getSet(key_resource_id, expiresStr);
          if (oldValueStr != null && oldValueStr.equals(currentValueStr)) {
               // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁
               return true;
          }
      }        
      //其他情况，均返回加锁失败
      return false;
      }
      ~~~

      **缺点**：

      - 过期时间是客户端自己生成的（System.currentTimeMillis()是当前系统的时间），必须要求分布式环境下，每个客户端的时间必须同步。
      - 如果锁过期的时候，并发多个客户端同时请求过来，都执行`jedis.getSet()`，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖
      - 该锁没有保存持有者的唯一标识，可能被别的客户端释放/解锁。

   3. 使用Lua脚本(包含SETNX + EXPIRE两条指令)

   4. SET的扩展命令（SET EX PX NX）

      > SET key value [EX seconds] [PX milliseconds] [NX|XX]，它也是原子性的
      >
      > - NX :表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获得锁，而其他客户端请求只能等其释放锁，才能获取。
      > - EX seconds :设定key的过期时间，时间单位是秒。
      > - PX milliseconds: 设定key的过期时间，单位为毫秒
      > - XX: 仅当key存在时设置值

      **缺点**：

      - **「锁过期释放了，业务还没执行完」**。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的。
      - **「锁被别的线程误删」**。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完。

   5. SET EX PX NX  + 校验唯一随机值，再释放锁

2. <font color='Apricot'>**基于Zookeeper实现**</font>：使用 ZooKeeper 提供的临时节点（ephemeral node）特性，通过创建一个临时节点来表示锁的持有。客户端创建临时节点成功的那个将获得锁，其他客户端则监听该节点的删除事件。Zookeeper作为一种高可用的分布式协调服务，相比于Redis分布式锁，Zookeeper分布式锁具有以下优缺点：		

   > 优点：			
   >
   > 1. 可以避免锁的失效问题：Zookeeper采用基于ZAB协议的分布式一致性算法，可以保证分布式锁的强一致性，避免因主从同步延迟导致锁失效问题。
   > 2. 支持更复杂的锁机制：Zookeeper提供了两种锁实现方式：共享锁和排他锁，可以根据具体的业务场景选择最适合的方式。
   > 3. 可以与其他Zookeeper服务集成：Zookeeper还提供了诸如分布式队列、命名服务等功能，可以与分布式锁一起使用，构建更完整的分布式应用系统。
   >
   > 缺点：
   >
   > 1. 性能相对较低：Zookeeper采用基于ZAB协议的分布式一致性算法，需要进行多次网络通信和数据同步，相比于Redis分布式锁，性能相对较低。
   > 2. 部署和维护成本较高：Zookeeper需要部署专门的服务器集群，需要进行一定的配置和维护工作，相比于Redis分布式锁，部署和维护成本较高。

3. <font color='Apricot'>**基于数据库实现**</font>，有两种方式：		

   - 使用数据库的事务性和唯一性约束来实现分布式锁。通过在数据库中插入一条记录或者更新一条记录，利用数据库的唯一性约束来确保只有一个客户端能够成功插入或更新。
   - 利用数据库的乐观锁机制，通过在记录中添加版本号等字段，实现分布式锁。客户端在获取锁时，检查版本号，成功则获取锁，失败则重试或者放弃。

   > 相比于Redis和Zookeeper分布式锁，MySQL分布式锁具有以下优缺点：
   >
   > 优点：
   >
   > 1. 易于部署和维护：MySQL已经广泛应用于各种应用场景中，部署和维护相对较为简单。
   > 2. 支持更复杂的锁机制：MySQL提供了多种锁实现方式，如行锁、表锁、读锁、写锁等，可以根据具体的业务场景选择最适合的方式。
   >
   > 缺点：
   >
   > 1. 性能较低：MySQL采用基于磁盘的存储方式，相比于Redis和Zookeeper，性能较低。
   > 2. 可扩展性较差：由于MySQL采用基于磁盘的存储方式，其可扩展性较差，难以应对高并发场景下的锁控制需求。
   > 3. 存在单点故障问题：MySQL采用主从复制的方式进行数据同步，存在单点故障问题，可能导致锁失效问题。

4. <font color='Apricot'>**开源框架~Redisson**</font>

   > Redisson中有比较成熟的分布式锁的方案，其提供了一个专门用来监控和续期锁的 Watch Dog（ 看门狗），如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。（默认情况下，每过 10 秒，看门狗就会执行续期操作，将锁的超时时间设置为 30 秒。看门狗续期前也会先判断是否需要执行续期操作，需要才会执行续期，否则取消续期操作，具体是异步续期通过lua脚本操作）
   >
   > 可重入锁：一个线程中可以多次获取同一把锁，为每个锁关联一个可重入计数器和一个占有它的线程。Redisson 内置了多种类型的锁比如可重入锁（Reentrant Lock）、自旋锁（Spin Lock）、公平锁（Fair Lock）、多重锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）

<font color='Chestnut Red'>**集群部署**</font>：

- 多机实现的分布式锁Redlock

  - Redlock核心思想是这样的：

    搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。

    > 假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。RedLock的实现步骤如下：
    >
    > 1. 获取当前时间，以毫秒为单位。
    > 2. 按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。
    > 3. 客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s> 30ms+40ms+50ms+4m0s+50ms）
    > 4. 如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。
    > 5. 如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。

# 脑裂

在Elasticsearch、ZooKeeper这些集群环境中，有一个共同的特点，就是它们有一个“大脑”。比如，Elasticsearch集群中有Master节点，ZooKeeper集群中有Leader节点。

集群中的Master或Leader节点往往是通过选举产生的。在网络正常的情况下，可以顺利的选举出Leader（后续以Zookeeper命名为例）。但当两个机房之间的网络通信出现故障时，选举机制就有可能在不同的网络分区中选出两个Leader。当网络恢复时，这两个Leader该如何处理数据同步？又该听谁的？这也就出现了“脑裂”现象。

<font color='Apricot'>**产生原因**</font>：

以zookeeper集群的场景为例来分析

在使用zookeeper时，很少遇到脑裂现象，是因为zookeeper已经采取了相应的措施来减少或避免脑裂的发生。先假设zookeeper没有采取这些防止脑裂的措施。在这种情况下，脑裂问题是如何发生的：

> 假如有6台zkServer服务组成了一个集群，部署在2个机房：正常情况下，该集群只有一个Leader，当Leader宕掉时，其他5个服务会重新选举出一个新的Leader。
>
> 如果机房1和机房2之间的网络出现故障，暂时不考虑Zookeeper的过半机制，也就是说机房2的三台服务检测到没有Leader了，于是开始重新选举，选举出一个新Leader来。原本一个集群，被分成了两个集群，同时出现了两个“大脑”，这就是所谓的“脑裂”现象。
>
> 由于原本的一个集群变成了两个，都对外提供服务。一段时间之后，两个集群之间的数据可能会变得不一致了。当网络恢复时，就面临着谁当Leader，数据怎么合并，数据冲突怎么解决等问题。

上面的过程只是假设Zookeeper不做任何预防脑裂措施时会出现的问题。防止脑裂的措施有多种，Zookeeper默认采用的是“过半原则”。所谓的过半原则就是：在Leader选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。通过过半机制，达到了要么没有Leader，要没只有1个Leader，避免了脑裂问题。

对于过半机制除了能够防止脑裂，还可以实现快速的选举。因为过半机制不需要等待所有zkServer都投了同一个zkServer就可以选举出一个Leader，所以也叫快速领导者选举算法。

<font color='Apricot'>**Leader假死**</font>：

假设某个Leader假死，其余的followers选举出了一个新的Leader。这时，旧的Leader复活并且仍然认为自己是Leader，向其他followers发出写请求也是会被拒绝的。

因为ZooKeeper维护了一个叫epoch的变量，每当新Leader产生时，会生成一个epoch标号（标识当前属于那个Leader的统治时期），epoch是递增的，followers如果确认了新的Leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求。

也有可能 follower 不知道新的 Leader 存在，但这肯定不是大多数，否则新Leader无法产生。ZooKeeper的写也遵循 quorum(法定人数) 机制，因此，得不到大多数支持的写是无效的，旧 leader 即使各种认为自己是 Leader，依然没有什么作用。

<font color='Apricot'>**解决方案**</font>：

<font color='Magenta'>Quorums（法定人数）方式</font>

> 比如 3 个节点的集群，Quorums = 2，也就是说集群可以容忍1个节点失效，这时候还能选举出1个lead，集群还可用。比如4个节点的集群，它的Quorums = 3，Quorums要超过3，相当于集群的容忍度还是1，如果2个节点失效，那么整个集群还是无效的。这是ZooKeeper防止“脑裂”默认采用的方法。

<font color='Magenta'>添加心跳线</font>

> 集群中采用多种通信方式，防止一种通信方式失效导致集群中的节点无法通信。
>
> 比如，添加心跳线。原来只有一条心跳线路，此时若断开，则接收不到心跳报告，判断对方已经死亡。若有2条心跳线路，一条断开，另一条仍然能够接收心跳报告，能保证集群服务正常运行。心跳线路之间也可以 HA（高可用），这两条心跳线路之间也可以互相检测，若一条断开，则另一条马上起作用。正常情况下，则不起作用，节约资源。

<font color='Magenta'>启动磁盘锁定方式</font>

> 使用磁盘锁的形式，保证集群中只能有一个Leader获取磁盘锁，对外提供服务，避免数据错乱发生。但是，也会存在一个问题，若该Leader节点宕机，则不能主动释放锁，那么其他的Follower就永远获取不了共享资源。于是有人在HA中设计了"智能"锁。正在服务的一方只有在发现心跳线全部断开（察觉不到对端）时才启用磁盘锁。平时就不上锁了

<font color='Magenta'>仲裁机制方式</font>

> 脑裂导致的后果是从节点不知道该连接哪一台Leader，此时有一个仲裁方就可以解决此问题。比如提供一个参考的IP地址，心跳机制断开时，节点各自ping一下参考IP，如果ping不通，那么表示该节点网络已经出现问题，则该节点需要自行退出争抢资源，释放占有的共享资源，将服务的提供功能让给功能更全面的节点。

以上方式可以同时使用，可以减少集群中脑裂情况的发生，但不能完全保证，比如仲裁机制中2台机器同时宕机，那么此时集群中没有Leader 可以使用。此时就需要人工干预了。

# Nacos

Nacos 是一种分布式服务发现和配置管理工具，它可以用于**服务注册、健康检查**、负载均衡、故障恢复、动态配置等方面。支持多种服务发现方式和多种协议，可以帮助开发人员和运维人员更好地管理和维护分布式系统。

> 服务注册实现：
>
> - Nacos 的服务注册是通过 Agent 进程实现的。
> - 当一个服务启动时，它会向 Nacos 的 Agent 发送一个注册请求，Agent 会将服务的元数据存储在本地，并将服务的信息发送到 Nacos 的 Server 上。
> - 当服务停止时，它会向 Agent 发送一个注销请求，Agent 会将服务的元数据从本地删除，并将服务的信息从 Nacos 的 Server 上删除。
>
> 健康检查实现：
>
> - Nacos 的健康检查是通过 Agent 进程实现的。
> - 当一个服务注册后，它会向 Nacos 的 Agent 发送一个健康检查请求，Agent 会定期向服务发送健康检查请求，并根据服务的响应结果来判断服务的健康状态。
> - 如果服务的健康状态发生变化，Agent 会将服务的状态信息发送到 Nacos 的 Server 上，以便其他服务可以及时发现和处理。
>
> 负载均衡实现：
>
> - Nacos 的负载均衡是通过 Service Mesh 实现的。
> - 当一个服务需要访问其他服务时，它会向 Nacos 的 Agent 发送一个服务发现请求，Agent 会返回一个可用的服务地址列表，并根据负载均衡算法选择一个地址进行访问。
> - Nacos 支持多种负载均衡算法，包括轮询、随机、加权轮询、加权随机等。
>
> 故障恢复实现：
>
> - Nacos 的故障恢复是通过 Agent 进程实现的。
> - 当一个服务的健康状态发生变化时，Agent 会将服务的状态信息发送到 Nacos 的 Server 上，并通知其他服务进行故障恢复。
> - 如果一个服务无法访问其他服务，它会向 Nacos 的 Agent 发送一个故障恢复请求，Agent 会返回一个可用的服务地址列表，并根据负载均衡算法选择一个地址进行访问。
>
> 动态配置实现：
>
> - Nacos 的动态配置是通过 Config Server 实现的。
> - 当一个服务需要读取配置信息时，它会向 Nacos 的 Config Server 发送一个配置读取请求，Server 会返回存储在 Nacos 的配置信息。
> - 当配置信息发生变化时，Nacos 的 Config Server 会将变化的信息发送到所有注册了 Watcher 的服务，服务可以根据事件信息进行相应的处理。

## 服务发现方式

- Nacos 支持多种服务发现方式，包括 DNS、HTTP API、RPC API、Service Mesh 等。
- 其中，DNS 和 HTTP API 是最常用的服务发现方式，它们可以帮助开发人员和运维人员更方便地访问和管理服务。

## 服务注册表结构？

Nacos采用了数据的分级存储模型，最外层是Namespace，用来隔离环境。然后是Group，用来对服务分组。接下来就是服务（Service）了，一个服务包含多个实例，但是可能处于不同机房，因此Service下有多个集群（Cluster），Cluster下是不同的实例（Instance）。

对应到Java代码中，Nacos采用了一个多层的Map来表示。结构为Map<String, Map<String, Service>>，其中最外层Map的key就是namespaceId，值是一个Map。内层Map的key是group拼接serviceName，值是Service对象。Service对象内部又是一个Map，key是集群名称，值是Cluster对象。而Cluster对象内部维护了Instance的集合。

## 如何支撑数十万服务注册压力

Nacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个阻塞队列就立即响应给客户端。然后利用线程池读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。

## 如何避免并发读写冲突问题

Nacos在更新实例列表时，会采用CopyOnWrite技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。这样在更新的过程中，就不会对读实例列表的请求产生影响，也不会出现脏读问题了。

## 与Eureka的区别有哪些？

- 接口方式：Nacos与Eureka都对外暴露了Rest风格的API接口，用来实现服务注册、发现等功能
- 实例类型：Nacos的实例有永久和临时实例之分；而Eureka只支持临时实例
- 健康检测：Nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；Eureka只支持心跳模式
- 服务发现：Nacos支持定时拉取和订阅推送两种模式；Eureka只支持定时拉取模式

## Sentinel的限流与Gateway的限流有什么差别？

限流算法常见的有三种实现：滑动时间窗口、令牌桶算法、漏桶算法。Gateway则采用了基于Redis实现的令牌桶算法。

而Sentinel内部却比较复杂：

- 默认限流模式是基于滑动时间窗口算法
- 排队等待的限流模式则基于漏桶算法
- 而热点参数限流则是基于令牌桶算法

## Sentinel的线程隔离与Hystix的线程隔离有什么差别?

Hystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的CPU开销，性能一般，但是隔离性更强。

Sentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。

## 优缺点

**优点**

- 支持多种服务发现方式和多种协议，可以满足不同场景下的需求。
- 支持多种负载均衡算法和故障恢复机制，可以提高系统的可用性和稳定性。
- 支持动态配置，可以帮助开发人员更好地管理和维护配置信息。
- 支持多数据中心，可以帮助开发人员和运维人员更好地管理和维护分布式系统。

**缺点**

- 学习成本较高，需要掌握一定的分布式系统和网络知识。
- 部署和维护成本较高，需要投入一定的人力和物力。
- 对于小型项目来说，使用 Nacos 可能会过于复杂，不太适合初学者使用。

# Zookeeper

注册中心为什么要用Zookeeper

## ZAB协议

在Zookeeper中主要依赖Zab协议来实现<font color='Apricot'>**数据一致性**</font>，基于该协议，zk实现了一种主备模型（即Leader和Follower模型）的系统架构来保证集群中各个副本之间数据的一致性。 这里的主备系统架构模型，就是指只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader客户端将数据同步到其他Follower节点。

### 核心

在 Zookeeper 中只有一个 Leader，并且只有 Leader 可以处理外部客户端的事务请求，并将其转换成一个事务 Proposal（写操作），然后 Leader 服务器再将事务 Proposal 操作的数据同步到所有 Follower（数据广播/数据复制）。Zookeeper 采用 Zab 协议的核心就是只要有一台服务器提交了 Proposal，就要确保所有服务器最终都能正确提交 Proposal，这也是 CAP/BASE 最终实现一致性的体现。

### Zab 模式

Zab 协议有两种模式：一种是消息广播模式，另一种是崩溃恢复模式。

#### 消息广播模式

在 Zookeeper 集群中数据副本的传递策略就是采用消息广播模式，Zookeeper 中的数据副本同步方式与2PC方式相似但却不同，2PC是要求协调者必须等待所有参与者全部反馈ACK确认消息后，再发送 commit 消息，要求所有参与者要么全成功要么全失败，2PC方式会产生严重的阻塞问题。而 Zookeeper 中 Leader 等待 Follower 的 ACK 反馈是指：只要半数以上的 Follower 成功反馈即可，不需要收到全部的 Follower 反馈。

**Zookeeper 中广播消息步骤**：

- 客户端发起一个写操作请求
- Leader 服务器处理客户端请求后将请求转换为 Proposal，同时为每个 Proposal 分配一个全局唯一 ID，即 ZXID
- Leader 服务器与每个 Follower 之间都有一个队列，Leader 将消息发送到该队列
- Follower 机器从队列中取出消息处理完（写入本地事务日志中）后，向 Leader 服务器发送 ACK 确认
- Leader 服务器收到半数以上的 Follower 的 ACK 后，即认为可以发送 Commit
- Leader 向所有的 Follower 服务器发送 Commit 消息

#### 崩溃恢复模式

<font color='Apricot'>**一旦 Leader 服务器出现崩溃或者由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。**</font>

Zookeeper 集群中为保证任何进程能够顺序执行，只能是 Leader 服务器接收写请求，其他服务器接收到客户端的写请求，也会转发至 Leader 服务器进行处理。

**Zab 协议崩溃恢复需满足以下2个请求：**

- 确保已经被 Leader 提交的 proposal 必须最终被所有的 Follower 服务器提交
- 确保丢弃已经被 Leader 提出的但没有被提交的 Proposal

也就是新选举出来的 Leader 不能包含未提交的 Proposal，必须都是已经提交了的 Proposal 的 Follower 服务器节点，新选举出来的 Leader 节点中含有最高的 ZXID，所以，在 Leader 选举时，将 ZXID（Zab协议的事务编号） 作为每个 Follower 投票时的信息依据。这样做的好处是避免了 Leader 服务器检查 Proposal 的提交和丢弃工作。

### Leader 选举算法

**FastLeaderElection**

# Dubbo

## Dubbo怎么实现的服务调用

1. **服务提供者注册：** 服务提供者在启动时，会将自己提供的服务注册到注册中心（例如 ZooKeeper）上，包括服务接口名称、地址等信息。
2. **服务消费者订阅：** 服务消费者在启动时，会从注册中心订阅自己所需的服务列表。
3. **服务调用：** 当服务消费者需要调用某个服务时，首先会根据服务接口名称在本地查找对应的代理对象。如果本地没有缓存该代理对象，那么它会通过网络请求去注册中心获取服务提供者的地址列表。
4. **负载均衡：** 服务消费者根据负载均衡算法（如随机、轮询等）选择一个服务提供者的地址。
5. **远程调用：** 服务消费者通过网络向选中的服务提供者发起远程调用请求，包括服务接口名称、方法名称以及参数等信息。
6. **序列化与反序列化：** 请求参数经过序列化后传输到服务提供者端，服务提供者收到请求后进行反序列化，并根据接口名称和方法名调用对应的服务方法。
7. **执行服务方法：** 服务提供者执行服务方法，并将结果进行序列化后返回给服务消费者。
8. **返回结果：** 服务消费者收到服务提供者的响应结果后进行反序列化，最终返回给调用方。
9. **结果处理：** 调用方根据返回结果进行相应的处理，完成整个服务调用流程。