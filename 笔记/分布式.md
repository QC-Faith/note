# 分布式理论

## CAP定理

在一个分布式系统中，以下三点特性无法同时满足，一个Web应用<font color='RedOrange'>至多只能同时支持下面的两个属性</font>

> 一致性（C）： 在分布式系统中的所有数据备份，在同一时刻是否拥有同样的值。（等同于所有节点访问同一份最新的数据副本）
>
> 可用性（A）： 服务一直可用，一个结点宕机，其余应该正常提供服务（对数据更新具备高可用性）
>
> 分区容错性（P）： 在结点宕机或者网络错误，仍然能对外提供服务。

注册中心一般分为两种： 

> <font color='RedOrange'>CP 注册中心</font>：牺牲可用性来保证数据强一致性，最典型就是 ZooKeeper、etcd、Consul。ZooKeeper 只有一个 Leader 网络出现问题，发生脑裂出现多个 Leader 后，注册中心不可用，etcd 和 Consul 使用 raft 保证强一致性，出现脑裂后，注册中心也不可用。 
>
> <font color='RedOrange'>AP 注册中心</font>：牺牲一致性来保证可用性，Nacos可以配置为 AP，最典型的是 Eureka，其无需选举一个 Leader，每个 Eureka 服务器单独保存服务中服务注册地址，可能出现数据不一致，但网络出现问题，每个 Eureka 服务其独立完成服务。 
>
> 对于注册中心，最主要的功能是服务的注册和发现，在网络出现问题的时候，可用性的需求要远远高于数据一致性。即使因为数据不一致，注册中心内引入了不可用的服务节点，也可以通过其他措施来避免，比如客户端的快速失败机制等，只要实现最终一致性，对于注册中心来说就足够了。因此，选择AP型注册中心，一般更加合适

## BASE理论

B：基本可用（响应时间适当增长、功能部分可用），可以通过延迟响应，流量削峰等手段来保障系统的核心功能的正常，从而实现基本可用。

S：软状态（数据同步允许存在一定的延时） ，就是可以变动的状态，强调的是数据状态处于一种短暂的临界状态。

E：最终一致性（系统中的所有副本，在一定的时间内，最终保持一致性）

# 分布式事务

分布式事务的常见解决方案主要分为 <font color='Peach'>强一致性的解决方案</font> 和 <font color='Peach'>最终一致性的解决方案</font>

### 强一致性的解决方案

<font color='Apricot'>**XA 分布式事务协议**</font>：

> XA中大致分为两部分：事务管理器和本地资源管理器。其中本地资源管理器往往由数据库实现，比如mysql、oracle、sqlserver、postgre库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。XA 协议通常包含两阶段提交（2PC）和三阶段提交（3PC）两种实现。XA 并发性能不太好，无法满足高并发场景，在互联网中使用较少。

<font color='Apricot'>**2PC 两阶段提交**</font>：

> 是非常经典的强一致性、中心化的原子提交协议，它通过协调者询问所有参与者是否可以提交，然后再通知所有参与者执行提交或回滚的操作。这种方法的缺点是在第二阶段可能会有阻塞，且协调者单点故障会导致整个系统无法工作。
>
> 1、每个参与者执行本地事务，但不提交，进入ready状态，并通知协调者已经准备就绪，
>
> 2、当事务管理器收到所有参与者的 ready 状态后通知参与者发起 commit 操作，否则发出rollback
>
> 第一阶段失败 可以设置超时时间重试，超时按执行失败处理
>
> 第二阶段失败 只能无限重试

<font color='Apricot'>**3PC 三阶段提交**</font>：

>  相对于2PC来说增加了CanCommit阶段和超时机制。如果段时间内没有收到协调者的commit请求，那么就会自动进行commit，解决了2PC单点故障的问题。
>
> 1、CanCommit阶段：询问事务参与者，你是否有能力完成此次事务；剩余两阶段与 2PC 一致

<font color='Apricot'>**DTS 方案**</font>：

> 阿里有一个分布式事务服务 (Distributed Transaction Service, DTS)， 是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。DTS 从架构上分为 xts-client 和 xts-server 两部分，前者是一个嵌入客户端应用的 JAR 包，主要负责事务数据的写入和处理；后者是一个独立的系统，主要负责异常事务的恢复。

<font color='Apricot'>**本地消息表（Local Message Table）： **</font>

> 在本地数据库中维护一个消息表，用于记录事务的执行状态。当事务需要提交时，先将消息插入消息表，然后再异步处理事务。如果事务失败，可以通过消息表进行回滚。这种方式可以提高性能，但要注意消息表的一致性。

### 最终一致性的解决方案

<font color='Apricot'>**TCC 分段提交【较常用】**</font>：

> 实现分布式事务，最常用的方法是二阶段提交协议和 TCC，这两个算法的适用场景是不同的，二阶段提交协议实现的是数据层面的事务，比如 XA 规范采用的就是二阶段提交协议；TCC 实现的是业务层面的事务，比如当操作不仅仅是数据库操作，还涉及其他业务系统的访问操作时，这时就应该考虑 TCC 了。
>
> <font color='RedOrange'>TCC 是一个分布式事务的处理模型，将事务过程拆分为 Try、Confirm、Cancel 三个步骤，在保证强一致性的同时，最大限度提高系统的可伸缩性与可用性，又被称补偿事务。它的核心思想是针对每个操作都要注册一个与其对应的确认操作和补偿操作（也就是撤销操作）</font>
>
> TCC 实现的是业务层面的事务，TCC 可以理解为是一个业务层面的协议，可以当做为一个编程模型来看待，因此这个的应用还是非常广泛的。，TCC 的 3 个操作是需要在业务代码中编码实现的，为了实现一致性，确认操作和补偿操作必须是等幂的，因为这 2 个操作可能会失败重试。
>
> TCC 不依赖于数据库的事务，而是在业务中实现了分布式事务，这样能减轻数据库的压力，但对业务代码的入侵性也更强，实现的复杂度也更高。

<font color='Apricot'>**MQ（非事务消息）【较常用】**</font>

> 采用非事务消息的这种方式比较常见，一个是由于市面上很多这种成熟的非事务消息的解决方案，一个是由于这些 MQ 的性能和吞吐量都比较好，可以满足大部分的业务场景。
>
> 一个典型流程基本上就是，生产者先执行本地事务并将消息落库，状态标记为待发送，然后发送消息。如果发送成功，则将消息改为发送成功；如果发送失败则不修改标记。然后会起一个定时任务，定时从数据库捞取在一定时间内待发送的消息并将消息发送。为确保消息一定能消费，消费者一般采用手动 ACK 机制，并且最好支持幂等。
>
> 在消费者端，我们可能面临的问题和解决方案是：
>
> 1. 消费者消费到消息后，消费者要保证对应的业务操作要执行成功之后再才能主动 ACK。如果业务执行失败，消息不能失效或者丢失。目前主流的 MQ 产品都具有持久化消息的功能，如果消费者宕机或者消费失败，都可以执行重试机制的，因此这个比较好解决。
> 2. 消费者消费消息要能够在业务层面保持幂等，因为消费可能会失败，因此只有具有幂等性，才能不影响业务。具体的方案，在业务层可以采用唯一主键来解决，也可以采用其他的日志或库表（去重表）来保证。
>
> 在生产者端，面临的问题是执行本地事务和发送消息是两个异步的操作，他们并不能保证强一致性，因此有一定的概率会出现一些 bug。

<font color='Apricot'>**MQ（事务消息）【没有开源方案】**</font>

> 在分布式事务实践中事务性消息也是比较常使用的，<font color='RedOrange'>所谓的消息事务就是基于消息队列的两阶段提交，本质上是对消息队列的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，本地事务和发送消息这两个步骤是保持了强一致性的，保证要么本地操作成功并且对外发消息成功，要么两者都失败，这种消息就是事务性消息。和不支持事务的消息中间相比，只是消息发送的时候，保证了和本地事务的一致。消费者实现还是不变。</font>
>
> 通过事务消息来实现的话，整体的可靠性会比较高，阿里的 RocketMQ 就是属于事务消息。RocketMQ 的事务消息的设计思路是：RocketMQ 第一阶段发送 Prepared 消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。然后需要定期扫描消息集群中的事物消息，这时候发现了 Prepared 消息，它会向消息发送者确认，RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。<font color='RedOrange'>RocketMQ 中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且 RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。</font>
>
> 目前一些主流的开源消息队列比如 ActiveMQ、RabbitMQ、Kafka 等都没有实现对事务消息的支持，但是可以有类似的实现方式。比如，Kafka 中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。

<font color='Apricot'>**SAGA 长流程分布式事务【较常用】**</font>

> SAGA 用于处理有序的一长串的长流程的事务，相对来说，性能更好，无资源锁定，无流程阻塞，但是不保证事务间的隔离性与原子性，需要业务侧根据需要处理可能的问题。
>
> SAGA 的每个子事务都有一个补偿接口，如果执行到某个阶段失败后，则对已经成功的子事务按栈顺序依次进行补偿操作（补偿不允许失败，失败必须重试直到成功），SAGA 的一阶段为 Do，二阶段是 Undo，每个 Do 都是一个完整的事务，但整个流程并不能保证隔离性与原子性。

<font color='Apricot'>**业务补偿方式：重试(or 回滚)+告警+人工修复【较常用】**</font>

> 另外一个实现弱一致性的比较简单粗暴的方式，就是采用业务补偿方式，通过重试 + 回滚 (自动或手动)的方式，当出现不一致的时候，进行重试，重试还是失败后就进行回滚，或者告警后人工修复。
>
> 补偿事务的缺点在于不同的业务要写不同的补偿事务，不具备通用性；并且如果业务流程很复杂，if/else会嵌套非常多层；同时也没有考虑补偿事务失败的后续流程。总之是一个比较糙的解决方案。在对一致性要求不高的情况下，如果又想要比较简单的实现，可以采用这种业务补偿方式。业务补偿设计的主要核心点在于：
>
> - 将服务做成幂等性的，如果一个事务失败了或是超时了，我们需要不断地重试，努力地达到最终我们想要的状态。
>
> - 如果执行不下去，需要启动补偿机制，回滚业务流程。



# 分布式锁

1. 基于缓存实现：利用分布式缓存系统（如Redis）的原子性操作，通过SETNX（SET if Not eXists）或者类似的原子操作来实现锁。Redis 还提供了更高级的 SETEX 命令，可以设置锁的过期时间，避免死锁问题。

2. 基于Zookeeper实现：使用 ZooKeeper 提供的临时节点（ephemeral node）特性，通过创建一个临时节点来表示锁的持有。客户端创建临时节点成功的那个将获得锁，其他客户端则监听该节点的删除事件。Zookeeper作为一种高可用的分布式协调服务，相比于Redis分布式锁，Zookeeper分布式锁具有以下优缺点：		

   > 优点：			
   >
   > 1. 可以避免锁的失效问题：Zookeeper采用基于ZAB协议的分布式一致性算法，可以保证分布式锁的强一致性，避免因主从同步延迟导致锁失效问题。
   > 2. 支持更复杂的锁机制：Zookeeper提供了两种锁实现方式：共享锁和排他锁，可以根据具体的业务场景选择最适合的方式。
   > 3. 可以与其他Zookeeper服务集成：Zookeeper还提供了诸如分布式队列、命名服务等功能，可以与分布式锁一起使用，构建更完整的分布式应用系统。
   >
   > 缺点：
   >
   > 1. 性能相对较低：Zookeeper采用基于ZAB协议的分布式一致性算法，需要进行多次网络通信和数据同步，相比于Redis分布式锁，性能相对较低。
   > 2. 部署和维护成本较高：Zookeeper需要部署专门的服务器集群，需要进行一定的配置和维护工作，相比于Redis分布式锁，部署和维护成本较高。

3. 基于数据库实现，有两种方式：		

   - 使用数据库的事务性和唯一性约束来实现分布式锁。通过在数据库中插入一条记录或者更新一条记录，利用数据库的唯一性约束来确保只有一个客户端能够成功插入或更新。
   - 利用数据库的乐观锁机制，通过在记录中添加版本号等字段，实现分布式锁。客户端在获取锁时，检查版本号，成功则获取锁，失败则重试或者放弃。

   > 相比于Redis和Zookeeper分布式锁，MySQL分布式锁具有以下优缺点：
   >
   > 优点：
   >
   > 1. 易于部署和维护：MySQL已经广泛应用于各种应用场景中，部署和维护相对较为简单。
   > 2. 支持更复杂的锁机制：MySQL提供了多种锁实现方式，如行锁、表锁、读锁、写锁等，可以根据具体的业务场景选择最适合的方式。
   >
   > 缺点：
   >
   > 1. 性能较低：MySQL采用基于磁盘的存储方式，相比于Redis和Zookeeper，性能较低。
   > 2. 可扩展性较差：由于MySQL采用基于磁盘的存储方式，其可扩展性较差，难以应对高并发场景下的锁控制需求。
   > 3. 存在单点故障问题：MySQL采用主从复制的方式进行数据同步，存在单点故障问题，可能导致锁失效问题。

# 脑裂

在Elasticsearch、ZooKeeper这些集群环境中，有一个共同的特点，就是它们有一个“大脑”。比如，Elasticsearch集群中有Master节点，ZooKeeper集群中有Leader节点。

集群中的Master或Leader节点往往是通过选举产生的。在网络正常的情况下，可以顺利的选举出Leader（后续以Zookeeper命名为例）。但当两个机房之间的网络通信出现故障时，选举机制就有可能在不同的网络分区中选出两个Leader。当网络恢复时，这两个Leader该如何处理数据同步？又该听谁的？这也就出现了“脑裂”现象。

<font color='Apricot'>**产生原因**</font>：

以zookeeper集群的场景为例来分析

在使用zookeeper时，很少遇到脑裂现象，是因为zookeeper已经采取了相应的措施来减少或避免脑裂的发生。先假设zookeeper没有采取这些防止脑裂的措施。在这种情况下，脑裂问题是如何发生的：

> 假如有6台zkServer服务组成了一个集群，部署在2个机房：正常情况下，该集群只有一个Leader，当Leader宕掉时，其他5个服务会重新选举出一个新的Leader。
>
> 如果机房1和机房2之间的网络出现故障，暂时不考虑Zookeeper的过半机制，也就是说机房2的三台服务检测到没有Leader了，于是开始重新选举，选举出一个新Leader来。原本一个集群，被分成了两个集群，同时出现了两个“大脑”，这就是所谓的“脑裂”现象。
>
> 由于原本的一个集群变成了两个，都对外提供服务。一段时间之后，两个集群之间的数据可能会变得不一致了。当网络恢复时，就面临着谁当Leader，数据怎么合并，数据冲突怎么解决等问题。

上面的过程只是假设Zookeeper不做任何预防脑裂措施时会出现的问题。防止脑裂的措施有多种，Zookeeper默认采用的是“过半原则”。所谓的过半原则就是：在Leader选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。通过过半机制，达到了要么没有Leader，要没只有1个Leader，避免了脑裂问题。

对于过半机制除了能够防止脑裂，还可以实现快速的选举。因为过半机制不需要等待所有zkServer都投了同一个zkServer就可以选举出一个Leader，所以也叫快速领导者选举算法。

<font color='Apricot'>**Leader假死**</font>：

假设某个Leader假死，其余的followers选举出了一个新的Leader。这时，旧的Leader复活并且仍然认为自己是Leader，向其他followers发出写请求也是会被拒绝的。

因为ZooKeeper维护了一个叫epoch的变量，每当新Leader产生时，会生成一个epoch标号（标识当前属于那个Leader的统治时期），epoch是递增的，followers如果确认了新的Leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求。

也有可能 follower 不知道新的 Leader 存在，但这肯定不是大多数，否则新Leader无法产生。ZooKeeper的写也遵循 quorum(法定人数) 机制，因此，得不到大多数支持的写是无效的，旧 leader 即使各种认为自己是 Leader，依然没有什么作用。

<font color='Apricot'>**解决方案**</font>：

<font color='Magenta'>Quorums（法定人数）方式</font>

> 比如 3 个节点的集群，Quorums = 2，也就是说集群可以容忍1个节点失效，这时候还能选举出1个lead，集群还可用。比如4个节点的集群，它的Quorums = 3，Quorums要超过3，相当于集群的容忍度还是1，如果2个节点失效，那么整个集群还是无效的。这是ZooKeeper防止“脑裂”默认采用的方法。

<font color='Magenta'>添加心跳线</font>

> 集群中采用多种通信方式，防止一种通信方式失效导致集群中的节点无法通信。
>
> 比如，添加心跳线。原来只有一条心跳线路，此时若断开，则接收不到心跳报告，判断对方已经死亡。若有2条心跳线路，一条断开，另一条仍然能够接收心跳报告，能保证集群服务正常运行。心跳线路之间也可以 HA（高可用），这两条心跳线路之间也可以互相检测，若一条断开，则另一条马上起作用。正常情况下，则不起作用，节约资源。

<font color='Magenta'>启动磁盘锁定方式</font>

> 使用磁盘锁的形式，保证集群中只能有一个Leader获取磁盘锁，对外提供服务，避免数据错乱发生。但是，也会存在一个问题，若该Leader节点宕机，则不能主动释放锁，那么其他的Follower就永远获取不了共享资源。于是有人在HA中设计了"智能"锁。正在服务的一方只有在发现心跳线全部断开（察觉不到对端）时才启用磁盘锁。平时就不上锁了

<font color='Magenta'>仲裁机制方式</font>

> 脑裂导致的后果是从节点不知道该连接哪一台Leader，此时有一个仲裁方就可以解决此问题。比如提供一个参考的IP地址，心跳机制断开时，节点各自ping一下参考IP，如果ping不通，那么表示该节点网络已经出现问题，则该节点需要自行退出争抢资源，释放占有的共享资源，将服务的提供功能让给功能更全面的节点。

以上方式可以同时使用，可以减少集群中脑裂情况的发生，但不能完全保证，比如仲裁机制中2台机器同时宕机，那么此时集群中没有Leader 可以使用。此时就需要人工干预了。