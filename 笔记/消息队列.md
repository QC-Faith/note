| 特性/消息队列  | ActiveMQ              | RabbitMQ          | Kafka                                    | RocketMQ       |
| :------------: | --------------------- | ----------------- | ---------------------------------------- | -------------- |
|  **消息协议**  | OpenWire, MQTT, STOMP | AMQP, MQTT, STOMP | 自定义二进制协议，社区封装了HTTP协议支持 | 自定义协议     |
| **消息持久化** | 是                    | 是                | 是                                       | 是             |
| **分区/分片**  | 不支持                | 不支持            | 支持                                     | 支持           |
|  **顺序保证**  | 需要额外配置          | 需要额外配置      | 默认支持                                 | 默认支持       |
| **事务性消息** | 支持                  | 支持              | 支持                                     | 支持           |
|   **吞吐量**   | 万级（再次之）        | 万级（最差）      | 十万级（次之）                           | 十万级（最高） |
|  **消息延迟**  | 毫秒级                | 微秒级（最快）    | 毫秒级                                   | 毫秒级         |

# RabbitMQ

## 特点

**可靠性**: RabbitMQ使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。

**灵活的路由** : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。

**扩展性**: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展集群中节点。

**高可用性** : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。

**多种协议** : RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息中间件协议。

**多语言客户端** : RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。

**管理界面** : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。

**插件机制** : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，也可以编写自己的插件。

## 组成

- 交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。
- 队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。
- 绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。
- Broker可以看做RabbitMQ的服务节点。一般情况下一个Broker可以看做一个RabbitMQ服务器。

## 交换机类型

主要有以下4种。

- fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。fanout 类型转发消息是最快的。
- direct：把消息路由到`BindingKey`和`RoutingKey`完全匹配的队列中（Routing Key==Binding Key）。它是完全匹配、单播的模式。
- topic：使用`BindingKey`和`RoutingKey`进行模糊匹配，匹配成功则将消息发送到相应的队列。`BindingKey`和`RoutingKey`都是句点号“. ”分隔的字符串，`BindingKey`中可以存在两种特殊字符 * 与“##”，用于做模糊匹配，其中“*”用于匹配一个单词，“##”用于匹配多个单词。
- headers：`Exchange`不依赖于`BindingKey`和`RoutingKey`的匹配规则来路由消息，而是根据发送的消息内容中的header属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。性能差，基本用不到。

## 死信队列

当一个消息在一个队列中变成死信之后，它能重新被发送到另一个交换机中，这个交换机就是DLX（死信交换机）。绑定 DLX 的队列就称之为死信队列。

<font color='Chestnut Red'>导致死信的原因：</font>

> - 消息被拒绝并且消息没有重新入队（requeue=false）
> - 消息超时未消费
> - 达到最大队列长度

## 延时队列

1. 使用插件，不会立刻将消息投递到队列，而是放到一个类似于数据库的结构中，等时间到了才会放入队列。

2. 当一个消息变成死信之后，他就能被重新发送到死信队列中（其实是交换机-exchange）。那么基于这样的机制，就可以实现延迟消息了。

   > 实现方式：
   >
   > 一个消息设定TTL，然但是并不消费这个消息，等他过期，过期后就会进入到死信队列，然后再监听死信队列的消息消费就行了。而且，RabbitMQ中的这个TTL是可以设置任意时长的。
   >
   > 优点： 基于RabbitMQ的死信队列，可以实现延迟消息，非常灵活的实现定时关单，并且借助RabbitMQ的集群扩展性，可以实现高可用，以及处理大并发量。
   >
   > 缺点：
   >
   > 1. 可能存在消息阻塞，因为队列是先进先出的，而且每次只会判断队头的消息是否过期，那么，如果队头的消息时间很长，一直都不过期，那么就会阻塞整个队列，这时候即使排在他后面的消息过期了，那么也会被一直阻塞。
   > 2. 方案比较复杂，不仅要依赖RabbitMQ，而且还需要声明很多队列(exchange)出来，增加系统的复杂度

## 可靠性保证

消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。

`生产者到RabbitMQ`：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。

`RabbitMQ自身`：持久化、集群、普通模式、镜像模式。

`RabbitMQ到消费者`：`basicAck`机制、死信队列、消息补偿机制。

## 幂等性消费

相同条件下对一个业务的操作，不管操作多少次，结果都是一样。

1. 设置一个版本号，每次操作都需要带上此版本号，每次操作版本号+1，当传入版本号<当前版本号则不执行。使用状态机来实现幂等，所谓的状态机是指一条数据的完整运行状态的转换流程，比如 ，因为它的状态只会向前变更，所以多次修改同一条数据的时候，一旦状态发生变更，那么对这条数据修改造成的影响只会发生一次。
2. 基于Token机制，消费过后Token置为无效或者删除
3. 可以利用数据库主键的唯一约束。
4. 使用 Redis 提供的 `setNX `指令，比如`mq`接受消息时，将消息`setNx`放入Redis中，一旦这个消息被消费过，就不会再次消费

# Kafka

## 如何做到高吞吐量

> - 顺序读写
>   `Kafka`的消息是不断追加到文件中的，这个特性使`Kafka`可以充分利用磁盘的顺序读写性能；顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写
>
> - 零拷贝
> 	跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”。`Kafka`的数据传输通过`TransportLayer`来完成，其子类`PlaintextTransportLayer`通过 Java NIO 的`FileChannel`的`transferTo`和`transferFrom`方法实现零拷贝。`transferTo`和`transferFrom`并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供`sendfile`这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。
> - 分区
> 	`Kafka`中的`topic`中的内容可以被分为多分`partition`存在,每个`partition`又分为多个段`segment`,所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力
> - 批量发送
> 	`Kafka`允许进行批量发送消息，`Producer`发送消息的时候，可以将消息缓存在本地,等到了固定条件发送到`Kafka`（等消息条数到固定条数或者一段时间发送一次）
> - 数据压缩
> 	Kafka还支持对消息集合进行压缩，`Producer`可以通过`GZIP`或`Snappy`格式对消息集合进行压缩，压缩的好处就是减少传输的数据量，减轻对网络传输的压力

## 可靠性保证

Kafka消息丢失场景（生产者丢失消息、消费者丢失消息、Kafka系统内丢失消息）

生产者：生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。

> 解决方法：使用带回调通知函数的方法进行发送消息，即 `Producer.send(msg, callback)`, 这样一旦发现发送失败， 就可以做针对性处理。
> 对于一致性要求不高的业务场景，也可以考虑Producer端设置retries（重试次数）设置一个比较合理的值，一般是3。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。

消费者丢失消息的情况：自动提交开启会存在这样的问题：当消费者poll到这个消息，还没进行真正消费的时候，offset被自动提交的同时消费者挂掉了。

> 解决办法：关闭自动提交offset（即：`enable.auto.commit为false`），每次在真正消费完消息之后，手动提交offset。这样会存在消费者刚消费完消息还没提交offset就宕机了，这个消息理论上就会被消费两次，因此需要消费端保证幂等性

Kafka系统内丢失消：假如leader副本所在的broker突然挂掉，那么就要从follower副本重新选出一个leader，但是leader的数据还有一些没有被follower副本的同步的话，就会造成消息丢失。

> 解决方法：
>
> 1. `Producer`端设置`acks=all`。acks的默认值为1，代表消息被leader副本接收之后就算被成功发送。当配置acks=all代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。（副本只是将消息存储在PageCache上的，定期flush到磁盘上的，如果出现断电或者机器故障等，`PageCache`上的数据就丢失了。但设置设置了acks=all，出现多个副本同时挂掉的概率比Leader挂掉的概率就小很多)
> 2. `topic`设置`replication.factor >= 3`。该参数表示分区副本的个数。建议设置`replication.factor >= 3`, 这样如果 Leader 副本异常 Crash 掉，Follower 副本会被选举为新的 Leader 副本继续提供服务。
> 3. 设置`min.insync.replicas > 1`。该参数表示消息至少要被写入成功到 ISR 多少个副本才算**"已提交"，**建议设置`min.insync.replicas > 1`，这样才可以提升消息持久性，保证数据不丢失。另外我们还需要确保一下`replication.factor > min.insync.replicas`, 如果相等，只要有一个副本异常 Crash 掉，整个分区就无法正常工作了，因此推荐设置成：`replication.factor =min.insync.replicas +1`, 最大限度保证系统可用性。
> 4. 设置`unclean.leader.election.enable=false`。该参数表示**有哪些 Follower 可以有资格被选举为 Leader** , 如果一个 Follower 的数据落后 Leader 太多，那么一旦它被选举为新的 Leader， 数据就会丢失，因此我们要将其设置为false，防止此类情况发生。
> 5. Producer端设置retries。配合acks=all，这样可以保证leader挂掉之后，Producer会重新发送消息。

## 幂等性保证

接口或者资源在重复调用的情况下，对系统产生的影响是一样的。在消息队列中的幂等性主要包括生产者幂等性和消费者幂等性两个方面。生产者幂等性，无论多少次消费消息队列中的消息，消费的结果都是一致的。简单来说就是：消费者幂等性保证消息不会被重复消费。生产者幂等性，即在网络情况波动等情况下是，生产者不会将冗余的消息推送给MQ，即消息不会被重复推送。

**为什么会重复消费?**

> 在Kafka中有offset的概念，每个消息在写入broker的时候都会有一个offset来代表消息序号，并且log文件的名字也是消息序号offset.log。consumer在消费数据之后，每隔一段时间（定期）会将消费过的offset提交到Kafka，表示该消息已经被消费过了，consumer重启之后可以继续从原来的offset进行消费。但是，如果consumer出现意外宕机或者直接被手动kill掉进程了，就会导致有些已经被消费过的消息，其offset还没来得及被提交，这就会导致有些消息在重启之后会被再消费一次。

### Consumer

**手动确认**

为消息生成一个全局的唯一标志id，当消费者消费消息的时候先手动从本地的唯一id来判断消息是否已经被消费过了来避免重复消费的问题

**消息去重**

如果你的消费者就是将消息写入到MySQL数据库中，那么可以先根据“数据库主键”或者“布隆过滤器”来进行查询，以保证消息最终的幂等性。

- Redis：在 Redis 中，每次都是使用 SET 命令，这本身天然支持幂等性，因为 SET 命令无论是设置新值还是更新已存在的键，都不会导致数据的重复。
- 自定义标识符：可以要求生产者在每条消息中添加一个全局唯一的标识符，例如订单 ID。在消费者端，你可以根据这个标识符去查询一个持久化存储（如 Redis），检查消息是否已经被处理过。如果消息尚未被处理，执行消息处理逻辑，并将该标识符写入存储中。如果消息已经处理过，可以选择跳过处理，以确保不会重复处理相同的消息。
- 数据库唯一键：如果你使用数据库来存储数据，可以利用数据库的唯一键约束。通过设置唯一键，可以确保在尝试插入重复数据时会触发唯一键约束，而不会导致数据库中出现重复或脏数据。

### Producer

Producer 幂等性的前提条件：

1. 幂等性仅能在 Producer 的单个会话内得到保障，如果 Producer 遇到意外故障并重新启动，跨会话的幂等性无法保证。因为在幂等性条件下，无法获取之前的状态信息，所以不能实现会话间的不丢失和不重复。
2. 幂等性不能跨越多个 Topic-Partition，仅能确保单个分区内的幂等性。当涉及多个 Topic-Partition 时，它们之间的状态不会同步。

如果需要实现跨会话和跨多个 Topic-Partition 的幂等性，你需要考虑使用 Kafka 的事务机制。

> Producer 的幂等性是为了解决什么问题而存在的？
>
> Producer 的幂等性指的是当发送相同的消息时，数据在服务器端仅会被持久化一次，确保数据不会丢失也不会重复存储。
>
> 在正常情况下，Producer向Broker推送消息，Broker将消息写入到某一Topic的Partition中，并向Producer返回ACK信号表示消息收到；然而，由于网络或其它原因，Producer和Broker之间通讯可能会出现异常，从而导致ACK在途中丢失，这样就会造成Producer再次推送消息导致消息重复。

**解决方案**
通过 Producer 配置 `enable-idempotence: true` 就可以实现消息的幂等性，它会确保相同的消息在发送时只会被写入一次，即使生产者发生重试或失败。当启用幂等性时，Producer 会自动为每个消息分配一个序列号，并在 Broker 上维护一个日志，记录每个 Producer 发送的消息序列号，以确保不会写入重复消息。

> 原理： Producer其幂等性实现原理主要是Kafka加入了2个标记值：
>
> - PID：在Producer初始化分配的时候，作为每个Producer会话的唯一标识；
> - 序列号（Sequence Number）：Producer发送的每条消息都会带有序列号，从0开始递增，Broker通过序列号来判断消息是否可以接受；
>
> Broker会为每个Topic Partition组合维护PID和序列号。对每条接收到的消息，都会检查它的序列号是否比Broker所维护的值严格+1，只有这样才是合法的，其他情况都会丢弃。
>
> 上面所说的幂等性保证了最细粒度的消息不重不漏，具体来说，它确保了以下几个方面的情况：
>
> - 单个Producer会话：在单个Producer会话内，消息不会重复发送，即使Producer重启，也能保证消息不重复。这是通过PID（Producer ID）来实现的，PID唯一标识了Producer的会话。
> - 单个Topic Partition级别：对于单个Topic Partition（主题分区），消息也不会重复，确保了在特定分区内的幂等性。
>
> 然而，幂等性的保证在以下情况下会失效：
>
> - Producer重启（PID发生变化）：如果Producer重启，PID会发生变化，这可能导致某些消息在新PID下被认为是不同的消息，从而无法保证幂等性。
> - 跨Topic和跨Partition：如果消息涉及跨多个Topic或不同的分区，幂等性保证可能失效，因为Producer会话在不同的Topic和Partition之间不共享。
>
> 需要注意的是，实现事务性要比实现幂等性复杂得多，需要协调组件（Transaction Coordinator）来确保跨多个Producer会话、多个Topic和多个Partition的事务性操作。虽然实现事务性更复杂，但它可以提供更高级别的一致性和可靠性，适用于需要严格事务性保证的应用场景。