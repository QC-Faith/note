|     特性/消息队列      | ActiveMQ                                                     | RabbitMQ                                                 | Kafka                                                    | RocketMQ                                             |
| :--------------------: | ------------------------------------------------------------ | -------------------------------------------------------- | -------------------------------------------------------- | ---------------------------------------------------- |
|      **消息协议**      | OpenWire, MQTT, STOMP                                        | AMQP, MQTT, STOMP                                        | 自定义二进制协议，社区封装了HTTP协议支持                 | 自定义协议                                           |
|     **消息持久化**     | 是                                                           | 是                                                       | 是                                                       | 是                                                   |
|     **分区/分片**      | 不支持                                                       | 不支持                                                   | 支持                                                     | 支持                                                 |
|      **顺序保证**      | 需要额外配置                                                 | 需要额外配置                                             | 默认支持                                                 | 默认支持                                             |
|     **事务性消息**     | 支持                                                         | 支持                                                     | 支持                                                     | 支持                                                 |
|       **吞吐量**       | 万级（再次之）                                               | 万级（最差）                                             | 十万级（次之）                                           | 十万级（<font color='Chestnut Red'>**最高**</font>） |
| **消息延迟（时效性）** | 毫秒级                                                       | 微秒级（<font color='Chestnut Red'>**最快**</font>）     | 毫秒级                                                   | 毫秒级                                               |
|       **可用性**       | 主从架构，可用性较高                                         | 同 ActiveMQ                                              | 天然的分布式系统，数据有副本机制，可用性非常高           | 分布式架构，可用性非常高                             |
|       **维护性**       | 基于 Java 语言实现，消息队列场景功能很完备，但社区活跃度较低，维护成本较高 | 基于 erlang 语言开发，社区活跃度一般，小团队维护成本较高 | 基于 Java 和 Scala 语言 实现，社区活跃度高，维护成本较低 | 基于 Java 语言实现，社区活跃度高，维护成本较低       |

解耦、削峰、驱动等场景下的业务时以及日志采集系统、监控系统、流式处理等各类场景中都离不开MQ队列。高吞吐、低延时、可用性和可维护性，是消息队列中间件的核心要求。

1. **RabbitMQ:**
   - RabbitMQ 提供了事务机制，通过 `channel.txSelect()`、`channel.txCommit()` 和 `channel.txRollback()` 方法来实现。
   - 在事务模式下，消息的确认和事务提交是绑定在一起的。即要么消息被确认，要么整个事务回滚。
2. **RocketMQ:**
   - RocketMQ 支持本地事务，即在发送消息前，会执行本地事务，然后根据本地事务执行结果来决定是提交还是回滚消息。
   - 用户需要实现 `TransactionListener` 接口，并在发送消息时指定相应的 `TransactionListener` 实现。
3. **Kafka:**
   - Kafka 本身不提供官方的事务支持。然而，Kafka 0.11.0.0 版本引入了事务性 producer，并通过 `send()` 方法支持事务性消息。
   - 在 Kafka 中，生产者可以通过 `initTransactions()`、`beginTransaction()`、`commitTransaction()` 和 `abortTransaction()` 来实现事务操作。

# RabbitMQ

## 特点

**可靠性**: RabbitMQ使用一些机制如持久化、传输确认及发布确认等来保证可靠性。

**灵活的路由** : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。

**扩展性**: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展集群中节点。

**高可用性** : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。

**多种协议** : RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息中间件协议。

**多语言客户端** : RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。

**管理界面** : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。

**插件机制** : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，也可以编写自己的插件。

## 组成

- 交换器 (Exchange)：消息交换机，指定消息规则，处理消息和队列之间的关系。用于把消息路由到队列的组件。生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。

  ~~~properties
  Exchange Types：direct、topic、fanout、headers
  ~~~

- 队列 (Queue)：消息的载体，位于硬盘或内存中，每个消息都会被投到一个或多个队列。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。

- 绑定 (Binding)：一套规则，把 Exchange 和 Queue 按照路由规则绑定起来。

- Routing Key：路由关键字，Exchange根据这个关键字进行消息投递

- Broker 消息队列服务器实体。一般情况下一个Broker可以看做一个RabbitMQ服务器。

- Connection：连接，应用程序与Broker的网络连接 TCP/IP/三次握手和四次挥手

- Channel：网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的通道，客户端可以建立多个Channel，每个Channel代表一个会话任务，是基于TCP连接之上的虚拟连接。

- Virtual Host：虚拟主机，当多个不同的用户使用同一个RabbitMQ Server提供的服务时，可以划分出多个vhost，每个用户在自己的vhost创建exchange／queue。

- producer：生产者，投递消息的程序

- consumer：消费者，接受消息的程序

## 交换机类型

主要有以下4种。

- fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。fanout 类型转发消息是最快的。
- direct：把消息路由到`BindingKey`和`RoutingKey`完全匹配的队列中（Routing Key==Binding Key）。它是完全匹配、单播的模式。
- topic：使用`BindingKey`和`RoutingKey`进行模糊匹配，匹配成功则将消息发送到相应的队列。`BindingKey`和`RoutingKey`都是句点号“. ”分隔的字符串，`BindingKey`中可以存在两种特殊字符  “\*“ 与“##”，用于做模糊匹配，其中“\*”用于匹配一个单词，“##”用于匹配多个单词。
- headers：`Exchange`不依赖于`BindingKey`和`RoutingKey`的匹配规则来路由消息，而是根据发送的消息内容中的header属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。性能差，基本用不到。

## 死信队列

当一个消息在一个队列中变成死信之后，它能重新被发送到另一个交换机中，这个交换机就是DLX（死信交换机）。绑定 DLX 的队列就称之为死信队列。

<font color='Chestnut Red'>导致死信的原因：</font>

> - 消息被拒绝并且消息没有重新入队（requeue=false）
> - 消息超时未消费
> - 达到最大队列长度

## 延时队列

1. 使用插件，不会立刻将消息投递到队列，而是放到一个类似于数据库的结构中，等时间到了才会放入队列。

2. 当一个消息变成死信之后，他就能被重新发送到死信队列中（绑定 DLX 的队列）。那么基于这样的机制，就可以实现延迟消息了。

   > 实现方式：
   >
   > 一个消息设定TTL，然但是并不消费这个消息，等他过期，过期后就会进入到死信队列，然后再监听死信队列的消息消费就行了。而且，RabbitMQ中的这个TTL是可以设置任意时长的。
   >
   > 优点： 基于RabbitMQ的死信队列，可以实现延迟消息，非常灵活的实现定时关单，并且借助RabbitMQ的集群扩展性，可以实现高可用，以及处理大并发量。
   >
   > 缺点：
   >
   > 1. 可能存在消息阻塞，因为队列是先进先出的，而且每次只会判断队头的消息是否过期，那么，如果队头的消息时间很长，一直都不过期，那么就会阻塞整个队列，这时候即使排在他后面的消息过期了，那么也会被一直阻塞。
   > 2. 方案比较复杂，不仅要依赖RabbitMQ，而且还需要声明很多队列(exchange)出来，增加系统的复杂度

## 可靠性保证

消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。

`生产者到RabbitMQ`：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。

`RabbitMQ自身`：持久化、集群、普通模式、镜像模式。

`RabbitMQ到消费者`：`basicAck`机制、死信队列、消息补偿机制。

## 幂等性消费

相同条件下对一个业务的操作，不管操作多少次，结果都是一样。

1. 设置一个版本号，每次操作都需要带上此版本号，每次操作版本号+1，当传入版本号<当前版本号则不执行。使用状态机来实现幂等，所谓的状态机是指一条数据的完整运行状态的转换流程，比如 ，因为它的状态只会向前变更，所以多次修改同一条数据的时候，一旦状态发生变更，那么对这条数据修改造成的影响只会发生一次。
2. 基于Token机制，消费过后Token置为无效或者删除
3. 可以利用数据库主键的唯一约束。
4. 使用 Redis 提供的 `setNX `指令，比如`mq`接受消息时，将消息`setNx`放入Redis中，一旦这个消息被消费过，就不会再次消费

# Kafka

## 如何做到高吞吐量

> - 顺序读写
>   `Kafka`的消息是不断追加到文件中的，这个特性使`Kafka`可以充分利用磁盘的顺序读写性能；顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写。（因为顺序写入的特性，所以Kafka是无法删除数据的，它会将所有数据都保留下来）
>
> - 零拷贝
> 	跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”。`Kafka`的数据传输通过`TransportLayer`来完成，其子类`PlaintextTransportLayer`通过 Java NIO 的`FileChannel`的`transferTo`和`transferFrom`方法实现零拷贝。`transferTo`和`transferFrom`并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供`sendfile`这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。
> 	
> - 分区
> 	Kafka的message是按topic分类存储的，topic中的数据是按照一个一个的partition即分区存储到不同broker节点，partition又是按照segment分段存储的。分区允许 Kafka 在多个节点上并行处理消息，提高吞吐量。
> 	
> 	为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。
> 	
> - 批量发送
> 	`Kafka`允许进行批量发送消息，`Producer`发送消息的时候，可以将消息缓存在本地,等到了固定条件发送到`Kafka`（等消息条数到固定条数或者一段时间发送一次）
> 	
> - 数据压缩
> 	Kafka还支持对消息集合进行压缩，`Producer`可以通过`GZIP`或`Snappy`格式对消息集合进行压缩，压缩的好处就是减少传输的数据量，减轻对网络传输的压力

## 可靠性保证

Kafka消息丢失场景（生产者丢失消息、消费者丢失消息、Kafka系统内丢失消息）

生产者：生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。

> 解决方法：使用带回调通知函数的方法进行发送消息，即 `Producer.send(msg, callback)`, 这样一旦发现发送失败， 就可以做针对性处理。
> 对于一致性要求不高的业务场景，也可以考虑Producer端设置retries（重试次数）设置一个比较合理的值，一般是3。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。

消费者丢失消息的情况：

> 1. 自动提交开启时当消费者poll到这个消息，还没进行真正消费的时候，offset被自动提交的同时消费者挂掉了。
>
>    解决办法：关闭自动提交offset（即：`enable.auto.commit为false`），每次在真正消费完消息之后，手动提交offset。这样会存在消费者刚消费完消息还没提交offset就宕机了，这个消息理论上就会被消费两次，因此需要消费端保证幂等性
>
> 2. **死信队列解决**

Kafka系统内丢失消：假如leader副本所在的broker突然挂掉，那么就要从follower副本重新选出一个leader，但是leader的数据还有一些没有被follower副本的同步的话，就会造成消息丢失。

> 解决方法：
>
> 1. `Producer`端设置`acks=all`。acks的默认值为1，代表消息被leader副本接收之后就算被成功发送。当配置acks=all代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。（副本只是将消息存储在PageCache上的，定期flush到磁盘上的，如果出现断电或者机器故障等，`PageCache`上的数据就丢失了。但设置设置了acks=all，出现多个副本同时挂掉的概率比Leader挂掉的概率就小很多)
> 2. `topic`设置`replication.factor >= 3`。该参数表示分区副本的个数。建议设置`replication.factor >= 3`, 这样如果 Leader 副本异常 Crash 掉，Follower 副本会被选举为新的 Leader 副本继续提供服务。
> 3. 设置`min.insync.replicas > 1`。该参数表示消息至少要被写入成功到 ISR 多少个副本才算**"已提交"，**建议设置`min.insync.replicas > 1`，这样才可以提升消息持久性，保证数据不丢失。另外我们还需要确保一下`replication.factor > min.insync.replicas`, 如果相等，只要有一个副本异常 Crash 掉，整个分区就无法正常工作了，因此推荐设置成：`replication.factor =min.insync.replicas +1`, 最大限度保证系统可用性。
> 4. 设置`unclean.leader.election.enable=false`。该参数表示**有哪些 Follower 可以有资格被选举为 Leader** , 如果一个 Follower 的数据落后 Leader 太多，那么一旦它被选举为新的 Leader， 数据就会丢失，因此我们要将其设置为false，防止此类情况发生。
> 5. Producer端设置retries。配合acks=all，这样可以保证leader挂掉之后，Producer会重新发送消息。

## 幂等性保证

接口或者资源在重复调用的情况下，对系统产生的影响是一样的。在消息队列中的幂等性主要包括生产者幂等性和消费者幂等性两个方面。生产者幂等性，无论多少次消费消息队列中的消息，消费的结果都是一致的。简单来说就是：消费者幂等性保证消息不会被重复消费。生产者幂等性，即在网络情况波动等情况下是，生产者不会将冗余的消息推送给MQ，即消息不会被重复推送。

**为什么会重复消费?**

> 在Kafka中有offset的概念，每个消息在写入broker的时候都会有一个offset来代表消息序号，并且log文件的名字也是消息序号offset.log。consumer在消费数据之后，每隔一段时间（定期）会将消费过的offset提交到Kafka，表示该消息已经被消费过了，consumer重启之后可以继续从原来的offset进行消费。但是，如果consumer出现意外宕机或者直接被手动kill掉进程了，就会导致有些已经被消费过的消息，其offset还没来得及被提交，这就会导致有些消息在重启之后会被再消费一次。

### Consumer

**手动确认**

为消息生成一个全局的唯一标志id，当消费者消费消息的时候先手动从本地的唯一id来判断消息是否已经被消费过了来避免重复消费的问题

**消息去重**

如果你的消费者就是将消息写入到MySQL数据库中，那么可以先根据“数据库主键”或者“布隆过滤器”来进行查询，以保证消息最终的幂等性。

- Redis：在 Redis 中，每次都是使用 SET 命令，这本身天然支持幂等性，因为 SET 命令无论是设置新值还是更新已存在的键，都不会导致数据的重复。
- 自定义标识符：可以要求生产者在每条消息中添加一个全局唯一的标识符，例如订单 ID。在消费者端，你可以根据这个标识符去查询一个持久化存储（如 Redis），检查消息是否已经被处理过。如果消息尚未被处理，执行消息处理逻辑，并将该标识符写入存储中。如果消息已经处理过，可以选择跳过处理，以确保不会重复处理相同的消息。
- 数据库唯一键：如果你使用数据库来存储数据，可以利用数据库的唯一键约束。通过设置唯一键，可以确保在尝试插入重复数据时会触发唯一键约束，而不会导致数据库中出现重复或脏数据。

### Producer

Producer 幂等性的前提条件：

1. 幂等性仅能在 Producer 的单个会话内得到保障，如果 Producer 遇到意外故障并重新启动，跨会话的幂等性无法保证。因为在幂等性条件下，无法获取之前的状态信息，所以不能实现会话间的不丢失和不重复。
2. 幂等性不能跨越多个 Topic-Partition，仅能确保单个分区内的幂等性。当涉及多个 Topic-Partition 时，它们之间的状态不会同步。

如果需要实现跨会话和跨多个 Topic-Partition 的幂等性，你需要考虑使用 Kafka 的事务机制。

> Producer 的幂等性是为了解决什么问题而存在的？
>
> Producer 的幂等性指的是当发送相同的消息时，数据在服务器端仅会被持久化一次，确保数据不会丢失也不会重复存储。
>
> 在正常情况下，Producer向Broker推送消息，Broker将消息写入到某一Topic的Partition中，并向Producer返回ACK信号表示消息收到；然而，由于网络或其它原因，Producer和Broker之间通讯可能会出现异常，从而导致ACK在途中丢失，这样就会造成Producer再次推送消息导致消息重复。

**解决方案**
通过 Producer 配置 `enable-idempotence: true` 就可以实现消息的幂等性，它会确保相同的消息在发送时只会被写入一次，即使生产者发生重试或失败。当启用幂等性时，Producer 会自动为每个消息分配一个序列号，并在 Broker 上维护一个日志，记录每个 Producer 发送的消息序列号，以确保不会写入重复消息。

> 原理： Producer其幂等性实现原理主要是Kafka加入了2个标记值：
>
> - PID：在Producer初始化分配的时候，作为每个Producer会话的唯一标识；
> - 序列号（Sequence Number）：Producer发送的每条消息都会带有序列号，从0开始递增，Broker通过序列号来判断消息是否可以接受；
>
> Broker会为每个Topic Partition组合维护PID和序列号。对每条接收到的消息，都会检查它的序列号是否比Broker所维护的值严格+1，只有这样才是合法的，其他情况都会丢弃。
>
> 上面所说的幂等性保证了最细粒度的消息不重不漏，具体来说，它确保了以下几个方面的情况：
>
> - 单个Producer会话：在单个Producer会话内，消息不会重复发送，即使Producer重启，也能保证消息不重复。这是通过PID（Producer ID）来实现的，PID唯一标识了Producer的会话。
> - 单个Topic Partition级别：对于单个Topic Partition（主题分区），消息也不会重复，确保了在特定分区内的幂等性。
>
> 然而，幂等性的保证在以下情况下会失效：
>
> - Producer重启（PID发生变化）：如果Producer重启，PID会发生变化，这可能导致某些消息在新PID下被认为是不同的消息，从而无法保证幂等性。
> - 跨Topic和跨Partition：如果消息涉及跨多个Topic或不同的分区，幂等性保证可能失效，因为Producer会话在不同的Topic和Partition之间不共享。
>
> 需要注意的是，实现事务性要比实现幂等性复杂得多，需要协调组件（Transaction Coordinator）来确保跨多个Producer会话、多个Topic和多个Partition的事务性操作。虽然实现事务性更复杂，但它可以提供更高级别的一致性和可靠性，适用于需要严格事务性保证的应用场景。

## 顺序消费

队列中的消息本身都是有顺序，都遵循了FIFO的原则。
单台消费者是不存在消息的顺序的问题，但是单机版本的消费吞吐比较低，所以一般消费者肯定要集群。在多个消费者消费同一个队列中的消息时候，有可能产生消息顺序行为错乱的问题。

**出现顺序乱的原因**

> a、同一个订单队列，被多个消费者消费，就会导致顺序错乱
> b、同一个订单号的不同行为，被分配到不同的队列里，被不同的消费者消费，也会造成错乱。

**解决思想**

> a、相同行为的消息存放到同一个MQ服务器中
> b、最终只会有单个消费者去消费

**保证消息顺序消费**

> a、相同的业务ID设置为同一个可以，存放到同一个分区中，kafka的消费策略是对于同Topic同Partition的消息可保证顺序消费
> b、每个分区中有单独对应的一个消费者实现消费

## Rebalance机制

在Kafka中，当有新消费者加入或者订阅的Topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：

1. 所有消费成员都向协调器（Coordinator）发送请求，请求入Consumer Group。一旦所有成员都发送了请求，Coordinator会从中选择一个Consumer担任Leader的角色，并把组成员信息以及订阅信息发给Leader。
2. Leader开始分配消费方案，指明具体哪个Consumer负责消费哪些Topic的哪些Partition。一旦完成分配，Leader会将这个方案发给Coordinator。Coordinator接收到分配方案之后会把方案发给各个Consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。
   所以对于Rebalance来说，Coordinator起着至关重要的作用

**Rebalance可能发生的时机**

1. 分区个数的增加
2. 对Topic的订阅发生变化
3. 消费组成员的加入或离开（最常遇到）

**Rebalance的影响**

1. 可能重复消费: Consumer被踢出消费组，可能还没有提交offset，Rebalance时会Partition重新分配其它Consumer,会造成重复消费，虽有幂等操作但耗费消费资源，亦增加集群压力
2. 集群不稳定：Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大
3. 影响消费速度：频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance

**避免rebalance措施**

1. 业务需要不可避免

   > - 针对分区个数的增加， 一般不会常有，是需要增加的时候都是业务及数据需求，不可避免
   > - 对Topic的订阅增加或取消亦不可避免

2. 合理设置消费者参数

   > 1. 未能及时发送心跳而Rebalance
   >
   >    `session.timeout.ms` 消费者 与 Broker 的心跳超时时间，默认 `10s`，Broker 如果超过设定的值仍然没有收到心跳，Broker 端将会将该消费者移除，并触发 Rebalance。
   >
   >    `heartbeat.interval.ms` 心跳时间，一般为超时时间的1/3，Consumer在被判定为死亡之前，能够发送至少 3 轮的心跳请求。心跳是在 Consumer 与 Coordinator 之间进行的。心跳用来保持 Consumer 的会话，并且在有 Consumer 加入或者离开 Consumer Group 时帮助进行 Rebalance。
   >
   > 2. Consumer消费超时而Rebalance
   >
   >    `max.poll.interval.ms` 每隔多长时间去拉取消息。合理设置预期值，尽量但间隔时间消费者处理完业务逻辑，否则就会被coordinator判定为死亡，踢出Consumer Group，进行Rebalance
   >
   >    `max.poll.records` 一次从拉取出来的数据条数。根据消费业务处理耗费时长合理设置，如果每次max.poll.interval.ms 设置的时间较短，可以max.poll.records设置小点儿，少拉取些，这样不会超时。
   >
   > 总之，尽可能在max.poll.interval.ms时间间隔内处理完max.poll.records条消息，让Coordinator认为消费Consumer还活着
   >
   > 如果上面两种从 Kafka 层面还无法避免 Rebalance，建议去排查下 Consumer 端的 GC 表现，比如是否出现了频繁的 Full GC 导致的长时间停顿，从而引发了 Rebalance。

