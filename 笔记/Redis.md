# 基本知识

它支持的数据结，如 [字符串（strings）](http://redis.cn/topics/data-types-intro.html#strings)， [散列（hashes）](http://redis.cn/topics/data-types-intro.html#hashes)， [列表（lists）](http://redis.cn/topics/data-types-intro.html#lists)， [集合（sets）](http://redis.cn/topics/data-types-intro.html#sets)， [有序集合（sorted sets）](http://redis.cn/topics/data-types-intro.html#sorted-sets) 与范围查询， [bitmaps](http://redis.cn/topics/data-types-intro.html#bitmaps)， [hyperloglogs](http://redis.cn/topics/data-types-intro.html#hyperloglogs) 和 [地理空间（geospatial）](http://redis.cn/commands/geoadd.html) 索引半径查询。 Redis 内置了 [复制（replication）](http://redis.cn/topics/replication.html)，[LUA脚本（Lua scripting）](http://redis.cn/commands/eval.html)， [LRU驱动事件（LRU eviction）](http://redis.cn/topics/lru-cache.html)，[事务（transactions）](http://redis.cn/topics/transactions.html) 和不同级别的 [磁盘持久化（persistence）](http://redis.cn/topics/persistence.html)， 并通过 [Redis哨兵（Sentinel）](http://redis.cn/topics/sentinel.html)和自动 [分区（Cluster）](http://redis.cn/topics/cluster-tutorial.html)提供高可用性（high availability）。

> Redis的工作线程是单线程的，但是整个Redis是多线程的（`持久化、异步删除`这些都是由额外的线程执行的）

因为 Redis 是基于内存的操作，CPU不是Redis的性能瓶颈。Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。Redis是使用C语言开发的，官方提供的数据为 100000+ 的 QPS，完全不比同样是使用key-value的memecache差

> Redis单线程为何还这么快？

误区 ：

1. 高性能的服务器不一定是多线程的
2. 多线程（CPU上下文会切换）不一定比单线程效率高

速度：CPU > 内存 > 硬盘

核心：Redis是将所有的数据全部放在内存中的，所以使用单线程去操作效率最高，多线程CPU会上下文切换，比较耗时，对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存情况下，这就是最佳的方案。Redis6.0对于持久化、异步删除、集群数据同步等同步阻塞功能支持了多线程处理。

**优势：**

1. 提高性能：缓存查询速度比数据库查询速度快（内存 `VS` 硬盘）
2. 提高并发能力：缓存分担了部分请求，支持更高的并发

# 分布式锁

## 特征

- **「互斥性」**: 任意时刻，只有一个客户端能持有锁。
- **「锁超时释放」**：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。
- **「可重入性」**:一个线程如果获取了锁之后,可以再次对其请求加锁。
- **「高性能和高可用」**：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。
- **「安全性」**：锁只能被持有的客户端删除，不能被其他客户端删除

## 实现方案：

<font color='Chestnut Red'>**单机部署**</font>：

- 方案一：SETNX + EXPIRE
  - SETNX key value，如果 key不存在，则 SETNX 成功返回1，如果 key 已经存在，则返回0。
  - 但是这个方案中，`setnx`和`expire`两个命令分开了，**「不是原子操作」**。如果执行完`setnx`加锁，正要执行`expire`设置过期时间时，进程**崩溃**或者要重启维护了，那么这个锁就“长生不老”了，**「别的线程永远获取不到」**

- 方案二：SETNX + value值是（系统时间+过期时间）

  - 可以把过期时间放到`setnx`的value值里面。如果加锁失败，再拿出value值校验一下即可。加锁代码如下：

    ~~~java
    long expires = System.currentTimeMillis() + expireTime; //系统时间+设置的过期时间
    String expiresStr = String.valueOf(expires);
    
    // 如果当前锁不存在，返回加锁成功
    if (jedis.setnx(key_resource_id, expiresStr) == 1) {
            return true;
    } 
    // 如果锁已经存在，获取锁的过期时间
    String currentValueStr = jedis.get(key_resource_id);
    
    // 如果获取到的过期时间，小于系统当前时间，表示已经过期
    if (currentValueStr != null && Long.parseLong(currentValueStr) < System.currentTimeMillis()) {
    
         // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间（
        String oldValueStr = jedis.getSet(key_resource_id, expiresStr);
        if (oldValueStr != null && oldValueStr.equals(currentValueStr)) {
             // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁
             return true;
        }
    }        
    //其他情况，均返回加锁失败
    return false;
    }
    ~~~

    **缺点**：

    - 过期时间是客户端自己生成的（System.currentTimeMillis()是当前系统的时间），必须要求分布式环境下，每个客户端的时间必须同步。
    - 如果锁过期的时候，并发多个客户端同时请求过来，都执行jedis.getSet()，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖
    - 该锁没有保存持有者的唯一标识，可能被别的客户端释放/解锁。

- 方案三：使用Lua脚本(包含SETNX + EXPIRE两条指令)

- 方案四：SET的扩展命令（SET EX PX NX）

  > SET key value [EX seconds] [PX milliseconds] [NX|XX]，它也是原子性的
  >
  > - NX :表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获得锁，而其他客户端请求只能等其释放锁，才能获取。
  > - EX seconds :设定key的过期时间，时间单位是秒。
  > - PX milliseconds: 设定key的过期时间，单位为毫秒
  > - XX: 仅当key存在时设置值

  **缺点**：

  - **「锁过期释放了，业务还没执行完」**。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的。
  - **「锁被别的线程误删」**。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完。

- 方案五：SET EX PX NX  + 校验唯一随机值，再释放锁

- 方案六：开源框架~Redisson

<font color='Chestnut Red'>**集群部署**</font>：

- 方案七：多机实现的分布式锁Redlock

  - Redlock核心思想是这样的：

    搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。

    > 假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。RedLock的实现步骤如下：
    >
    > 1. 获取当前时间，以毫秒为单位。
    > 2. 按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。
    > 3. 客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s> 30ms+40ms+50ms+4m0s+50ms）
    > 4. 如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。
    > 5. 如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。

# Redis的高并发和快速原因

1. redis是基于内存的，内存的读写速度非常快（纯内存）; 数据存在内存中，数据结构用HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)。
2. redis是单线程的，省去了很多上下文切换线程的时间（避免线程切换和竞态消耗）。
3. redis使用IO多路复用技术（IO multiplexing, 解决对多个I/O监听时,一个I/O阻塞影响其他I/O的问题），可以处理并发的连接（非阻塞IO）。

# 热 key

我们把<font color='Magenta'>访问频率高的Key，称为热Key</font>。比如突然又几十万的请求去访问redis中某个特定的Key，那么这样会造成redis服务器短时间流量过于集中，很可能导致redis的服务器宕机。那么接下来对这个Key的请求，都会直接请求到我们的后端数据库中，数据库性能本来就不高，这样就可能直接压垮数据库，进而导致后端服务不可用。

## 产生原因

1. 用户消费的数据远大于生产的数据，如商品秒杀、热点新闻、热点评论等读多写少的场景。

   > 双十一秒杀商品，短时间内某个爆款商品可能被点击/购买上百万次，或者某条爆炸性新闻等被大量浏览，此时会造成一个较大的请求Redis量，这种情况下就会造成热点Key问题。

2. 请求分片集中，超过单台Redis服务器的性能极限。

   > 在服务端读数据进行访问时，往往会对数据进行分片切分，例如采用固定 Hash 分片，Hash 落入同一台redis服务器，如果瞬间访问量过大，超过机器瓶颈时，就会导致热点 Key 问题的产生。

## 危害

> 缓存击穿，压垮redis服务器，导致大量请求直接发往后端服务，并且DB本身性能较弱，很可能进一步导致后端服务雪崩。

## 识别热 key

> 1. 凭借个人经验，结合业务场景，判断哪些是热Key
>
>    比如，双十一大促的时候，苹果手机正在秒杀，那么我们可以判断苹果手机这个 sku 就是热Key。
>
> 2. 使用redis之前，在客户端写程序统计key的使用次数。
>
>    修改业务代码，在操作redis之前，加入Key使用次数的统计逻辑，定时把收集到的数据上报到统一的服务进行聚合计算，这样我们就可以找到那些热点Key。缺点就是对我们的业务代码有一定的侵入性。
>
> 3. redis节点抓包分析
>
>    自己写程序监听端口，解析数据，进行分析。

## 解决方案

1. redis集群扩容，增加分片数量，分摊客户端发过来的读请求
1. 随机的Redis Key，通过得知redis集群的分片数量，去设置这个key，将redis集群的key分散到不同的机器上。
1. 使用二级缓存，即 JVM 本地缓存，减少redis的读请求
1. 限流：通过控制请求的速率来防止系统过载。在应用层实现限流，可以有效减轻热点Key对Redis的压力。常见的限流算法有漏桶算法和令牌桶算法。

# 大key问题

<font color='Magenta'>`Redis`的`key`和`String`类型`value`限制均为`512MB`。</font>虽然`Key`的大小上限为`512M`,但是**一般建议`key`的大小不要超过`1KB`**，这样既可以节约存储空间，又有利于`Redis`进行检索

==String类型==：一个`String`类型的`value`最大可以存储`512M`

==List、Set、Hash、Sorted set类型==：单个元素的`value`上限为`512M`

## 影响

1. 内存占用过高。大`Key`占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，`Redis`实例崩溃，影响系统的稳定性。
2. 性能下降。大`Key`会占用大量内存空间，导致内存碎片增加，进而影响`Redis`的性能。对于大`Key`的操作，如读取、写入、删除等，都会消耗更多的`CPU`时间和内存资源，进一步降低系统性能。
3. 阻塞其他操作。某些对大`Key`的操作可能会导致`Redis`实例阻塞。例如，使用`DEL`命令删除一个大`Key`时，可能会导致`Redis`实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。
4. 网络拥塞。每次获取大`key`产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是`1MB`，每秒访问`1000`次，就有`1000MB`的流量。
5. 主从同步延迟。当`Redis`实例配置了主从同步时，大`Key`可能导致主从同步延迟。由于大`Key`占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。
6. 数据倾斜。在`Redis`集群模式中，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。另外也可能造成`Redis`内存达到`maxmemory`参数定义的上限导致重要的`key`被逐出，甚至引发内存溢出。

## 原因

1. 业务设计不合理。这是最常见的原因，不应该把大量数据存储在一个`key`中，而应该分散到多个`key`。例如：把全国数据按照省行政区拆分成`34`个`key`，或者按照城市拆分成`300`个`key`，可以进一步降低产生大`key`的概率。
2. 没有预见`value`的动态增长问题。如果一直添加`value`数据，没有删除机制、过期机制或者限制数量，迟早出现大`key`。例如：微博明星的粉丝列表、热门评论等。
3. 过期时间设置不当。如果没有给某个`key`设置过期时间，或者过期时间设置较长。随着时间推移，`value`数量快速累积，最终形成大`key`。
4. 程序`bug`。某些异常情况导致某些`key`的生命周期超出预期，或者`value`数量异常增长 ，也会产生大`key`。

## 排查大key

<font color='Magenta'>SCAN命令</font>

通过使用`Redis`的`SCAN`命令，我们可以逐步遍历数据库中的所有`Key`。结合其他命令（如`STRLEN`、`LLEN`、`SCARD`、`HLEN`等），我们可以识别出大`Key`。`SCAN`命令的优势在于它可以在不阻塞`Redis`实例的情况下进行遍历。

<font color='Magenta'>bigkeys参数</font>

使用`redis-cli`命令客户端，连接`Redis`服务的时候，加上 `—bigkeys `参数，可以扫描每种数据类型数量最大的`key`。

> redis-cli -h 127.0.0.1 -p 6379 —bigkeys

<font color='Magenta'>Redis RDB Tools工具</font>

使用开源工具`Redis RDB Tools`，分析`RDB`文件，扫描出`Redis`大`key`。

> 例如：输出占用内存大于1kb，排名前3的keys。
>
> rdb —commond memory —bytes 1024 —largest 3 dump.rbd

## 解决方式

1. 拆分成多个小`key`。这是最容易想到的办法，降低单`key`的大小，读取可以用`mget`批量读取。
2. 数据压缩。使用`String`类型的时候，使用压缩算法减少`value`大小。或者是使用`Hash`类型存储，因为`Hash`类型底层使用了压缩列表数据结构。
3. 设置合理的过期时间。为每个`key`设置过期时间，并设置合理的过期时间，以便在数据失效后自动清理，避免长时间累积的大`Key`问题。
4. 启用内存淘汰策略。启用`Redis`的内存淘汰策略，例如`LRU`（`Least Recently Used`，最近最少使用），以便在内存不足时自动淘汰最近最少使用的数据，防止大`Key`长时间占用内存。
5. 数据分片。例如使用`Redis Cluster`将数据分散到多个`Redis`实例，以减轻单个实例的负担，降低大`Key`问题的风险。
6. 删除大`key`。使用`UNLINK`命令删除大`key`，`UNLINK`命令是`DEL`命令的异步版本，它可以在后台删除`Key`，避免阻塞`Redis`实例。

# 数据库&缓存一致性保证

建议采用“==先写数据库再删除缓存==”的方式

1. 先确定是更新缓存还是删除缓存：

   <font color='Apricot'>应该优先选择删除缓存而不是更新缓存。</font>原因如下：

   1. 我们放到缓存中的数据，很多时候可能不只是简单的一个字符串类型的值，他还可能是一个大的`JSON`串，一个`map`类型等等。如果选择更新，那么业务中先需要从缓存中查出整个模型数据，把他进行反序列化之后，再解析出其中的库存字段，把他修改掉，然后再序列化，最后再更新到缓存中。相比于直接删除缓存，操作过程比较的复杂，而且也容易出错。

   2. "写写并发"的场景中，如果同时更新缓存和数据库，那么很容易会出现因为并发的问题导致数据不一致的情况。如：

      <img src="https://gitee.com/qc_faith/picture/raw/master/image/202312251719055.png" alt="image-20231225171927029" style="zoom: 25%;" />

      <font color='Magenta'>如果是做缓存的删除的话，在写写并发的情况下，缓存中的数据都是要被清除的，所以就不会出现数据不一致的问题。</font>但是，删除缓存相比更新缓存有一个小缺点，那就是带来的一次额外的`cache miss`，也就是说在删除缓存后的下一次查询会无法命中缓存，要查询一下数据库。<font color='Magenta'>这种cache miss在某种程度上可能会导致缓存击穿</font>，也就是刚好缓存被删除之后，同一个`Key`有大量的请求过来，导致缓存被击穿，大量请求访问到数据库。但是，通过加锁的方式是可以比较方便的解决缓存击穿的问题的。

      总之，删除缓存相比较更新缓存，方案更加简单，而且带来的一致性问题也更少。所以，在删除和更新缓存之间，建议优先选择删除缓存。

2. 确定好是删除缓存后再确定是"先写数据库后删除缓存"还是"先删除缓存后写数据库"。

   <font color='Apricot'>先写数据库后删除缓存</font>，因为数据库和缓存的操作是两步的，没办法做到保证原子性，所以就有可能第一步成功而第二步失败。一般情况下，如果把缓存的删除动作放到第二步，由如下好处：

   1. <font color='Magenta'>缓存删除失败的概率还是比较低的</font>，除非是网络问题或者缓存服务器宕机的问题，否则大部分情况都是可以成功的。

   2. 先写数据库后删除缓存虽然不存在"写写并发"导致的数据一致性问题，但是会存在"读写并发"情况下的数据一致性问题。我们知道，当我们使用了缓存之后，一个读的线程在查询数据的过程是这样的：1、查询缓存，如果缓存中有值，则直接返回 2、否则查询数据库 3、把数据库的查询结果更新到缓存中。所以，<font color='Magenta'>对于一个读线程来说，虽然不会写数据库，但是是会更新缓存的</font>，所以，在一些特殊的并发场景中，就会导致数据不一致的情况。读写并发的时序如下：

      <img src="/Users/sunchaofei/Library/Application Support/typora-user-images/image-20231225171056260.png" alt="image-20231225171056260" style="zoom: 33%;" />

   也就是说，假如一个读线程，在读缓存的时候没查到值，他就会去数据库中查询，但是如果自查询到结果之后，更新缓存之前，数据库被更新了，但是这个读线程是完全不知道的，那么就导致最终缓存会被重新用一个"旧值"覆盖掉。这也就导致了<font color='Magenta'>缓存和数据库的不一致的现象</font>。但是这种现象其实发生的概率比较低，因为一般一个读操作是很快的，数据库+缓存的读操作基本在十几毫秒左右就可以完成了。而在这期间，刚好另一个线程执行完了一个比较耗时的写操作的概率确实比较低。

3. 如果先删缓存后写数据库会有什么问题

   首先，<font color='Magenta'>如果是选择先删除缓存后写数据库的这种方案，那么第二步的失败是可以接受的</font>，因为这样不会有脏数据，也没什么影响，只需要重试就好了。

   但是，<font color='Magenta'>先删除缓存后写数据库的这种方式，会无形中放大前面我们提到的"读写并发"导致的数据不一致的问题。</font>

   因为这种"读写并发"问题发生的前提是读线程读缓存没读到值，而先删缓存的动作一旦发生，刚好可以让读线程就从缓存中读不到值。

   所以，本来一个小概率会发生的"读写并发"问题，在先删缓存的过程中，问题发生的概率会被放大。

   而且这种问题的后果也比较严重，那就是缓存中的值一直是错的，就会导致后续的所以命中缓存的查询结果都是错的！

## 延迟双删

```tsx
先删除缓存；再写数据库；休眠1-2s；再次删除缓存。不休眠的话，读请求还有可能未结束，造成脏数据
```

虽然先写数据后删除缓存的这种情况，可以大大的降低并发问题的概率，但是依旧是有出问题的可能。可以采用延迟双删来应对。

因为"读写并发"的问题会导致并发发生后，缓存中的数据被读线程写进去脏数据，那么就只需要在写线程在写数据库、删缓存之后，延迟一段时间，在执行一把删除缓存动作就行了。

这样就能保证缓存中的脏数据被清理掉，避免后续的读操作都读到脏数据。这个延迟的时长一般建议设置1-2s就可以了。

<font color='RedOrange'>弊端</font>：可能会导致缓存中准确的数据被删除掉。当然这也问题不大，只是增加一次cache miss罢了。

## 总结

主要还是根据实际的业务情况来分析。

如果业务量不大，并发不高的情况，可以选择**先写数据库，后删除缓存**的方式，因为这种方案更加简单。

但是，如果是业务量比较大，并发度很高的话，建议选择**先删除缓存**，因为这种方式在引入延迟双删、分布式锁等机制后，会使得整个方案会更加趋近于完美，带来的并发问题更少。当然，也会更复杂。

#  I/O 多路复用

Redis 采用网络 I/O 多路复用技术，来保证在多连接的时候系统的高吞吐量。关于 I/O 多路复用(又被称为“事件驱动”)，首先要理解的是，操作系统为你提供了一个功能，当你的某个 socket 可读或者可写的时候，它可以给你一个通知。这样当配合非阻塞的 socket 使用时，只有当系统通知我哪个描述符可读了，我才去执行 read 操作，可以保证每次 read 都能读到有效数据而不做纯返回 -1 和 EAGAIN 的无用功，写操作类似。

操作系统的这个功能是通过 select/poll/epoll/kqueue 之类的系统调用函数来实现，这些函数都可以同时监视多个描述符的读写就绪状况，这样，多个描述符的 I/O 操作都能在一个线程内并发交替地顺序完成，这就叫 I/O 多路复用。多路---指的是多个 socket 连接，复用---指的是复用同一个 Redis 处理线程。多路复用主要有三种技术：select，poll，epoll。epoll 是最新的也是目前最好的多路复用技术。

采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求(尽量减少网络 I/O 的时间消耗)，且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，基于这两点 Redis 具有很高的吞吐量。

#  五大数据类型及实操

`string 	set		zset 	hash	list`

| 数据类型 | 可以存储的值           | 操作                                                         | 应用场景                                                     |
| -------- | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 | 做简单的键值对缓存                                           |
| LIST     | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 | 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据；可当做栈、队列、阻塞队列 |
| SET      | ==无序==集合           | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 | 交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 | 存储用户信息，商品信息等                                     |
| ZSET     | ==有序==集合           | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 | 去重但可以排序，如获取排名前几名的用户                       |

**三种特殊数据类型**：

`geospatial`（地理位置）：`Geo`底层是`Zset`实现，可以用`zset`命令来操作`geo`

`hyperloglog`：用来做基数（集合中不重复的数）统计的算法，优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。

`bitmaps`（位图）：位存储，`vip`和非`vip`用户，网站活跃、不活跃用户，登录、未登录用户，打开、未打卡，任何两种状态都可以用`bitmap`实现、操作二进制位，只有`0、1`两个状态

# 穿透、击穿、雪崩

##缓存穿透

缓存穿透是指频繁请求查询==缓存和数据库中都没有==的数据

**解决方案：**

1. null结果缓存，并加入短暂过期时间
2. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 `bitmap `中，一个一定不存在的数据会被这个 `bitmap `拦截掉，从而避免了对底层存储系统的查询压力

##缓存击穿

缓存击穿是指==缓存中没有但数据库中有==的数据（一般是缓存时间到期），一个`key`非常热点，并发访问特别多，在它失效的瞬间，持续的大并发就穿破缓存，直接请求到了数据库。

 **解决方案：**

1. 设置热点数据永远不过期。
2. 加互斥锁，保证同一个进程中针对同一个数据不会并发请求到`DB`，减小`DB`压力。

##缓存雪崩

缓存雪崩是指在某个时间点，大量的缓存数据同时过期或失效，导致大量请求直接访问数据库。==和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库==。

   **解决方案**：

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。

```java
setRedis（Key，value，time + Math.random() * 10000）；
```

2. 给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。



# 事务

**`Redis`事务保证原子性吗，支持回滚吗？**

`Redis`中，单条命令是原子性执行的，但**事务不保证原子性，且没有回滚**。事务中任意命令执行失败，其余的命令仍会被执行。

# 内存淘汰

## <font color='VioletRed'>过期删除策略</font>

<font color='Peach'>定期删除+惰性删除</font>

> <font color='Apricot'>定期删除</font>：`Redis`默认是每隔` 100ms` 就<font color='Apricot'>随机抽取</font>一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里随机抽取的原因是假如 `Rredis` 存了几十万个 `key` ，每隔`100ms`就遍历所有设置了过期时间的 `key` 的话，会给 `CPU` 带来很大的负载！
>
> <font color='Apricot'>惰性删除 </font>：定期删除可能会导致很多过期 `key` 到了时间并没有被删除掉。惰性策略就是在客户端访问这个`key`的时候，`redis`对`key`的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。

## <font color='VioletRed'>数据淘汰策略</font>

1. no-envicition：该策略对于写请求不再提供服务，会直接返回错误，当然排除`del`等特殊操作，**`Redis`的默认策略**。

2. allkeys-lru：使用`LRU`（`Least Recently Used`，最近最少使用）算法，从`Redis`中选取最近最少使用的`key`进行淘汰

3. volatile-lru：使用`LRU`（`Least Recently Used`，最近最少使用）算法，从设置了过期时间的键集合中驱逐最近最少使用的键

4. allkeys-random：从所有key随机删除

5. volatile-random：从配置了过期时间的键的集合中进行随机淘汰

6. volatile-ttl：从配置了过期时间的键中淘汰马上就要过期的键

   <font color='Tasma'>在Redis 4.0以后，又增加了以下两种</font>

7. volatile-lfu：使用`LFU`（`Least Frequently Used`，最不经常使用），从所有配置了过期时间的键中驱逐使用频率最少的键

8. allkeys-lfu：使用`LFU`（`Least Frequently Used`，最不经常使用），从所有键中驱逐使用频率最少的键

<font color='VioletRed'>内存淘汰算法</font>

- 随机

- TTL：

  > 从设置了过期时间的 Keys 中获取最早过期的一批 Keys，然后淘汰这些 Keys

- LRU（Least Recently Used，最近最少使用）:

  > 所有的 Keys 都根据最后被访问的时间来进行排序的，所以在淘汰时只需要按照所有 Keys 的最后被访问时间，由小到大来进行即可；
  >
  > <font color='orange'>LRU算法的特点：</font>
  >
  > 1. 新增key value的时候首先在链表结尾添加Node节点，如果超过LRU设置的阈值就淘汰队头的节点并删除掉HashMap中对应的节点。
  > 2. 修改key对应的值的时候先修改对应的Node中的值，然后把Node节点移动队尾。
  > 3. 访问key对应的值的时候把访问的Node节点移动到队尾即可。

  <font color='blue'>Redis的LRU实现</font>

  > Redis维护了一个24位时钟，可以简单理解为当前系统的时间戳，每隔一定时间会更新这个时钟。每个key对象内部同样维护了一个24位的时钟，当新增key对象的时候会把系统的时钟赋值到这个内部对象时钟。比如我现在要进行LRU，那么首先拿到当前的全局时钟，然后再找到内部时钟与全局时钟距离时间最久的（差最大）进行淘汰，这里值得注意的是全局时钟只有24位，按秒为单位来表示才能存储194天，所以可能会出现key的时钟大于全局时钟的情况，如果这种情况出现那么就两个相加而不是相减来求最久的key。
  >
  > 
  >
  > Redis中的LRU与常规的LRU实现并不相同，常规LRU会准确的淘汰掉队头的元素，但是Redis的LRU并不维护队列，只是根据配置的策略要么从所有的key中随机选择N个（N可以配置）要么从所有的设置了过期时间的key中选出N个键，然后再从这N个键中选出最久没有使用的一个key进行淘汰。
  >
  > <font color='orange'>为什么要使用近似LRU？</font>
  >
  > 1、性能问题，由于近似LRU算法只是最多随机采样N个key并对其进行排序，如果精准需要对所有key进行排序，这样近似LRU性能更高
  >
  > 2、内存占用问题，redis对内存要求很高，会尽量降低内存使用率，如果是抽样排序可以有效降低内存的占用
  >
  > 3、实际效果基本相等，如果请求符合长尾法则，那么真实LRU与Redis LRU之间表现基本无差异
  >
  > 4、在近似情况下提供可自配置的取样率来提升精准度，例如通过 CONFIG SET maxmemory-samples 指令可以设置取样数，取样数越高越精准，如果你的CPU和内存有足够，可以提高取样数看命中率来探测最佳的采样比例。

- LFU（Least Frequently Used，最不经常使用）：

  > 它是根据数据的历史访问频率来淘汰数据，核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。LFU算法反映了一个key的热度情况，不会因LRU算法的偶尔一次被访问被误认为是热点数据。

  <font color='blue'>LFU算法的常见实现方式为链表：</font>

  新数据放在链表尾部 ，链表中的数据按照被访问次数降序排列，访问次数相同的按最近访问时间降序排列，链表满的时候从链表尾部移出数据。

#持久化

## RDB

RDB快照是某个时间点的一次全量数据备份，是二进制文件，在存储上非常紧凑。

> <font color='blue'>优点</font>
>
> - RDB文件小，非常适合定时备份，用于灾难恢复
> - Redis加载RDB文件的速度比AOF快很多，因为RDB文件中直接存储的时内存数据，而AOF文件中存储的是一条条命令，需要重演命令。
>
> <font color='blue'>缺点</font>
>
> - RDB无法做到实时持久化，若在两次bgsave间宕机，则会丢失区间（分钟级）的增量数据，不适用于实时性要求较高的场景
> - RDB的cow机制中，fork子进程属于重量级操作，并且会阻塞redis主进程  (Redis 使用操作系统的多进程 cow(Copy On Write) 机制来实现RDB快照持久化)
> - 存在老版本的Redis不兼容新版本RDB格式文件的问题

## AOF

AOF日志是持续增量的备份，是基于写命令存储的可读的文本文件。AOF日志会在持续运行中持续增大，由于Redis重启过程需要优先加载AOF日志进行指令重放以恢复数据，恢复时间会无比漫长。所以需要定期进行AOF重写，对AOF日志进行瘦身。

> 当两种方式同时开启时，数据恢复`Redis`会优先选择`AOF`恢复，因为`AOF`数据更新的频率更高，会保存更新的数据。

<font color='RedOrange'>重写（rewrite）机制</font>

> AOF日志会在持续运行中持续增大，需要定期进行AOF重写，对AOF日志进行瘦身。
>
> **AOF Rewrite** 虽然是“压缩”AOF文件的过程，但并非采用“基于原AOF文件”来重写或压缩，而是采取了类似RDB快照的方式：基于Copy On Write，全量遍历内存中数据，然后逐个序列到AOF文件中。因此AOF rewrite能够正确反应当前内存数据的状态。
>
> AOF重写（bgrewriteaof）和RDB快照写入（bgsave）过程类似，二者都消耗磁盘IO。Redis采取了“schedule”策略：无论是“人工干预”还是系统触发，快照和重写需要逐个被执行。
>
> 重写过程中，对于新的变更操作将仍然被写入到原AOF文件中，同时这些新的变更操作也会被Redis收集起来。当内存中的数据被全部写入到新的AOF文件之后，收集的新的变更操作也将被一并追加到新的AOF文件中。然后将新AOF文件重命名为appendonly.aof，使用新AOF文件替换老文件，此后所有的操作都将被写入新的AOF文件。

<font color='RedOrange'>优缺点</font>

> <font color='blue'>优点</font>： AOF只是追加写日志文件，对服务器性能影响较小，速度比RDB要快，消耗的内存较少
>
> <font color='blue'>缺点</font>：
>
> - AOF方式生成的日志文件太大，需要不断AOF重写，进行瘦身。
> - 即使经过AOF重写瘦身，由于文件是文本文件，文件体积较大（相比于RDB的二进制文件）。
> - AOF重演命令式的恢复数据，速度显然比RDB要慢。

## 混合持久化

- 仅使用RDB快照方式恢复数据，由于快照时间粒度较大，会丢失大量数据。
- 仅使用AOF重放方式恢复数据，日志性能相对 rdb 来说要慢。在 Redis 实例很大的情况下，启动需要花费很长的时间。

Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——**混合持久化**。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。相当于：

- 大量数据使用粗粒度（时间上）的rdb快照方式，性能高，恢复时间快。
- 增量数据使用细粒度（时间上）的AOF日志方式，尽量保证数据的不丢失。

在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

缺点：兼容性差，一旦开启了混合持久化，在4.0之前版本都不识别该aof文件，同时由于前部分是RDB格式，阅读性较差

#应用场景

**总结一**

1. 计数器

可以对 `String` 进行自增自减运算，从而实现计数器功能。`Redis` 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

2. 缓存

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

3. 会话缓存

可以使用 `Redis` 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

4. 全页缓存（FPC）

除基本的会话`token`之外，`Redis`还提供很简便的`FPC`平台。

5. 查找表

例如 `DNS` 记录就很适合使用 `Redis` 进行存储。查找表和缓存类似，也是利用了 `Redis` 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

6. 消息队列(发布/订阅功能)

`List` 是一个双向链表，可以通过 `lpush` 和 `rpop` 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。

7. 分布式锁实现

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 `Redis` 自带的 `SETNX` 命令实现分布式锁，除此之外，还可以使用官方提供的 `RedLock` 分布式锁实现。

8. 其它

`Set` 可以实现交集、并集等操作，从而实现共同好友等功能。`ZSet` 可以实现有序性操作，从而实现排行榜等功能。

**总结二**

`Redis`相比其他缓存，有一个非常大的优势，就是支持多种数据类型。

`string`——适合最简单的`k-v`存储，类似于`memcached`的存储结构，短信验证码，配置信息等，就用这种类型来存储。

`hash`——一般`key`为`ID`或者唯一标示，`value`对应的就是详情了。如商品详情，个人信息详情，新闻详情等。

`list`——因为`list`是有序的，比较适合存储一些有序且数据相对固定的数据。如省市区表、字典表等。因为`list`是有序的，适合根据写入的时间来排序，如：消息队列等。

`set`——可以简单的理解为`ID-List`的模式，如微博中一个人有哪些好友，`set`最牛的地方在于，可以对两个`set`提供交集、并集、差集操作。例如：查找两个人共同的好友等。

`Sorted Set`——是`set`的增强版本，增加了一个`score`参数，自动会根据`score`的值进行排序。比较适合类似于`top 10`等不根据插入的时间来排序的数据。

