# HashMap

1. **HashMap的结构和底层原理？**

`HashMap`是非常常用的数据结构，由 <span style="color:red">***数组和链表组合构成***</span> （1.8版本之后为==数组+链表/红黑树==）的数据结构。

数组里面每个地方都存了`Key-Value`这样的实例，在`Java7`叫`Entry`在`Java8`中叫`Node`。

![image-20211113134726750](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113134726750.png)

因为他本身所有的位置都为`null`，在`put`插入的时候会根据`key`的`hash`去计算一个`index`值。



2. **HashMap为什么需要链表，链表是什么样子的？**

数组长度是有限的，在有限的长度里面使用哈希，哈希本身就存在概率性，就是`A`和`B`我们都去`hash`有一定的概率会一样，极端情况下对`B`哈希会和`A` `hash`到一个值上，那就形成了链表。

源码表示，每一个节点都会保存自身的`hash、key、value、以及下个节点`

![image-20211113134901459](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113134901459.png)

`HashMap`通过`key`的`hashCode`经过 扰动函数 `(hashcode的高16位和低16位进行异或操作)`处理后得到`hash`值，然后通过`(n-1)&hash`判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存入的元素`hash`值以及`key`是否相同，如果相同直接覆盖，不相同就通过**拉链法**解决冲突。

###插入原理

**HashMap的数据插入原理**

![](https://gitee.com/qc_faith/picture/raw/master/image/1bc8b49a4d3948e9992b23f8af586603~tplv-k3u1fbpfcp-zoom-1.image)

1. 判断数组是否为空，为空进行初始化;

2. 不为空，计算 `k` 的 `hash `值，通过`(n - 1) & hash`计算应当存放在数组中的下标 `index`;

3. 查看 `table[index]` 是否存在数据，没有数据就构造一个`Node`节点存放在 `table[index]` 中；

4. 存在数据，说明发生了`hash`冲突(存在二个节点`key`的`hash`值一样), 继续判断`key`是否相等，相等，用新的`value`替换原数据`(onlyIfAbsent为false)`；

5. 如果不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中；

6. 如果不是树型节点，创建普通`Node`加入链表中；判断链表长度是否大于 `8`， 大于的话链表转换为红黑树；

7. 插入完成之后判断当前节点数是否大于阈值，如果大于开始扩容为原数组的二倍。



3. **新的Entry节点在插入链表的时候，是怎么插入的？**

<span style="color:red">`java8`之前是头插法</span>，就是说新来的值会取代原有的值，原有的值就顺推到链表中去，因为写这个代码的作者认为新加的值被查找的可能性更大一点，能够提升查找的效率。但是，<span style="color:red">在`java8`之后，都是使用尾部插入了</span>



4. **为啥改为尾部插入呢？**

<span style="color:red">结论：</span>

1. 头插法会改变链表中元素原本的顺序，导致链表成环的问题，而尾插法，链表元素顺序不变，不会出现链表成环的问题

2. 能够更好的利用 CPU 缓存的局部性原理，提高性能

   > 尾插法对 CPU 缓存的局部性原理有利的主要原因是它减少了链表节点的随机访问，提高了连续访问节点的可能性，从而更好地利用了 CPU 缓存的特性，提高了性能。
   >
   > CPU 缓存通常由三级结构组成：L1 Cache（一级缓存）、L2 Cache（二级缓存）、L3 Cache（三级缓存），以及主存。缓存系统在处理数据时具有局部性原理，分为两种：
   >
   > 1. **时间局部性（Temporal Locality）：** 如果一个数据被访问，那么在不久之后它很可能再次被访问。
   > 2. **空间局部性（Spatial Locality）：** 如果一个数据被访问，那么在接下来的一段时间内，与它相邻的数据也可能会被访问。
   >
   > 尾插法在 HashMap 中应用，将新的节点插入到链表的尾部。这样做有利于提高空间局部性，因为新插入的节点会被放在链表末尾，节点之间是连续存储的。当程序遍历链表时，由于节点是顺序存储的，它们更有可能被缓存在CPU的缓存层次结构中，这就利用了 CPU 缓存的局部性原理。
   >
   > 相反，如果使用头插法，新节点总是插入链表的头部，这会破坏空间局部性，因为新节点插入后，链表中的节点在内存中可能不是连续存储的，这样会导致节点之间的跳跃式访问，降低了 CPU 缓存的利用率，增加了缓存的失效率。
   >
   > 因此，尾插法利用了空间局部性的特性，有助于提高节点的连续性存储，减少了随机访问，更好地利用了 CPU 缓存的局部性原理，提高了性能。

假设往一个容量大小为`2`的`put`两个值，负载因子是`0.75`，那在`put`第二个的时候就会进行`resize`。(`2*0.75 = 1 `所以插入第二个就要`resize`了)

<img src="https://gitee.com/qc_faith/picture/raw/master/image/image-20211113135009863.png" alt="image-20211113135009863" style="zoom:67%;" />

现在我们要在容量为`2`的容器里面**用不同线程**插入`A，B，C`，假如我们在`resize`之前打个短点，那意味着数据都插入了但是还没`resize`那扩容前可能是这样的。

我们可以看到链表的指向`A->B->C`

**Tip：A的下一个指针是指向B的**

![image-20211113135030049](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113135030049.png)

因为`resize`的赋值方式，也就是使用了**单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置**，在旧数组中同一条`Entry`链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。

就可能出现下面的情况，`B`的下一个指针指向了`A`

![image-20211113135044363](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113135044363.png)

一旦几个线程都调整完成，就可能出现环形链表

![image-20211113135058942](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113135058942.png)

如果这个时候去取值，悲剧就出现了——`Infinite Loop`。

### 扩容

扩容的时候1.7需要对原数组中的元素进行重新`hash`定位在新数组的位置

1.8采用更简单的判断逻辑，原哈希值与扩容新增出来的长度`16`进行`&`运算，若值等于 0 ，下标位置不变，若不为 0 ，新的位置为原来位置加16；

> 扩容的时候为什么1.8 不用重新`hash`就可以直接定位原节点在新数据的位置呢? 
>
> 这是由于扩容是扩大为原数组大小的`2`倍，用于计算数组位置的掩码仅仅只是高位多了一个`1`，怎么理解呢？ 扩容前长度为`16`，用于计算`(n-1) & hash` 的二进制`n-1`为`0000 1111`，扩容为`32`后的二进制就高位多了`1`，为`0001 1111`。 因为是`&` 运算，`1`和任何数` & `都是它本身，那就分二种情况，原数据`hashcode`高位第`4`位为`0`和高位为`1`的情况； 第四位高位为`0`，重新`hash`数值不变，第四位为`1`，重新`hash`数值比旧数组的容量大`16`

**`HashMap`的扩容机制**：

- **扩容的两个决定因素**

`Capacity`：`HashMap`当前长度。

`LoadFactor`：负载因子，默认值`0.75f`。

- **1.7扩容的步骤？**

**`扩容`**：创建一个新的`Entry`空数组，长度是原数组的`2`倍。

`ReHash`：遍历原`Entry`数组，把所有的`Entry`重新`Hash`到新数组。

> **为什么要重新Hash而不是直接复制过去？**
>
> 是因为长度扩大以后，`Hash`的规则也随之改变。
>
> `Hash的公式---> index = HashCode（Key） & （Length - 1）`
>
> 原来长度`(Length)`是`8`你位运算出来的值是`2` ，新的长度是`16`你位运算出来的值明显不一样了。





5. **1.8的尾插是怎么样的呢？**

因为**`java8`之后链表有红黑树**的部分，红黑树的引入巧妙的将原本`O(n)`的时间复杂度降低到了`O(logn)`。

**使用头插**会改变链表上的顺序，但是如果**使用尾插**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

`Java7`在多线程操作`HashMap`时可能引起死循环，原因是扩容转移后前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。

`Java8`在同样的前提下并不会引起死循环，原因是扩容转移后前后链表顺序不变，保持之前节点的引用关系。



6. **那是不是意味着Java8就可以把HashMap用在多线程中呢？**

即使不会出现死循环，但是通过源码看到`put/get`方法都没有加同步锁，多线程情况最容易出现的就是：无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证

### **2的幂**

7. **HashMap默认初始化长度为什么是16？**

一般如果`new HashMap() `不传值，默认大小是`16`，负载因子是`0.75`， 如果自己传入初始大小`k`，初始化大小为 **大于k的 2的整数次方**，例如如果传10，大小为16。

`JDK1.8`中写道 `1<<4 `就是16，因为 16 是 2 的幂，这样是为了位运算的方便，因为**位与运算比算数计算的效率高了很多**，使用是`2`的幂的数字的时候，`Length-1`的值是所有二进制位全为`1`，这种情况下，`index`的结果等同于`HashCode`后几位的值。只要输入的`HashCode`本身分布均匀，Hash算法的结果就是均匀的。这是为了**实现均匀分布**。

> 2的幂有 2, 4, 8, 16, 32等，选2，4， 8的话长度太小，需要频繁扩容，32的话又太大浪费空间，所以选了16
>
> `index的计算公式：index = HashCode(Key) & (Length - 1)`
>
> 之所以用位与运算效果与取模一样，性能也提高了不少！



9. **为啥我们重写equals方法的时候需要重写hashCode方法呢？用HashMap举个例子？**

在java中，所有的对象都是继承于 `Object` 类。`Ojbect` 类中有两个方法`equals、hashCode`，这两个方法都是用来比较两个对象是否相等的。

在未重写 `equals `方法时我们是继承了`object`的` equals` 方法，**那里的 `equals`是比较两个对象的内存地址**，显然我们`new`了2个对象内存地址肯定不一样。

`HashMap` 是通过`key`的` hashCode` 去寻找` index` 的，`index`一样就会形成链表，假如A、B在一个链表上，`index `都为2。我们`get`的时候，是根据 `key` 去 `hash` 然后计算出 `index`，找到`index`为`2`处，这就没法分辨`到底是要 A 还是 B` ,所以如果对`equals`方法进行了重写，一定要对` hashCode `方法重写，以保证相同的对象返回相同的`hash值`，不同的对象返回不同的`hash值`。不然一个链表的对象，发现 `hashCode` 都一样，就无法知道要找的是哪个。



10. **什么是线程安全？**

《Java并发编程实践》中对线程安全的定义：

> 当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。



11. **HashMap是线程不安全的，那怎么处理HashMap在线程安全的场景？**

在这样的场景，一般会使用**`HashTable`**或者**`ConcurrentHashMap`**，但是因为前者的**并发度**的原因基本上没啥使用场景了，所以存在线程不安全的场景使用`ConcurrentHashMap`。

`HashTable`很简单粗暴，直接在方法上锁，并发度很低，最多同时允许一个线程访问，`ConcurrentHashMap`就好很多了，`1.7`和`1.8`有较大的不同，不过并发度都比前者好太多了。



12. **Hashmap中的链表大小超过八个时会自动转化为红黑树，当删除小于六时重新变为链表，为啥呢？**

根据泊松分布，在负载因子默认为`0.75`的时候，发生`hash`碰撞8次的几率为百万分之6，。因为8够用了，小于6时重新变为链表是因为如果`hash`碰撞次数在8附近徘徊，会一直发生链表和红黑树的转化，为了预防这种情况的发生。



### 扰动函数

**HashMap的哈希函数怎么设计的? 为什么这么设计**

~~~java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
~~~

`hash`函数是先拿到`key `的`hashcode`，是`32`位的`int`值，然后让`hashcode`的高`16`位和低`16`位进行异或操作。

这个也叫扰动函数，这么设计有二点原因：

1. 一定要尽可能降低`hash`碰撞，越分散越好；
2. 算法一定要尽可能高效，因为这是高频操作, 因此采用位运算；

**为什么采用hashcode的高16位和低16位异或能降低hash碰撞？hash函数能不能直接用key的hashcode？**

1. 把哈希值右移`16`位，正好是自己长度的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。
2. 不能，因为`key.hashCode()`函数调用的是`key`键值类型自带的哈希函数，返回`int`型散列值。`int`值范围为**`-2147483648~2147483647`**，前后加起来大概`40`亿的映射空间。只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个`40`亿长度的数组，内存是放不下的。如果HashMap数组的初始大小才16，用之前需要对数组的长度取模运算，得到的余数才能用来访问数组下标。

~~~markdown
1. ThreadLocal 是基于数组的开放寻址数据结构，采用的斐波那契散列，因为它在有限空间内，对线程内的元素计算索引位置更加分散。HashMap 为了降低元素的碰撞采用的是扰动函数
2. HashMap 为了解决元素的碰撞，采用哈希桶 + 链表/红黑树的数据结构，也称为拉链寻址。开放寻址是 ThreadLocal 解决元素的碰撞使用的数据结构
~~~



### 1.8的优化

1. 数组 + 链表改成了数组+链表或红黑树；

   > 防止发生`hash`冲突，链表长度过长，将时间复杂度由`O(n)`降为`O(logn)`;

2. 链表的插入方式从头插法改成了尾插法，简单说就是插入时，如果数组位置上已经有元素，1.7将新元素放到数组中，原始节点作为新节点的后继节点，1.8遍历链表，将元素放置到链表的最后；

   > 因为1.7头插法扩容时，头插法会使链表发生反转，多线程环境下会产生环； A线程在插入节点B，B线程也在插入，遇到容量不够开始扩容，重新`hash`，放置元素，采用头插法，后遍历到的B节点放入了头部，这样形成了环

3. 扩容的时候1.7需要对原数组中的元素进行重新`hash`定位在新数组的位置，1.8采用更简单的判断逻辑，原哈希值与扩容新增出来的长度进行`&`运算，若值等于 0 ，下标位置不变，若不为 0 ，新的位置为原来位置加原数组长度；

   > 扩容的时候为什么1.8 不用重新`hash`就可以直接定位原节点在新数据的位置呢? 这是由于扩容是扩大为原数组大小的`2`倍，用于计算数组位置的掩码仅仅只是高位多了一个`1`，假设扩容前长度为`16`，用于计算`(n-1) & hash` 的二进制`n-1`为`0000 1111`，扩容为`32`后的二进制就高位多了`1`，为`0001 1111`。 因为是`&` 运算，`1`和任何数` & `都是它本身，那就分二种情况，原数据`hashcode`高位第`4`位为`0`和高位为`1`的情况； 第四位高位为`0`，重新`hash`数值不变，第四位为`1`，重新`hash`数值比旧数组的容量大`16`

4. 在插入时，1.7先判断是否需要扩容，再插入，1.8先进行插入，插入完成再判断是否需要扩容

### 最大容量

`HashMap`的最大容量规定为：

```java
// 最大容量（必须是2的幂且小于2的30次方，传入容量过大将被这个值替换）
static final int MAXIMUM_CAPACITY = 1 << 30;
```

"<<"为左移运算符，1表示十进制中的“1”，30表示十进制数字1转化为二进制后向左移动30位。在数值上等同于2的30次幂。

首先：`JAVA`规定了该`static final `类型的静态变量为`int`类型，至于为什么不是`byte`、`long`等类型，原因是由于考虑到`HashMap`的性能问题而作的折中处理！

由于`int`类型限制了该变量的长度为`4`个字节共`32`个二进制位，按理说可以向左移动`31`位即`2`的`31`次幂。但是事实上由于二进制数字中最高的一位也就是最左边的一位是符号位，用来表示正负之分（0为正，1为负），所以只能向左移动`30`位，而不能移动到处在最高位的符号位！



# ArrayList

1. **什么是ArrayList**

`ArrayList`是数组列表，或者说动态数组，它提供了动态的增加和减少元素，实现了`ICollection`和`IList`接口，灵活的设置数组的大小等好处。主要用来装载数据，当装载的是基本类型的数据`int、long、boolean、short、byte...`的时候只能存储它们对应的包装类，底层实现是<span style="color:red">***数组***</span> `Object[] elementDate`

与它类似的是` LinkedList`，和 `LinkedList `相比，它的查找和访问元素的速度更快，但新增删除的速度较慢

**特点：**查询效率高，增删效率低，线程不安全。使用频率很高。



2. **为啥线程不安全还使用它呢？**

我们正常使用的场景中，都是用来查询，不会涉及太频繁的增删，如果涉及频繁的增删，可以使用 `LinkedList`，如果需要线程安全就使用 `Vector`，这就是三者的区别，实际开发过程中还是 `ArrayList` 使用最多的。

不存在一个集合工具是查询效率又高，增删效率也高的，还线程安全的，至于为啥大家看代码就知道了，因为数据结构的特性就是优劣共存的，想找个平衡点很难，牺牲了性能，那就安全，牺牲了安全那就快速。



3. **它的底层实现是数组，但数组的大小是定长的，如果不断的往里面添加数据的话，不会有问题吗？**

`ArrayList` 可以通过构造方法在初始化的时候指定底层数组的大小。

通过无参构造方法的方式 `ArrayList()` 初始化，则赋值底层数组 `Object[] elementData` 为一个**默认空数组** `Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}` 所以**数组容量为 0**，**只有真正对数据进行添加 `add` 时，才分配默认 DEFAULT_CAPACITY = 10 的初始容量**。



4. **数组的长度是有限制的，而ArrayList可以存放任意数量对象，长度不受限制，他是怎么实现的？**

他是通过数组扩容的方式去实现的。扩容策略是每次都增加当前数组长度的一半。

比如现在有一个长度为10的数组，我们要新增一个元素，发现已经满了。

那第一步他会重新定义一个长度为10+10/2的数组也就是新增一个长度为15的数组。

然后把原数组的数据，原封不动的复制到新数组中，这个时候再把指向原数的地址换到新数组，ArrayList就这样完成了一次改头换面。

在使用`ArrayList`的时候一般不会设置初始值的大小，那ArrayList默认的大小就刚好是10。如果传入了初始值大小，那就使用你传入的参数，如果没，那就使用默认的



5. **ArrayList1.7和1.8版本初始化的时候的区别？**

`ArrayList` 1.7开始变化有点大，一个是初始化的时候，1.7以前会调用`this(10)`才是真正的容量为10，1.7即本身以后是默认走了空数组，只有第一次add的时候容量会变成10。



6. **ArrayList在增删的时候是怎么做的么？主要说一下他为啥慢。**

他有指定`index`新增，也有直接新增的。

在这之前他会有一步校验长度的判断 **`ensureCapacityInternal`** 去检查一下数组的容量是否足够，如果足够则直接添加，长度不够，是需要扩容的。

![image-20211113140243007](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113140243007.png)

在扩容的时候，老版本的 jdk 和 8 以后的版本是有区别的，8之后的效率更高了，采用了位运算，**右移**一位，扩容到原来的1.5倍。

![image-20211113193720468](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193720468.png)

指定位置新增的时候，首先检查`index`是否越界，接着进行空间检查看是否需要扩容，最后就是数组的`copy`（复制指定待插入位置`(index a)`及之后的元素，将它们放在`index a+1`的位置上，为新增元素腾出位置）

![image-20211113193734559](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193734559.png)

7. **ArrayList（int initialCapacity）会不会初始化数组大小？**

==会初始化数组大小！但是List的大小没有变，因为list的大小是返回size的。==

而且将构造函数与` initialCapacity` 结合使用，然后使用 `set() `会抛出异常，尽管该数组已创建，但是大小设置不正确。

使用`sureCapacity()`也不起作用，因为它基于`elementData`数组而不是大小。还有其他副作用，这是因为带有`sureCapacity()的静态`DEFAULT_CAPACITY`。

进行此工作的唯一方法是在使用构造函数后，根据需要使用`add()`多次。

直接操作一下代码，大家会发现我们虽然对`ArrayList`设置了初始大小，但是我们打印List大小的时候还是0，我们操作下标set值的时候也会报错，数组下标越界。

其实数组是初始化了，但是`List`没，那`size`就没变，`set`下标是和`size`比较的那就报错了。

![image-20211113193756040](https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193756040.png)

8. **ArrayList插入删除一定慢么？**

取决于你插入删除的元素离数组末端有多远，`ArrayList`拿来作为堆栈来用还是挺合适的，`push`和`pop`操作完全不涉及数据移动操作，在数组末尾进行增删的话还是比较快的。

9. **ArrayList删除怎么实现的？**

要删除数组中的`index a`这个位置，代码就复制从`index a+1`开始到最后的数组，然后把它放到`index a`的位置，其实就是被覆盖了

10. **ArrayList是线程安全的么？**

不是，线程安全版本的数组容器是`Vector`。

`Vector`的实现很简单，就是把所有的方法统统加上`synchronized`就完事了。

也可以不使用`Vector`，用`Collections.synchronizedList`把一个普通`ArrayList`包装成一个线程安全版本的数组容器也可以，原理同`Vector`是一样的，就是给所有的方法套上一层`synchronized`。

11. **ArrayList用来做队列合适么？**

`ArrayList`不适合做队列。

队列一般是`FIFO（先入先出）`的，如果用`ArrayList`做队列，就需要在数组尾部追加数据，数组头部删除数组，反过来也可以。

但是无论如何总会有一个操作会涉及到数组的数据搬迁，这个是比较耗费性能的。

12. **数组适合用来做队列么？**

数组是非常合适的。

比如`ArrayBlockingQueue`内部实现就是一个环形队列，它是一个定长队列，内部是用一个定长数组来实现的。

另外著名的`Disruptor`开源`Library`也是用环形数组来实现的超高性能队列。

简单点说就是使用两个偏移量来标记数组的读位置和写位置，如果超过长度就折回到数组开头，前提是它们是定长数组。

13. **ArrayList的遍历和LinkedList遍历性能比较如何？**

论遍历`ArrayList`要比`LinkedList`快得多，`ArrayList`遍历最大的优势在于内存的连续性，CPU的内部缓存结构会缓存连续的内存片段，可以大幅降低读取内存的性能开销。



# ConcurrentHashMap

> - JDK1.8底层是==**数组 + 链表/红黑树**== 
>
>   在`1.7`中：**`segments`+`HashEntry`数组**
>
> - `ConCurrentHashMap`支持**高并发**的访问和更新，它是通过==**`Node + CAS + synchronized`来实现线程安全的**==
>
> - 检索操作不用加锁，`get`方法是非阻塞的
>
> - `key`和`value`都不允许为`null`



1. **HashMap在多线程环境下存在线程安全问题，一般怎么处理这种情况？**

一般在多线程的场景，会使用这几种不同的方式去代替：

- 使用`Collections.synchronizedMap(Map)`创建线程安全的`map`集合；
- `Hashtable`
- `ConcurrentHashMap`

`HashTable`是直接在操作方法上加`synchronized`关键字，锁住整个数组，粒度比较大

`Collections.synchronizedMap`是使用`Collections`集合工具的内部类，通过传入`Map`封装出一个`SynchronizedMap`对象，内部定义了一个对象锁，方法内通过对象锁实现；

`ConcurrentHashMap`使用分段锁，降低了锁粒度，让并发度大大提高。



2. **Collections.synchronizedMap是怎么实现线程安全的**

在`SynchronizedMap`内部维护了一个普通对象`Map`，还有排斥锁`mutex`

``` java
Collections.synchronizedMap(new HashMap<>(16));
```

我们在调用这个方法的时候就需要传入一个`Map`，里面有两个构造器，如果你传入了`mutex`参数，则将对象排斥锁赋值为传入的对象。

如果没有，则将对象排斥锁赋值为`this`，即调用`synchronizedMap`的对象。

创建出`synchronizedMap`之后，再操作`map`的时候，就会对方法上锁



#Hashtable与HashMap

- 跟`HashMap`相比<span style="color:red">`Hashtable`是线程安全的</span>，适合在多线程的情况下使用，但是效率不高。

  源码中显示，他在对数据操作的时候都会上锁，所以效率比较低下。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/image-20211113193836931.png" alt="image-20211113193836931" style="zoom:67%;" />

-  <span style="color:red">`Hashtable` 是不允许键或值为 null</span> 的，`HashMap` 的键值则都可以为` null`。

- <span style="color:red">实现方式不同</span>：`Hashtable` 继承了 `Dictionary`类，而 `HashMap` 继承的是 `AbstractMap` 类。

  ​                           `Dictionary` 是 `JDK 1.0` 添加的。

- <span style="color:red">初始化容量不同</span>：`HashMap` 的初始容量为`16`，`Hashtable `初始容量为`11`

  ​							两者的负载因子默认都是：`0.75`。

- <span style="color:red">扩容机制不同</span>：当现有容量  `>` 总容量 `*` 负载因子时，`HashMap` 扩容规则为当前容量翻倍，

  ​                         `Hashtable` 扩容规则为当前容量翻倍` +1`。

- <span style="color:red">迭代器不同</span>：`HashMap` 中的` Iterator `迭代器是` fail-fast `的，而` Hashtable `的` Enumerator `不是` fail-fast` 的。

  所以，当其他线程改变了`HashMap `的结构，如：增加、删除元素，将会抛出	`ConcurrentModificationException` 异常，而` Hashtable `则不会。


###Hashtable 不允许null

4. **为啥 Hashtable 是不允许 KEY 和 VALUE 为 null, 而 HashMap 则可以呢？**

因为`Hashtable`在我们`put `空值的时候会直接抛空指针异常，但是`HashMap`却做了特殊处理。

```java
static final int hash(Object key) { 

	int h;

	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);

}
```

因为`Hashtable`使用的是**<span style="color:red">安全失败机制（fail-safe）</span>**，这种机制会使此次读到的数据不一定是最新的数据。

如果你使用`null`值，就会使得其无法判断对应的`key`是不存在还是为空，因为你无法再调用一次`contain(key）`来对`key`是否存在进行判断，`ConcurrentHashMap`同理。

###fail-fast

5. **fail-fast是啥，原理是什么？**

**<span style="color:red">（fail—fast）</span>**是`java`集合中的一种`快速失败`机制，`java.util` 包下所有的集合都是快速失败的，快速失败会抛出 `ConcurrentModificationException` 异常

`fail-fast` 可以把它理解为一种快速检测机制，它只能用来检测错误，不会对错误进行恢复，`fail-fast` 不一定只在`多线程`环境下存在，`ArrayList `也会抛出这个异常，主要原因是由于 **`modCount` 不等于 `expectedModCount`**。

**<span style="color:red">原理</span>**：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 `modCount` 变量。集合在被遍历期间如果内容发生变化，就会改变`modCount`的值。

每当迭代器使用`hashNext()/next()`遍历下一个元素之前，都会检测`modCount`变量是否为`expectedmodCount`值，是的话就返回遍历；否则抛出异常，终止遍历。

**<span style="color:red">注意</span>**：这里异常的抛出条件是检测到 `modCount！=expectedmodCount` 这个条件。如果集合发生变化时修改`modCount`值刚好又设置为了`expectedmodCount`值，则异常不会抛出。

因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的`bug`。

**<span style="color:red">场景</span>**：`java.util`包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）算是一种安全机制吧。 

###fail-safe

`fail-safe` 是 `Java `中的一种 `安全失败` 机制，它表示的是在遍历时不是直接在原集合上进行访问，而是先复制原有集合内容，在拷贝的集合上进行遍历。 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发 `ConcurrentModificationException`。`java.util.concurrent` 包下的容器都是安全失败的，可以在多线程条件下使用，并发修改



6. **ConcurrentHashMap的数据结构**

`1.8`是基于 ==**数组 + 链表/红黑树**== 组成的，

在`1.7`中：**`segments`+`HashEntry`数组**

和 `HashMap` 一样，仍然是==**数组加链表**==。

`Segment` 是 `ConcurrentHashMap` 的一个内部类，**继承了ReentrantLock**，每个片段都有一个锁，叫做“**锁分段**”

`HashEntry`跟`HashMap`差不多，不同点是，他使用`volatile`去修饰了他的数据`Value`还有下一个节点`next`。

因为基本上还是数组加链表的方式，查询的时候，还得遍历链表，会导致效率很低，这个跟`jdk1.7`的`HashMap`是存在的一样问题。

`JDK1.8`抛弃了原有的 `Segment` 分段锁，而采用了 `Node + CAS + synchronized` 来保证并发安全性。

跟`HashMap`很像，也把之前的`HashEntry`改成了`Node`，但是作用不变，把值和`next`采用了`volatile`去修饰，保证了可见性，并且也引入了红黑树，在链表大于一定值的时候会转换（默认是`8`）。

### 分段锁

`ConcurrentHashMap`成员变量使用`volatile `修饰，免除了指令重排序，同时保证内存可见性，另外使用`CAS`操作和`synchronized`结合实现赋值操作，多线程操作只会锁住当前操作索引的节点。

###并发度高

8. **为啥ConcurrentHashMap并发度这么高？**

原理上来说，`ConcurrentHashMap` 采用了**分段锁**技术，其中 `Segment `继承于 `ReentrantLock`。

不会像 `HashTable `那样不管是` put `还是` get `操作都需要做同步处理，理论上`ConcurrentHashMap `支持 `CurrencyLevel` (`Segment` 数组数量)的线程并发。

每当一个线程占用锁访问一个 `Segment `时，不会影响到其他的 `Segment`。

就是说如果容量大小是`16`他的并发度就是`16`，可以同时允许`16`个线程操作`16`个`Segment`而且还是线程安全的。

他先定位到Segment，然后再进行put操作。

再看看他的put源代码，首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 `scanAndLockForPut()` 自旋获取锁。

1. 尝试自旋获取锁。
2. 如果重试的次数达到了 `MAX_SCAN_RETRIES` 则改为阻塞锁获取，保证能获取成功。



9. **ConcurrentHashMap  get的逻辑？**

`get` 逻辑比较简单，只需要将 `Key` 通过 `Hash` 之后定位到具体的 `Segment` ，再通过一次 `Hash` 定位到具体的元素上。

由于 `HashEntry` 中的 `value` 属性是用 `volatile` 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。

`ConcurrentHashMap` 的 `get` 方法是非常高效的，==因为整个过程都不需要加锁==。

###put、get

12. **ConcurrentHashMap值的存取操作？以及是怎么保证线程安全的？**

> `ConcurrentHashMap`在进行==`put`==操作时大致可分为以下步骤：

1. 根据 `key `计算出 `hashcode `。
2. 判断是否需要进行初始化。
3. 即为当前 `key `定位出的 `Node`，如果为空表示当前位置可以写入数据，利用 `CAS `尝试写入，失败则自旋保证成功。
4. 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
5. 如果都不满足，则利用 `synchronized `锁写入数据。
6. 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树。

> `ConcurrentHashMap`的==`get`==操作如下：

- 根据计算出来的 `hashcode `寻址，如果就在桶上那么直接返回值。
- 如果是红黑树那就按照树的方式获取值。
- 就不满足那就按照链表的方式遍历获取值。

小结：`1.8` 在 `1.7` 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（`O(logn)`），甚至取消了 `ReentrantLock` 改为了 `synchronized`，这样可以看出在新版的 JDK 中对 `synchronized `优化是很到位的。

它是通过**部分锁定+CAS算法来进行实现线程安全的**

### 线程安全

在 `JDK1.7 `中，`ConcurrentHashMap` 采用了分段锁策略，将一个 `HashMap` 切割成 `Segment` 数组，其中 `Segment` 可以看成一个 `HashMap`， 不同点是 `Segment` 继承自 `ReentrantLock`，在操作的时候给 `Segment` 赋予了一个对象锁，从而保证多线程环境下并发操作安全。

`JDK1.8` 对 `HashMap` 做了改造，**当冲突链表长度大于 8 时，会将链表转变成红黑树结构**，`JDK1.8` 中 `ConcurrentHashMap` 类取消了 `Segment` 分段锁，采用 `CAS + synchronized` 来保证并发安全，数据结构跟` jdk1.8 `中 `HashMap` 结构类似，都是数组 + 链表（当链表长度大于` 8` 时，链表结构转为红黑二叉树）结构。

`ConcurrentHashMap` 中 `synchronized` 只锁定当前链表或红黑树的首节点，只要节点 `hash` 不冲突，就不会产生并发，相比 `JDK1.7` 的 `ConcurrentHashMap` 效率又提升了 `N` 倍！

###CAS  自旋

13. **CAS是什么？自旋又是什么？**

`CAS` （比较与交换，==Compare and swap==） 是一种有名的**无锁算法**，是乐观锁的一种实现方式，是一种轻量级锁，`JUC `中很多工具类的实现就是基于 `CAS `的。

`CAS`有**`3`个**操作数

- ==**内存值 V**==
- ==**旧的预期值 A**==
- ==**要修改的新值 B**==

<span style="color:red">当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B ，否则什么都不做</span>

- 当多个线程尝试使用`CAS`同时更新同一个变量时，只有其中一个线程能更新变量的值(<span style="color:red">A 和内存值 V 相同时，将内存值 V 修改为 B </span>)，而其它线程都失败，失败的线程<span style="color:red">并不会被挂起</span>，而是被告知这次竞争中失败，并可以再次尝试<span style="color:red">(否则什么都不做)</span>

先**比较**是否相等，如果相等则**替换**(CAS算法)

`CAS `操作线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程。

这是一种乐观策略，认为并发操作并不总会发生。

<img src="https://gitee.com/qc_faith/picture/raw/master/image/16f1408812043a58" alt="img" style="zoom:67%;" />

就比如我现在要修改数据库的一条数据，修改之前我先拿到他原来的值，然后在`SQL`里面还会加个判断，原来的值和我手上拿到的他的原来的值是否一样，一样我们就可以去修改了，不一样就证明被别的线程修改了`return`错误就好了。

`SQL`伪代码大概如下：

``` sql
update a set value = newValue where value = #{oldValue} //oldValue就是我们执行前查询出来的值 
```



14. **ABA 问题？**

    如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。

    ==解决方式：==

    J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。
    
    - 版本号：修改前去查询原来的值的时候带一个版本号，每次判断就连值和版本号一起判断，判断成功就给版本号加`1`。
    - 时间戳：查询的时候把时间戳一起查出来，对的上才修改并且更新值的时候一起修改更新时间，这样也能保证。

```sql
update a set value = newValue ，vision = vision + 1 where value = #{oldValue} and vision = #{vision} // 判断原来的值和版本号是否匹配，中间有别的线程修改，值可能相等，但是版本号100%不一样
```



15. **CAS性能很高，但是synchronized性能可不咋地，为啥jdk1.8升级之后反而多了synchronized？**

`synchronized`之前一直都是重量级的锁，但是后来`java`官方是对他进行过升级的，他现在采用的是锁升级的方式去做的。

针对 `synchronized `获取锁的方式，`JVM `使用了锁升级的优化方式，就是先使用**偏向锁**优先同一线程然后再次获取锁，如果失败，就升级为 **`CAS `轻量级锁**，如果失败就会短暂**自旋**，防止线程被系统挂起。最后如果以上都失败就升级为**重量级锁**。

所以是一步步升级上去的，最初也是通过很多轻量级的方式锁定的。



#volatile

### 特性

==可见性、禁止指令重排序（实现有序性）==

`volatile`通常被比喻成`"轻量级的synchronized"`，和`synchronized`不同的是，`volatile`是一个变量修饰符，只能用来修饰变量。无法修饰方法及代码块等。

volatile关键字是Java虚拟机提供的的最轻量级的同步机制，它作为一个修饰符出现，用来修饰变量（不包括局部变量）保证变量对所有线程可见性。

<font color='RedOrange'>volatile修饰的变量，在每个读操作（Load操作）之前都加上Load屏障，强制从主内存读取最新的数据。每次在写操作（Store操作）后面，加上Store屏障，强制将数据刷新到主内存。</font>

<font color='Magenta'>使用场景：</font>

> 对于一个变量，只有一个线程执行写操作，其它线程都是读操作，这时候可以用 `volatile `修饰这个变量。

<font color='Magenta'>volatile仅仅用来保证该变量对所有线程的可见性，但不保证原子性</font>

- 保证<font color='Peach'>该变量对所有线程的可见性</font>
  - 当写一个`volatile`变量时，`JVM`会把本地内存的变量强制刷新到主内存中
  - 这个写操作导致其他线程中的缓存无效，其他线程读，会从主内存读。`volatile`的写操作对其它线程实时可见。
- 禁止指令重排序（实现==**有序性**==），指令重排序是指编译器和处理器为了优化程序性能对指令进行排序的一种手段，需要遵守一定规则：
  - 不会对存在依赖关系的指令重排序，例如 `a = 1;b = a`; `a` 和`b`存在依赖关系，不会被重排序
  - 不能影响单线程下的执行结果。比如：`a=1`;`b=2`;`c=a+b`这三个操作,前两个操作可以重排序，但是`c=a+b`不会被重排序，因为要保证结果是`3`
- 不保证原子性
  - 修改变量(赋值)实质上在`JVM`中分了好几步，而在这几步内(从装载变量到修改)，它是不安全的。`volatile` 只能保证对单次读/写的原子性。

`volatile`  与	`synchronized`区别

1. <font color='Magenta'>`volatile` 关键字：</font>
   - *作用：* 用于标记变量，确保多个线程对该变量的读取和写入操作都在主内存中进行，而不是在线程的本地缓存中操作。
   - 特点：
     - 保证了变量的可见性，即当一个线程修改了变量的值，其他线程能够立即看到最新的值，而不会使用本地缓存中的旧值。
     - 不能保证原子性，多个线程对该变量的操作仍然可能存在竞态条件问题。
   - <font color='Magenta'>适用场景：</font> 适用于对变量的读取和写入操作不依赖于当前值的情况，常用于标记某个变量是否被修改过。
2. <font color='Magenta'>`synchronized` 关键字：</font>
   - *作用：* 用于实现同步，确保多个线程之间对同步块或方法的互斥访问，只允许一个线程执行同步代码块，其他线程必须等待。
   - 特点：
     - 提供了原子性和可见性，保证了同步代码块内对共享变量的操作是原子的，并且对其他线程可见。
     - 锁的释放由 JVM 自动管理，退出同步块或方法时自动释放锁。
   - <font color='Magenta'>适用场景：</font> 适用于需要保护共享资源的情况，确保多个线程在同一时间只能有一个线程访问共享资源，避免出现竞态条件和数据不一致等问题。

<font color='Magenta'>主要区别：</font>

- `volatile` 主要解决的是变量可见性的问题，保证线程在读取和修改变量时能够看到最新的值，且禁止指令重排序但不能保证原子性。只能用于变量，不会造成阻塞
- `synchronized` 主要用于实现线程之间的同步和互斥，确保同一时间只有一个线程能够访问共享资源，保证了原子性和可见性。用于类、变量、方法和代码块，会阻塞
- 性能：在资源竞争不激烈的情况下，`synchronized` 由于会阻塞线程所以性能损耗比较大，而`volatile` 不会引起线程阻塞，性能较好。

一般情况下，如果仅需保证变量的可见性而不需要原子性的操作，可以使用 `volatile`；如果需要保证原子性以及线程安全，通常使用 `synchronized` 或者更高级的并发工具如 `Lock`。

### 原理

在`JVM`底层`volatile`是采用 <font color='Apricot'>内存屏障</font> 来实现的，内存屏障会提供3个功能：

1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2. 它会强制将缓存的修改操作立即写到主内存
3. 写操作会导致其它`CPU`中的缓存行失效，写之后，其它线程的读操作会从主内存读。

### 局限性

<font color='Apricot'>volatile 只能保证可见性，不能保证原子性。</font>写操作对其它线程可见，但是不能解决多个线程同时写的问题。

# 锁

## 分类

> - <font color='RedOrange'>可重入锁</font>：Synchronized和ReentrantLook都是可重入锁，锁的可重入性标明了锁是针对线程分配方式而不是针对方法。例如调用Synchronized方法A中可以调用Synchronized方法B，而不需要重新申请锁。
> - <font color='RedOrange'>读写锁</font>：数据库事务隔离特性的类比读写锁，在访问统一个资源（一个文件）的时候，使用读锁来保证多线程可以同步读取资源。ReadWriteLock是一个读写锁，通过readLock()获取读锁，通过writeLock()获取写锁。
> - <font color='RedOrange'>可中断锁</font>：是指锁是可以被中断的，Synchronized内置锁是不可中断锁，ReentrantLock可以通过lockInterruptibly方法中断显性锁。例如线程B在等待等待线程A释放锁，但是线程B由于等待时间太久，可以主动中断等待锁。
> - <font color='RedOrange'>公平锁</font>：公平锁是指尽量以线程的等待时间先后顺序获取锁，等待时间最久的线程优先获取锁。synchronized隐性锁是非公平锁，它无法保证等待的线程获取锁的顺序，ReentrantLook可以自己控制是否公平锁。

<font color='each'>Java内置锁</font>：隐式锁（Implicit Locks）和显式锁（Explicit Locks）。

<font color='RedOrange'>隐式锁</font>，也称为内置锁或 `synchronized` 锁，是Java语言级别提供的一种锁机制。通过在方法或代码块中使用synchronized关键字，Java编译器和JVM会自动在对象或类上添加锁，以实现对共享资源的同步访问。隐式锁的使用简单方便，但锁的粒度较粗，只能实现基本的互斥和同步。

<font color='RedOrange'>显式锁</font>，也称为外部锁，是通过 `Lock` 接口及其实现类来实现的。显式锁提供了更加灵活和精细的锁控制，如可重入性、条件变量、公平性等。显式锁的使用需要显式地获取和释放锁，提供了更多的操作和状态信息，适用于复杂的并发控制场景。

### 两种锁的底层实现

> Synchronized：底层使用指令码方式来控制锁的，映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当线程执行遇到monitorenter指令时会尝试获取内置锁，如果获取锁则锁计数器+1，如果没有获取锁则阻塞；当遇到monitorexit指令时锁计数器-1，如果计数器为0则释放锁。

> Lock：底层是CAS乐观锁，依赖AbstractQueuedSynchronizer类，把所有的请求线程构成一个同步队列（CLH）。而对该队列的操作均通过Lock-Free（CAS）操作。

### Synchronized和Lock比较

- Synchronized是关键字，内置语言实现，Lock是接口。
- Synchronized在线程发生异常时会自动释放锁，因此不会发生异常死锁。Lock异常时不会自动释放锁，所以需要在finally中实现释放锁。
- Lock是可以中断锁，Synchronized是非中断锁，必须等待线程执行完成释放锁。
- Lock可以使用读锁提高多线程读效率。

## Synchronized

`Synchronized` 是由 `JVM`实现的一种实现互斥同步的一种方式，查看被 `Synchronized` 修饰过的程序块编译后的字节码会发现， 被 `Synchronized` 修饰过的程序块，在编译前后被编译器生成了`monitorenter` 和 `monitorexit` 两 个字节码指令。

在虚拟机执行到 `monitorenter` 指令时，首先要尝试获取对象的锁: 如果这个对象没有锁定，或者当前线程已经拥有了这个对象的锁，把锁的计数器 `+1`;当执行 `monitorexit` 指令时将锁计数器 `-1`；当计数器 为 `0` 时，锁就被释放了。如果获取对象失败了，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。

`Java` 中 `Synchronize` 通过在对象头设置标记，达到了获取锁和释放锁的目的。

“锁”的本质其实是 `monitorenter` 和 `monitorexit` 字节码指令的一 个 `Reference` 类型的参数，即要锁定和解锁的对象。使用`Synchronized` 可以修饰不同的对象，因此，对应的对象锁可以这么确 定：

1. 如果 `Synchronized` 明确指定了锁对象，比如 Synchronized(变量名)、Synchronized(this) 等，说明加解锁对象为该对象。
2. 如果没有明确指定:

- 若 `Synchronized` 修饰的方法为非静态方法，表示此方法对应的对象为 锁对象;
- 若 `Synchronized` 修饰的方法为静态方法，则表示此方法对应的类对象为 锁对象。

当一个对象被锁住时，对象里面所有用 `Synchronized` 修饰的方法都将产生堵塞，而对象里非 `Synchronized` 修饰的方法可正常被调用，不受锁影响。

### 使用场景

三种应用方式：

1. 修饰<font color='RedOrange'>实例方法</font>：当前实例加锁（<font color='Peach'>锁class的同一实例的此方法</font>），进入同步代码前要获得当前实例的锁；一个对象中的加锁方法只允许一个线程访问。这种情况下锁的是访问该方法的实例对象， 如果多个线程不同对象访问该方法，则无法保证同步。
2. 修饰<font color='RedOrange'>静态方法</font>：当前类加锁（<font color='Peach'>锁class的所有实例的此方法</font>），进去同步代码前要获得当前类对象的锁；由于静态方法是类方法， 所以这种情况下锁的是包含这个方法的类，也就是类对象；这样如果多个线程不同对象访问该静态方法，也是可以保证同步的。
3. 修饰<font color='RedOrange'>代码块</font>：这需要指定加锁的对象，对所给的指定对象加锁，进入同步代码前要获得指定对象的锁。
   1. 使用 `synchronized(Class)` 时，锁定的是整个类的对象，而不是实例对象。这意味着无论多少实例对象存在，它们都会竞争同一个锁。
   2. 使用 `synchronized(this) `时，锁定的是当前实例对象（this）。这意味着同一实例的不同方法调用会相互排斥，但不同实例之间的方法调用不会相互排斥。

### 原理

`synchronized`底层原理是基于`JVM`的指令和对象的监视器（monitor）来实现的。

当一个线程要执行一个被`synchronized`修饰的方法或代码块时，它需要先获取该方法或代码块所属对象的监视器。如果获取成功，那么该线程就可以执行同步代码，并且监视器的计数器加一。如果获取失败，那么该线程就会阻塞，直到监视器被释放。

当一个线程执行完同步代码后，它会释放监视器，并且监视器的计数器减一。如果计数器为零，那么说明没有线程持有该监视器，其他线程就可以竞争获取该监视器。

`synchronized`修饰方法时，在字节码层面会有一个`ACC_SYNCHRONIZED`标志，用来表示该方法是同步的。`synchronized`修饰代码块时，在字节码层面会有`monitorenter`和`monitorexit`两个指令，分别用来进入和退出监视器。

<font color='Apricot'>`synchronized` 的底层实现原理可以概括为以下几点：</font>

- synchronized 通过监视器锁来实现线程同步。
- 每个 Java 对象都有一个监视器锁。
- 线程在获取了对象的监视器锁后，可以执行被修饰的代码。
- 线程在释放了对象的监视器锁后，其他线程可以尝试获取监视器锁。

### 特点

1. 互斥性（Mutual Exclusion）：同一时刻只有一个线程可以持有锁，其他线程无法获得锁，从而保证了对共享资源的互斥访问。
1. 可重入性（Reentrant）：同一线程可以多次获得锁，不会造成死锁。
1. 非公平性（Non-Fairness）：隐式锁默认是非公平锁，即不保证线程获取锁的顺序与其请求锁的顺序一致，可能导致某些线程长时间无法获取锁。
1. 释放锁的条件（Release Condition）：隐式锁是自动释放的，当线程退出同步代码块时会自动释放锁，也可以通过调用wait()、notify()、notifyAll()等方法显式地释放锁。

### 锁的升级

`synchronized`在`JDK1.6`之后进行了优化，引入了<font color='RedOrange'>偏向锁，轻量级锁，自旋锁</font>等概念，用来提高性能和减少阻塞开销。

1. 偏向锁：它会将锁定的对象与线程相关联，当一个线程获得锁时，它会标记对象为已偏向该线程，以后再次进入同步块时，不需要竞争锁，而是直接获得。这对于减少无竞争情况下的锁开销非常有用。
2. 轻量级锁：在低竞争情况下，JDK使用轻量级锁来减小锁开销。轻量级锁采用自旋方式来等待锁的释放，而不是进入阻塞状态。
3. 自旋锁：当轻量级锁尝试获取锁失败时，JDK可以选择使用自旋锁。自旋锁不会使线程进入阻塞状态，而是一直尝试获取锁，通常在短时间内完成。这对于低竞争锁非常有用。
4. 适应性自旋：JDK中的锁可以根据历史性能数据来调整自旋等待的次数，以达到更好的性能。

这些优化措施有助于提高`synchronized`的性能，使其在不同的竞争场景中更加高效。但优化是基于JVM和硬件平台的，因此在不同的环境中表现可能会有所不同。

### 优缺点

<font color='Apricot'>优点：</font>

1. 简单易用：synchronized关键字是Java语言提供的内置锁，使用简单且方便，不需要显式地创建锁对象或调用锁相关的方法。
1. 调试方便：隐式锁是Java语言提供的原生锁，可以方便地在代码中添加调试信息或日志，便于排查并发问题。
1. 支持可重入：隐式锁支持线程对同一把锁的重入，不会导致死锁。
1. 支持自动释放：隐式锁在同步代码块执行完成或异常退出时会自动释放锁，不需要手动释放。

<font color='Apricot'>缺点：</font>

1. 非公平性：隐式锁默认是非公平锁，可能导致某些线程长时间无法获取锁，从而影响系统的性能。
1. 粒度较大：隐式锁的粒度较大，可能导致多个线程之间无法并发执行，从而降低系统的吞吐量。
1. 锁的限制：隐式锁只能修饰方法、实例对象或类对象，无法对其他对象进行同步控制.

## ReentrantLock

显式锁是通过`Lock`接口及其实现类来实现的，相比隐式锁有这些优点：

1. 公平性：与隐式锁不同，显式锁可以支持公平性，即按照线程的请求顺序来获取锁，避免某些线程长时间无法获取锁的问题。
2. 粒度可控：显式锁可以通过 `lock()` 和 `unlock()` 方法手动控制锁的获取和释放，从而可以更精细地控制锁的粒度，避免粒度过大或过小的问题。
3. 可中断：显式锁提供了可以中断等待锁的机制，通过 `lockInterruptibly()` 方法可以在等待锁的过程中响应中断，从而避免线程长时间阻塞。
4. 支持多条件：显式锁可以通过 `Condition` 对象支持多条件的等待和唤醒，从而可以实现更复杂的线程协作机制。
5. 高性能：显式锁在某些情况下可以比隐式锁具有更好的性能，因为它提供了更多的优化选项，如可重入锁、读写锁等。

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
public class LockExample {
    private Lock lock = new ReentrantLock(); // 创建显式锁

    public void doSomething() {
        lock.lock(); // 获取锁
        try {
            // 执行需要同步的代码
        } finally {
            lock.unlock(); // 释放锁
        }
    }
}
```

### 公平锁与非公平锁

`ReentrantLock `构造函数传`true`表示公平锁。

公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的顺序。

非公平锁就是一种锁的抢占机制，是随机获得锁的，可能会导致某些线程一致拿不到锁，所以是不公平的。

###  注意点

1. `ReentrantLock`使用`lock`和`unlock`来获得锁和释放锁
2. `unlock`要放在`finally`中，这样正常运行或者异常都会释放锁
3. 使用`condition`的`await`和`signal`方法之前，必须调用`lock`方法获得对象监视器

### 可重入性实现

`ReentrantLock` 内部自定义了同步器 `Sync`(`Sync` 既实现了 `AQS`， 又实现了 `AOS`，而 `AOS` 提供了一种互斥锁持有的方式)，其实就是加锁的时候通过 `CAS` 算法，将线程对象放到一个双向链表中，每次获取锁的时候，看下当前维护的那个线程 `ID` 和当前请求的线程 `ID` 是否一样，一样就可重入了。

## 比较：

> **1. 锁的实现**：`synchronized` 是 `JVM` 实现的，而 `ReentrantLock` 是 `JDK` 实现的。
>
> **2. 性能**：新版本 `Java` 对 `synchronized` 进行了很多优化，例如自旋锁等，`synchronized` 与 `ReentrantLock` 大致相同。
>
> **3. 等待可中断**：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。`ReentrantLock` 可中断，而 `synchronized` 不行。
>
> **4. 公平锁**：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。`synchronized` 中的锁是非公平的，`ReentrantLock` 默认构造函数创建的是非公平锁，可以通过参数 `true` 设为公平锁，但公平锁性能不是很好。
>
> **5. 锁绑定多个条件**：一个 `ReentrantLock` 可以同时绑定多个 `Condition` 对象。

### 使用选择

除非需要使用 `ReentrantLock` 的高级功能，否则优先使用 `synchronized`。这是因为 `synchronized` 是 `JVM` 实现的一种锁机制，`JVM` 原生地支持它，而 `ReentrantLock` 不是所有的 `JDK` 版本都支持。并且使用 `synchronized` 不用担心没有释放锁而导致死锁问题，因为 `JVM` 会确保锁的释放。

#乐观锁与悲观锁

### 乐观锁

- **基本思想：** 乐观锁假设并发冲突不经常发生，因此不会立即加锁，而是在更新数据之前检查是否被其他线程修改过。
- **实现方式：** 通常使用版本号（Versioning）或时间戳（Timestamp）等机制来检测数据是否被修改，比如CAS（Compare and Swap）操作。
- **特点：** 乐观锁不会阻塞其他线程，当检测到冲突时，会进行回滚或重试，适用于读操作频繁、写操作较少的场景，减少了锁的竞争和开销。

**版本号方式**：一般是在数据表中加上一个数据版本号`version`字段，表示数据被修改的次数，当数据被修改时，`version`值会加一。当线程`A`要更新数据值时，在读取数据的同时也会读取`version`值，在提交更新时，若刚才读取到的`version`值为当前数据库中的`version`值相等时才更新，否则重试更新操作，直到更新成功。

**CAS操作方式：**即`compare and swap` （比较与交换），涉及到三个操作数，数据所在的内存值，预期值，新值。当需要更新时，判断当前内存值与之前取到的预期值是否相等，若相等，则用新值更新，若失败则重试，一般情况下是一个自旋操作，即不断的重试。

### 悲观锁

- 基本思想： 悲观锁认为在并发情况下会发生竞争，因此每次访问前都会先加锁，防止其他线程同时修改数据。
- 实现方式： 通过使用互斥锁（例如 `synchronized` 关键字、`ReentrantLock` 等）来保护共享资源，确保在任何时候只有一个线程能够访问资源。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。在`Java`中，`synchronized`的思想也是悲观锁。
- 特点： 悲观锁可能会导致多个线程等待锁释放，效率较低，但适用于写操作频繁的场景。

### 使用场景：

- 悲观锁适合写操作频繁的场景，因为它会阻塞其他线程，保证数据的一致性。
- 乐观锁适合读操作频繁、写操作较少的场景，因为它不会阻塞其他线程，只在发生冲突时进行回滚或重试，提高了并发性能。



# 锁优化

这里的锁优化主要是指 JVM 对 synchronized 的优化。

### 自旋锁

互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。

自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。

在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。

### 锁消除

锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。

锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。

对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：

```java
public static String concatString(String s1, String s2, String s3) {
    return s1 + s2 + s3;
}
```

String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：

```java
public static String concatString(String s1, String s2, String s3) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。

### 锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。

上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。

### 轻量级锁

JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。

以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。

[<img src="https://gitee.com/qc_faith/picture/raw/master/image/202212131737094.png" alt="img" style="zoom:67%;" />](https://camo.githubusercontent.com/244b36284e8af2b9991999bc998ce6ec787bc1d606d02fb3c480c078830af57e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62623661343962652d303066322d346632372d613063652d3465643736346263363035632e706e67)

轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。

如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。

### 偏向锁

偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。

当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。

当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

[<img src="https://gitee.com/qc_faith/picture/raw/master/image/202212131737412.jpeg" alt="img" style="zoom: 33%;" />](https://camo.githubusercontent.com/95d0ad9a48474178e9ab5fcfc994d768a904d1e53fce6c144a58340a6f71dc22/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33393063393133622d356633312d343434662d626264622d3262383862363838653763652e6a7067)



- 偏向锁(Biased Locking)
- 轻量级锁
- 重量级锁

这三种锁使得 JDK 得以优化 Synchronized 的运行，当 JVM 检测 到不同的竞争状况时，会自动切换到适合的锁实现，这就是锁的升级、 降级。

- 当没有竞争出现时，默认会使用偏向锁。JVM 会利用 CAS 操作，在对象头上的 Mark Word 部分设置线程ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁，因 为在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定， 使用偏斜锁可以降低无竞争开销。
- 如果有另一线程试图锁定某个被偏斜过的对象，JVM 就撤销偏斜锁， 切换到轻量级锁实现。
- 轻量级锁依赖 CAS 操作 Mark Word 来试图获取锁，如果重试成功， 就使用普通的轻量级锁;否则，进一步升级为重量级锁。

## 多线程开发良好的实践

- 给线程起个有意义的名字，这样可以方便找 Bug。
- 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。
- 多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。
- 使用 BlockingQueue 实现生产者消费者问题。
- 多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。
- 使用本地变量和不可变类来保证线程安全。
- 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。

## 总结

1. 当只有一个线程写，其它线程都是读的时候，可以用 `volatile `修饰变量

2. 当多个线程写，那么一般情况下并发不严重的话可以用 `Synchronized `，`Synchronized`并不是一开始就是重量级锁，在并发不严重的时候，比如只有一个线程访问的时候，是偏向锁；当多个线程访问，但不是同时访问，这时候锁升级为轻量级锁；当多个线程同时访问，这时候升级为重量级锁。所以在并发不是很严重的情况下，使用`Synchronized`是可以的。不过`Synchronized`有局限性，比如不能设置锁超时，不能通过代码释放锁。

3. `ReentranLock `可以通过代码释放锁，可以设置锁超时。

4. 高并发下，`Synchronized`、`ReentranLock `效率低，因为同一时刻只有一个线程能进入同步代码块，如果同时有很多线程访问，那么其它线程就都在等待锁。这个时候可以使用并发包下的数据结构，例如 `ConcurrentHashMap ， LinkBlockingQueue `，以及原子性的数据结构如： `AtomicInteger `。

# 线程安全及实现方式

线程安全问题通常出现在多个线程同时访问和修改共享数据时。这些问题可能导致数据不一致、意外行为或程序崩溃等情况。一些常见的线程安全问题包括：

1. **竞态条件（Race Condition）：** 当多个线程试图同时访问和操作共享数据，且最终结果取决于线程执行顺序时，就会出现竞态条件。
2. **数据竞争（Data Race）：** 多个线程同时修改共享数据而没有同步机制，导致未定义的行为。

### 不可变

不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。

不可变的类型：

- final 关键字修饰的基本数据类型
- String
- 枚举类型
- Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。

对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。

```java
public class ImmutableExample {
    public static void main(String[] args) {
        Map<String, Integer> map = new HashMap<>();
        Map<String, Integer> unmodifiableMap = Collections.unmodifiableMap(map);
        unmodifiableMap.put("a", 1);
    }
}
Exception in thread "main" java.lang.UnsupportedOperationException
    at java.util.Collections$UnmodifiableMap.put(Collections.java:1457)
    at ImmutableExample.main(ImmutableExample.java:9)
```

Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。

```java
public V put(K key, V value) {
    throw new UnsupportedOperationException();
}
```

### 互斥同步

synchronized 和 ReentrantLock。

互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。

互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

### 非阻塞同步

随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。

#### 1. CAS

`CAS` （比较与交换，==Compare and swap==） 是一种有名的**无锁算法**，是乐观锁的一种实现方式，是一种轻量级锁，`JUC `中很多工具类的实现就是基于 `CAS `的。

`CAS`有**`3`个**操作数

- ==**内存值 V**==
- ==**旧的预期值 A**==
- ==**要修改的新值 B**==

<span style="color:red">当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B ，否则什么都不做</span>

#### 2. AtomicInteger

J.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。

以下代码使用了 AtomicInteger 执行了自增的操作。

```java
private AtomicInteger cnt = new AtomicInteger();

public void add() {
    cnt.incrementAndGet();
}
```

以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。

```java
public final int incrementAndGet() {
    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
}
```

以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。

可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。

```java
public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

    return var5;
}
```

#### 3. ABA

如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。

J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。

### 无同步方案

要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。

#### 1. 栈封闭

多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。

```java
public class StackClosedExample {
    public void add100() {
        int cnt = 0;
        for (int i = 0; i < 100; i++) {
            cnt++;
        }
        System.out.println(cnt);
    }
}
public static void main(String[] args) {
    StackClosedExample example = new StackClosedExample();
    ExecutorService executorService = Executors.newCachedThreadPool();
    executorService.execute(() -> example.add100());
    executorService.execute(() -> example.add100());
    executorService.shutdown();
}
100
100
```

#### 2. 线程本地存储（Thread Local Storage）

如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。

符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。

可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。

对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。

```java
public class ThreadLocalExample {
    public static void main(String[] args) {
        ThreadLocal threadLocal = new ThreadLocal();
        Thread thread1 = new Thread(() -> {
            threadLocal.set(1);
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(threadLocal.get());
            threadLocal.remove();
        });
        Thread thread2 = new Thread(() -> {
            threadLocal.set(2);
            threadLocal.remove();
        });
        thread1.start();
        thread2.start();
    }
}
1
```

为了理解 ThreadLocal，先看以下代码：

```java
public class ThreadLocalExample1 {
    public static void main(String[] args) {
        ThreadLocal threadLocal1 = new ThreadLocal();
        ThreadLocal threadLocal2 = new ThreadLocal();
        Thread thread1 = new Thread(() -> {
            threadLocal1.set(1);
            threadLocal2.set(1);
        });
        Thread thread2 = new Thread(() -> {
            threadLocal1.set(2);
            threadLocal2.set(2);
        });
        thread1.start();
        thread2.start();
    }
}
```

每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。

```java
/* ThreadLocal values pertaining to this thread. This map is maintained
 * by the ThreadLocal class. */
ThreadLocal.ThreadLocalMap threadLocals = null;
```

当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal->value 键值对插入到该 Map 中。

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
```

get() 方法类似。

```java
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}
```

ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。

在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。

#### 3. 可重入代码（Reentrant Code）

这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。

可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。
