# 常用的集合

`Map`接口和`Collection`接口是所有集合框架的父接口：

`Collection`集合主要有`List`和`Set`两大接口

- `List`：一个==有序==（元素存入集合的顺序和取出的顺序一致）容器，元素==可以重复==，可以插入==多个`null`==元素，元素都有索引。
  - 常用的实现类有 `ArrayList、LinkedList 和 Vector`。
- `Set`：一个==无序==（存入和取出顺序有可能不一致）容器，==不可以存储重复元素==，只允许存入==一个`null`==元素，必须保证元素唯一性。
  - 常用实现类是` HashSet、LinkedHashSet 以及 TreeSet`。

`Map`是一个键值对集合，存储键、值和之间的映射。 `Key`无序，唯一；`value `不要求有序，允许重复。从`Map`集合中检索元素时，只要给出键对象，就会返回对应的值对象。

1. `Map`不是`collection`的子接口或者实现类。`Map`是一个接口。

2. `Map` 的 每个 `Entry` 都持有两个对象，一个键一个值，`Map` 可能会持有相同的值对象但键对象必须是唯一的。

3. `TreeMap` 也通过 `Comparator` 或者 `Comparable` 维护了一个排序顺序。

4. `Map` 里可以有随意个 `null` 值但最多只能有一个 `null` 键。

- 常用实现类：`HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap`

# List

> `List`在`Java`里边是一个接口，常见的实现类如下：
>
> （1）`ArrayList`：数组实现，查询快，增删慢，轻量级；(线程不安全)
> （2）`LinkedList`：双向链表实现，增删快，查询慢 (线程不安全)
> （3）`Vector`：数组实现，重量级 (线程安全、使用少)
>
> 在开发中用得最多的是`ArrayList`，这是**由底层的数据结构**来决定的，在日常开发中，遍历的需求比增删要多，即便是增删也是往往在`List`的尾部添加就OK了。像在尾部添加元素，`ArrayList`的时间复杂度也就`O(1)`，所以在开发中用得最多
>
> `ArrayList`的底层数据结构是==数组==，`LinkedList`底层数据结构是==链表==。

> 如果是**集合类型**，有List和Set供我们选择。`List`的特点是**插入有序，元素可重复**。`Set`的特点是**插入无序，元素不可重复**。至于选择哪个实现类来作为我们的存储容器，我们就得看具体的应用场景。是希望可重复的就得用`List`，选择`List`下常见的子类。是希望不可重复，选择`Set`下常见的子类。
>
> 如果是`Key-Value`型，那我们会选择`Map`。如果要保持插入顺序的，我们可以选择`LinkedHashMap`，如果不需要则选择`HashMap`，如果要排序则选择`TreeMap`。

## 遍历list

1.`for`循环，指定下标长度，使用`List`集合的`size()`方法，进行`for`循环遍历

2.使用`foreach`遍历`List`，但不能对某一个元素进行操作（这种方法在遍历数组和`Map`集合的时候同样适用）

3.适用迭代器`Iterator`遍历：直接根据`List`集合的自动遍历

## ArrayList

1. **我们本身就有数组了，为什么要用`ArrayList`呢**

原生的数组会有一个特点：在使用的时候必须要为它创建大小，而`ArrayList`不用。

2. **为什么`ArrayList`不用创建大小**

源码表明，当我们`new ArrayList()`的时候，默认会有一个空的`Object`数组，大小为`0`。当我们**第一次**`add`添加数据的时候，会给这个数组初始化一个大小，这个大小默认值为`10`，数组的大小是固定的，而`ArrayList`的大小是可变的。

3. **怎么理解固定和可变？**

假设我们给定数组的大小是`10`，要往这个数组里边填充元素，我们只能添加`10`个元素。而`ArrayList`不一样，因为`ArrayList`是实现了动态扩容的，`ArrayList`在使用的时候可以往里边添加`20`个，`30`个，甚至更多的元素。

4. **怎么实现动态扩容的？**

使用`ArrayList`在每一次`add`的时候，它都会先去计算这个数组的空间够不够，如果空间足够，那直接追加上去。如果不够，那就得扩容。

5. **那怎么扩容？一次扩多少**

在源码里边，有个`grow`方法，每一次扩原来的`1.5`倍。比如说，初始化的值是10嘛。现在我第11个元素要进来了，发现这个数组的空间不够了，所以会扩到15，空间扩完容之后，会调用`arraycopy`来对数组进行拷贝。另外，`ArrayList`的增删底层调用的`copyOf()`被优化过，现代`CPU`对内存可以**块操作**，`ArrayList`的增删一点儿也不会比`LinkedList`慢。



### 详解

1. `get(int index)` 方法的时间复杂度为 O(1)，因为是直接从底层数组根据下标获取的，和数组长度无关。

   ~~~java
   public E get(int index) {
       Objects.checkIndex(index, size);
       return elementData(index);
   }
   ~~~

2. `add(E e)` 方法会默认将元素添加到数组末尾，但需要考虑到数组扩容的情况，如果不需要扩容，时间复杂度为 O(1)。

   ~~~java
   public boolean add(E e) {
       modCount++;
       add(e, elementData, size);
       return true;
   }
   
   private void add(E e, Object[] elementData, int s) {
       if (s == elementData.length)
           elementData = grow();
       elementData[s] = e;
       size = s + 1;
   }
   ~~~

   如果需要扩容的话，并且不是第一次（`oldCapacity > 0`）扩容的时候，**内部执行的 `Arrays.copyOf()` 方法是耗时的关键**，需要把原有数组中的元素复制到扩容后的新数组当中。

   ~~~java
   private Object[] grow(int minCapacity) {
       int oldCapacity = elementData.length;
       if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
           int newCapacity = ArraysSupport.newLength(oldCapacity,
                   minCapacity - oldCapacity, /* minimum growth */
                   oldCapacity >> 1           /* preferred growth */);
           return elementData = Arrays.copyOf(elementData, newCapacity);
       } else {
           return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];
       }
   }
   ~~~

3. `add(int index, E element)` 方法将新的元素插入到指定的位置，考虑到需要复制底层数组（根据之前的判断，扩容的话，数组可能要复制一次），根据最坏的打算（不管需要不需要扩容，`System.arraycopy()` 肯定要执行），所以时间复杂度为 O(n)。在数组中插入元素的时候，会把插入位置以后的元素依次往后复制

   ~~~java
   public void add(int index, E element) {
       rangeCheckForAdd(index);
       modCount++;
       final int s;
       Object[] elementData;
       if ((s = size) == (elementData = this.elementData).length)
           elementData = grow();
       System.arraycopy(elementData, index,
               elementData, index + 1,
               s - index);
       elementData[index] = element;
       size = s + 1;
   }
   ~~~

4. `remove(int index)` 方法将指定位置上的元素删除，考虑到需要复制底层数组，所以时间复杂度为 O(n)。

   ~~~java
   public E remove(int index) {
       Objects.checkIndex(index, size);
       final Object[] es = elementData;
   
       @SuppressWarnings("unchecked") E oldValue = (E) es[index];
       fastRemove(es, index);
   
       return oldValue;
   }
   private void fastRemove(Object[] es, int i) {
       modCount++;
       final int newSize;
       if ((newSize = size - 1) > i)
           System.arraycopy(es, i + 1, es, i, newSize - i);
       es[size = newSize] = null;
   }
   ~~~

### 与LinkedList相比：

> `ArrayList`的增删**未必**就是比`LinkedList`要慢。

- 如果增删都是在**末尾**来操作【每次调用的都是remove()和add()】，此时`ArrayList`就不需要移动和复制数组来进行操作了。如果数据量有百万级的时，**速度是会比`LinkedList`要快的**。
- 如果**删除操作**的位置是在**中间**。由于`LinkedList`的消耗主要是在遍历上，`ArrayList`的消耗主要是在移动和复制上(底层调用的是`arraycopy()`方法，是`native`方法)。
  - `LinkedList`的遍历速度是要慢于`ArrayList`的复制移动速度的
  - 如果数据量有百万级的时，**还是`ArrayList`要快**。

#### 插入

##### 头插

==`LinkedList > ArrayList`==

1. `ArrayList `头插时，需要把数组元素通过`Arrays.copyOf`的方式把数组元素移位，如果容量不足还需要扩容。

2. `LinkedList `头插时，则不需要考虑扩容以及移位问题，直接把元素定位到首位，接点链条链接上即可。

   ![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928170956.png)

   分别验证，10万、100万、1000万的数据量，在头插时的一个耗时情况：`ArrayList`需要做大量的位移和复制操作，而`LinkedList`的耗时只是在于实例化一个Node（插入时候会创建新的节点元素，`new Node<>(null, e, f)`）对象。

##### 尾插

==`ArrayList > LinkedList`==

1. `ArrayList `尾插时，是不需要数据位移的，比较耗时的是数据的扩容时，需要拷贝迁移。

2. `LinkedList `尾插时，与头插相比耗时点会在对象的实例化上

   ![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928170915.png)

   分别验证，10万、100万、1000万的数据量，在尾插时的一个耗时情况：`ArrayList` 不需要做位移拷贝也就不那么耗时了，而`LinkedList`则需要创建大量的对象。*所以这里`ArrayList`尾插的效果更好一些。*

##### 中间插

==`ArrayList > LinkedList`==

1. `ArrayList `中间插入，首先我们知道他的定位时间复杂度是O(1)，比较耗时的点在于数据迁移和容量不足的时候扩容。

2. `LinkedList `中间插入，链表的数据实际插入时候并不会怎么耗时，但是它定位的元素（需要进行遍历）的时间复杂度是O(n)，所以这部分以及元素的实例化比较耗时。

   ![img](https://bugstack.cn/assets/images/2020/interview/interview-9-10.png)

   分别验证，10万、100万、1000万的数据量，在中间插时的一个耗时情况：`Linkedlist`在中间插入时，遍历寻找插入位置非常耗时。

#### 删除

与`ArrayList`不同，`LinkedList`删除不需要拷贝元素，只需找到元素位置，把元素前后链连接上

![img](https://gitee.com/qc_faith/picture/raw/master/image/20220928171904.png)

- 确定出要删除的元素 x，把前后的链接进行替换。
- 如果是删除首尾元素，操作起来会更加容易，这也就是为什么说插入和删除快。但中间位置删除，需要遍历找到对应位置



##Vector

1. **Vector**

`Vector`底层结构是==数组==，现在已经很少用了，被`ArrayList`替代，原因有两个：

- `Vector`所有方法都是同步，**有性能损失**。

- `Vector`初始`length`是`10 `超过`length`时 以`100%`比率增长，**相比于`ArrayList`更多消耗内存**。

相对于`ArrayList`，它是==线程安全==的，在扩容的时候它是直接==扩容两倍==的，比如现在有`10`个元素，要扩容的时候，就会将数组的大小增长到`20`。

- 

## 线程安全List

2. **除了Vector，线程安全的List还有什么？**

首先，可以用`Collections`将`ArrayList`包装一下，变成线程安全。除此之外，在`java.util.concurrent`包下还有一个类，叫做`CopyOnWriteArrayList`。

>讲`CopyOnWriteArrayList`之前，先说说`copy-on-write`这个意思，下面简称为`cow`。比如说在Linux中，我们知道所有的进程都是`init`进程`fork`出来的，除了进程号之外，`fork`出来的进程，默认跟父进程一模一样的。在`fork`之后`exec`之前，两个进程用的是相同的内存空间的，这意味着子进程的代码段、数据段、堆栈都是**指向**父进程的物理空间。
>
>当父子进程中有更改的行为发生时，再为子进程分配相应物理空间。这样做的好处就是，等到真正发生修改的时候，才去分配资源，可以减少分配或者复制大量资源时带来的**瞬间延时**。简单来说，就可以理解为我们的懒加载，或者说单例模式的懒汉式。等真正用到的时候再分配。
>
>在文件系统中，其实也有`cow`的机制。文件系统的`cow`就是在修改数据的时候，不会直接在原来的数据位置上进行操作，而是重新找个位置修改。比如说：要修改数据块`A`的内容，先把`A`读出来，写到`B`块里面去。如果这时候断电了，原来`A`的内容还在。这样做的好处就是可以保证数据的完整性，瞬间挂掉了容易**恢复**

`CopyOnWriteArrayList`是一个线程安全的`List`，底层是通过**复制数组**的方式来实现的。

首先关于它的`add()`方法的实现，在`add()`方法他会加`lock`锁，然后会复制出一个新的数组，往新的数组里边`add`真正的元素，最后把`array`的指向改变为新的数组，其实`get()`方法又或是`size()`方法只是获取`array`所指向的数组的元素或者大小。读不加锁，写加锁，可以发现的是，`CopyOnWriteArrayList`跟文件系统的`COW`机制是很像的

3. **CopyOnWriteArrayList有什么缺点**

<span style="color:red">很耗费内存</span>：每次`set()/add()`都会复制一个数组出来。

<span style="color:red">只能保证数据的**最终一致性，不能保证数据的实时一致性**</span>：假设两个线程，线程`A`去读取`CopyOnWriteArrayList`的数据，还没读完，现在线程`B`把这个`List`给清空了，线程`A`此时还是可以把剩余的数据给读出来。

## LinkedList

`LinkedList`既是`List`的实现类，也是`Queue`的实现类，所以`LinkedList`也可以当作队列使用 ，底层是**双向链表**（方便实现往前遍历）。

 `LinkedList `还实现了 `Deque `这个队列接口，可以作为双向队列的实现。

 `LinkedList `实现了一个倒序迭代器 `DescendingIterator`，游标直接在迭代器尾部，实际是向前遍历；还实现了一个 `ListIterator `，名叫 `ListItr`，`ListItr`操作基本都是调用的内部关键方法

`LinkedList `的迭代器都是` fail-fast` 的: 如果在并发环境下，其他线程使用迭代器以外的方法修改数据，会导致 `ConcurrentModificationException`.

特点：

- 基于双端链表，添加/删除元素只会影响周围的两个节点，开销很低；
- 只能顺序遍历，无法按照索引获得元素，因此查询效率不高；
- 没有固定容量，不需要扩容；
- 需要更多的内存，每个节点中需要多存储前后节点的信息，占用空间更多些。

`LinkedList `==访问元素==时一般是通过 循环遍历获取到这个元素所在位置，然后返回这个元素，时间复杂度为 `O(n)`。删除或者插入一个给定指针指向的结点（例如头尾节点）时间复杂度为` O(1)`，否则为`O(n)`。

### 适用场景

在集合的==首位==有大量的插入、删除以及获取操作，那么可以使用`LinkedList`，因为它都有相应的方法；`addFirst`、`addLast`、`removeFirst`、`removeLast`、`getFirst`、`getLast`，这些操作的时间复杂度都是O(1)，非常高效。

### 详解

1. `get(int index)` 方法的时间复杂度为 O(n)，因为需要循环遍历整个链表。

   ~~~java
   public E get(int index) {
       checkElementIndex(index);
       return node(index).item;
   }
   
   LinkedList.Node<E> node(int index) {
       // assert isElementIndex(index);
   
       if (index < (size >> 1)) {
           LinkedList.Node<E> x = first;
           for (int i = 0; i < index; i++)
               x = x.next;
           return x;
       } else {
           LinkedList.Node<E> x = last;
           for (int i = size - 1; i > index; i--)
               x = x.prev;
           return x;
       }
   }
   ~~~

   下标小于链表长度的一半时，从前往后遍历；否则从后往前遍历，这样从理论上说，就节省了一半的时间。

   如果下标为 0 或者 `list.size() - 1` 的话，时间复杂度为 O(1)。这种情况下，可以使用 `getFirst()` 和 `getLast()` 方法。

   ~~~java
   public E getFirst() {
       final LinkedList.Node<E> f = first;
       if (f == null)
           throw new NoSuchElementException();
       return f.item;
   }
   
   public E getLast() {
       final LinkedList.Node<E> l = last;
       if (l == null)
           throw new NoSuchElementException();
       return l.item;
   }
   ~~~

   first 和 last 在链表中是直接存储的，所以时间复杂度为 O(1)。

2. `add(E e)` 方法默认将元素添加到链表末尾，所以时间复杂度为 O(1)。

   ~~~java
   public boolean add(E e) {
       linkLast(e);
       return true;
   }
   void linkLast(E e) {
       final LinkedList.Node<E> l = last;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(l, e, null);
       last = newNode;
       if (l == null)
           first = newNode;
       else
           l.next = newNode;
       size++;
       modCount++;
   }
   ~~~

3. `add(int index, E element)` 方法将新的元素插入到指定的位置，需要先通过遍历查找这个元素，然后再进行插入，所以时间复杂度为 O(n)。

   ~~~java
   public void add(int index, E element) {
       checkPositionIndex(index);
   
       if (index == size)
           linkLast(element);
       else
           linkBefore(element, node(index));
   }
   ~~~

   如果下标为 0 或者 `list.size() - 1` 的话，时间复杂度为 O(1)。这种情况下，可以使用 `addFirst()` 和 `addLast()` 方法。

   ~~~java
   public void addFirst(E e) {
       linkFirst(e);
   }
   private void linkFirst(E e) {
       final LinkedList.Node<E> f = first;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(null, e, f);
       first = newNode;
       if (f == null)
           last = newNode;
       else
           f.prev = newNode;
       size++;
       modCount++;
   }
   ~~~

   `linkFirst()` 只需要对 first 进行更新即可。

   ~~~java
   public void addLast(E e) {
       linkLast(e);
   }
   
   void linkLast(E e) {
       final LinkedList.Node<E> l = last;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(l, e, null);
       last = newNode;
       if (l == null)
           first = newNode;
       else
           l.next = newNode;
       size++;
       modCount++;
   }
   ~~~

   `linkLast()` 只需要对 last 进行更新即可。

   需要注意的是，有些文章里面说，LinkedList 插入元素的时间复杂度近似 O(1)，其实是有问题的，因为 `add(int index, E element)` 方法在插入元素的时候会调用 `node(index)` 查找元素，该方法之前我们之间已经确认过了，时间复杂度为 O(n)，即便随后调用 `linkBefore()` 方法进行插入的时间复杂度为 O(1)，总体上的时间复杂度仍然为 O(n) 才对。

   ~~~java
   void linkBefore(E e, LinkedList.Node<E> succ) {
       // assert succ != null;
       final LinkedList.Node<E> pred = succ.prev;
       final LinkedList.Node<E> newNode = new LinkedList.Node<>(pred, e, succ);
       succ.prev = newNode;
       if (pred == null)
           first = newNode;
       else
           pred.next = newNode;
       size++;
       modCount++;
   }
   ~~~

4. `remove(int index)` 方法将指定位置上的元素删除，考虑到需要调用 `node(index)` 方法查找元素，所以时间复杂度为 O(n)。

   ~~~java
   public E remove(int index) {
       checkElementIndex(index);
       return unlink(node(index));
   }
   
   E unlink(LinkedList.Node<E> x) {
       // assert x != null;
       final E element = x.item;
       final LinkedList.Node<E> next = x.next;
       final LinkedList.Node<E> prev = x.prev;
       if (prev == null) {
           first = next;
       } else {
           prev.next = next;
           x.prev = null;
       }
       if (next == null) {
           last = prev;
       } else {
           next.prev = prev;
           x.next = null;
       }
       x.item = null;
       size--;
       modCount++;
       return element;
   }
   ~~~



## CopyOnWriteArrayList(Set)

`CopyOnWriteArrayList`是同步`List`的替代品，`CopyOnWriteArraySet`是同步`Set`的替代品。

无论是`Hashtable-->ConcurrentHashMap`，还是说`Vector-->CopyOnWriteArrayList`。`JUC`下支持并发的容器与老一代的线程安全类相比，总结起来就是加锁==**粒度**==的问题

- `Hashtable、Vector`加锁的粒度大(直接在方法声明处使用`synchronized`)
- `ConcurrentHashMap、CopyOnWriteArrayList`加锁粒度小(用各种的方式来实现线程安全，比如我们知道的`ConcurrentHashMap`用了`CAS`锁、`volatile`等方式来实现线程安全..)
- `JUC`下的线程安全容器在遍历的时候**不会**抛出`ConcurrentModificationException`异常

所以一般来说，我们都会**使用JUC包下给我们提供的线程安全容器**，而不是使用老一代的线程安全容器。

下面我们来看看`CopyOnWriteArrayList`是怎么实现的，为什么使用**迭代器遍历**的时候就**不用额外加锁**，也不会抛出`ConcurrentModificationException`异常。

回顾一下`COW`：

> 如果有多个调用者（`callers`）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取**相同的指针指向相同的资源**，直到某个调用者**试图修改**资源的内容时，系统才会**真正复制一份专用副本**（`private copy`）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。**优点**是如果调用者**没有修改该资源，就不会有副本**（`private copy`）被建立，因此多个调用者只是读取操作时可以**共享同一份资源**。

- `CopyOnWriteArrayList`是线程安全容器(相对于`ArrayList`)，底层通过**复制数组**的方式来实现。
- `CopyOnWriteArrayList`在遍历的使用不会抛出`ConcurrentModificationException`异常，并且遍历的时候就不用额外加锁
- 元素可以为`null`

### CopyOnWriteArrayList基本结构

``` JAVA
 /** 可重入锁对象 */
    final transient ReentrantLock lock = new ReentrantLock();

    /** CopyOnWriteArrayList底层由数组实现，volatile修饰 */
    private transient volatile Object[] array;

    /**
     * 得到数组
     */
    final Object[] getArray() {
        return array;
    }

    /**
     * 设置数组
     */
    final void setArray(Object[] a) {
        array = a;
    }

    /**
     * 初始化CopyOnWriteArrayList相当于初始化数组
     */
    public CopyOnWriteArrayList() {
        setArray(new Object[0]);
    }
```

`CopyOnWriteArrayList`底层就是数组，加锁就交由`ReentrantLock`来完成。

如果遍历`Vector/SynchronizedList`是需要自己手动加锁的。

`CopyOnWriteArrayList`使用迭代器遍历时不需要显示加锁。

- **在修改时，复制出一个新数组，修改的操作在新数组中完成，最后将新数组交由array变量指向**。
- **写加锁，读不加锁**

`CopyOnWriteArrayList`在使用迭代器遍历的时候，操作的都是**原数组**（所以遍历时得到的是“旧”数据）！所以能够在容器遍历的时候对其进行修改而不抛出异常

``` java
  // 1. 返回的迭代器是COWIterator
  public Iterator<E> iterator() {
        return new COWIterator<E>(getArray(), 0);
    }

  // 2. 迭代器的成员属性
    private final Object[] snapshot;
    private int cursor;

  // 3. 迭代器的构造方法
  private COWIterator(Object[] elements, int initialCursor) {
        cursor = initialCursor;
        snapshot = elements;
    }

  // 4. 迭代器的方法...
  public E next() {
        if (! hasNext())
            throw new NoSuchElementException();
        return (E) snapshot[cursor++];
    }

  //.... 可以发现的是，迭代器所有的操作都基于snapshot数组，而snapshot是传递进来的array数组

```

### CopyOnWriteArrayList缺点

- **内存占用**：如果`CopyOnWriteArrayList`经常要增删改里面的数据，经常要执行`add()、set()、remove()`的话，那是比较耗费内存的。
  - 因为我们知道每次`add()、set()、remove()`这些增删改操作都要**复制一个数组**出来。
- **数据一致性**：`CopyOnWrite`容器**只能保证数据的最终一致性，不能保证数据的实时一致性**。
  - 从上面的例子也可以看出来，比如线程`A`在迭代`CopyOnWriteArrayList`容器的数据。线程`B`在线程`A`迭代的间隙中将`CopyOnWriteArrayList`部分的数据修改了(已经调用`setArray()`了)。但是线程`A`迭代出来的是原有的数据。



# Map

> `Map`在`Java`里边是一个接口，常见的实现类有`HashMap`、`LinkedHashMap`、`TreeMap`和`ConcurrentHashMap`
>
> 在`Java`里边，哈希表的结构是`数组+链表`的方式
>
> `HashMap`底层数据机构是`数组+链表/红黑树`
>
> `LinkedHashMap`底层数据结构是`数组+链表+双向链表`
>
> `TreeMap`底层数据结构是红黑树
>
> `ConcurrentHashMap`底层数据结构也是`数组+链表/红黑树`
>
> **`LinkedHashMap `和 `TreeMap`是有序的Map**

## HashMap

1. **当`new`一个HashMap的时候，会发生什么？**

`HashMap`有几个构造方法，但最主要的就是指定初始值大小和负载因子的大小。如果我们不指定，默认`HashMap`的大小为`16`，负载因子的大小为`0.75`

`HashMap`的大小只能是**`2`次幂**的，假设你传一个`10`进去，实际上最终`HashMap`的大小是`16`，你传一个7进去，`HashMap`最终的大小是`8`，具体的实现在`tableSizeFor`可以看到。我们把元素放进`HashMap`的时候，需要算出这个元素所在的位置（hash）。在`HashMap`里用的是**位运算**来代替取模，能够更加**高效**地算出该元素所在的位置。`HashMap`的大小只能是`2`次幂的原因是只有大小为`2`次幂时，**才能合理用位运算替代取模**

而负载因子的大小决定着哈希表的**扩容**和**哈希冲突**。比如默认的`HashMap`大小为`16`，负载因子为`0.75`，这意味着数组最多只能放`12`个元素，一旦超过`12`个元素，哈希表需要扩容。每次`put`元素进去的时候，都会检查`HashMap`的大小有没有超过这个阈值，如果有，就要扩容

`HashMap`的大小只能是`2`次幂，所以扩容的时候时候默认是扩原来的`2`倍。

显然扩容这个操作肯定是耗时的，那我能不能把**负载因子调高**一点，比如我要调至为`1`，那我的`HashMap`就等到`16`个元素的时候才扩容呢。显然是可以的，但是不推荐。负载因子调高了，这意味着**哈希冲突的概率**会增高，哈希冲突概率增高，同样会耗时（因为查找的速度变慢了）”

2. **在 put 元素的时候，传递的 key 是怎样计算哈希值的**

实现就在`hash`方法上，它是先算出正常的哈希值，然后与**高16位**做异或运算，产生最终的哈希值。这样做的好处可以**增加了随机性**，减少了碰撞冲突的可能性。

3. **HashMap 的 put / get 方法的实现**

在**`put`**的时候，首先对`key`做`hash`运算，计算出该`key`所在的`index`。如果没碰撞，直接放到数组中，如果碰撞了，需要判断目前数据结构是链表还是红黑树，根据不同的情况来进行插入。假设`key`是相同的，则替换到原来的值。最后判断哈希表是否满了(当前哈希表大小`*`负载因子），如果满了，则扩容。

在**`get`**的时候，还是对`key`做`hash`运算，计算出该`key`所在的`index`，然后判断是否有`hash`冲突，如果没有直接返回，如果有则判断当前数据结构是链表还是红黑树，分别从不同的数据结构中取出。

4. **在HashMap中，怎样判断一个元素是否相同**

首先会比较`hash`值，随后会用`==`运算符和`equals()`来判断该元素是否相同。说白了就是：如果只有`hash`值相同，那说明该元素哈希冲突了，如果`hash`值和`equals() || ==` 都相同，那说明该元素是同一个。

5. **HashMap 的数据结构是数组 + 链表 / 红黑树，什么情况才会用到红黑树**

当数组的大小大于**`64`**且链表的大小大于**`8`**的时候才会将链表改为红黑树，当红黑树大小为**`6`**时，会退化为链表。这里转红黑树退化为链表的操作主要出于**查询和插入时对性能的考量**。链表查询时间复杂度`O(N)`，插入时间复杂度`O(1)`，红黑树查询和插入时间复杂度`O(logN)`

6. **Java中HashMap的key值要是为类对象则该类需要满足什么条件？**

==**需要同时重写该类的`hashCode()`方法和它的`equals()`方法**。==

- 从源码可以得知，在插入元素的时候是**先算出该对象的`hashCode`**。如果`hashcode`相等话的。那么表明该对象是存储在同一个位置上的。
- 如果调用`equals()`方法，**两个`key`相同**，则**替换元素**
- 如果调用`equals()`方法，**两个`key`不相同**，则说明该**`hashCode`仅仅是碰巧相同**，此时是散列冲突，将新增的元素放在桶子上

一般来说，我们会认为：**只要两个对象的成员变量的值是相等的，那么我们就认为这两个对象是相等的**！因为，`Object`底层比较的是两个对象的地址，而对我们开发来说这样的意义并不大~这也就为什么我们要重写`equals()`方法

重写了`equals()`方法，就要重写`hashCode()`的方法。因为**`equals()`认定了这两个对象相同**，而**同一个对象调用`hashCode()`方法时**，是应该返回相同的值的！



## HashMap与HashTable

> 从**存储结构**和**实现**来讲基本上都是相同的。它和`HashMap`的最大的不同是==它是线程安全==的，另外它==不允许`key`和`value`为`null`==。`Hashtable`是个过时的集合类，不建议在新代码中使用，不需要线程安全的场合可以用`HashMap`替换，需要线程安全的场合可以用`ConcurrentHashMap`替换

![img](List.assets/162af93a329c3635)



## LinkedHashMap

它**继承**了`HashMap`，在`HashMap`的基础上维护了一个**双向链表** ，有头尾节点，同时`LinkedHashMap`节点`Entry`内部除了继承`HashMap`的`Node`属性，还有`before `和 `after`用于标识前置节点和后置节点。可以实现按插入的顺序或访问顺序排序。

- **底层结构是`数组+链表+双向链表`**

- 允许为null，不同步
- 插入的顺序是有序的(底层链表致使有序)
- 装载因子和初始容量对`LinkedHashMap`影响是很大的~

`LinkedHashMap`在遍历的时候实际用的是双向链表来遍历的，所以`LinkedHashMap`的大小不会影响到遍历的性能。

## TreeMap

`TreeMap`是按照`Key`的自然顺序或者`Comparator`的顺序进行排序，底层数据结构是==红黑树==。所以要么`key`所属的类实现Comparable接口，或者自定义一个实现了`Comparator`接口的比较器，传给`TreeMap`用于`key`的比较。`Comparator`维护了一个变量，**如果该变量为`null`，那么就使用自然顺序**

- `TreeMap`实现了`NavigableMap`接口，而`NavigableMap`接口继承着`SortedMap`接口，致使我们的**`TreeMap`是有序的**！
- `TreeMap`底层是红黑树，它方法的时间复杂度都不会太高:`log(n)`
- `key`不能为`null`，为`null`为抛出`NullPointException`的
- `TreeMap`非同步的，想要同步可以使用`Collections`来进行封装
- 使用`Comparator`或者`Comparable`来比较`key`是否相等与排序的问题

## 线程安全Map

1. 什么是线程安全？

> ==线程安全==就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。
>
> ==线程不安全==就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据

`HashMap`不是线程安全的，在多线程环境下，`HashMap`有可能会有数据丢失和获取不了最新数据的问题，比如说：线程`A` `put`进去了，线程`B` `get`不出来。

**线程安全的Map**

一般在多线程的场景，会使用这几种不同的方式去代替：

- 使用`Collections.synchronizedMap(Map)`创建线程安全的`map`集合；
- `Hashtable`
- `ConcurrentHashMap`

不过因为前两个是直接在外层套`synchronize`，导致线程并发度不高，`ConcurrentHashMap`的性能和效率明显高于前两者。

## ConcurrentHashMap

`ConcurrentHashMap`是线程安全的`Map`实现类，它在`juc`包下的。线程安全的`Map`实现类除了`ConcurrentHashMap`还有`Hashtable`。也可以使用`Collections`来包装出一个线程安全的`Map`。但`Hashtable`和`Collections`包装出来的都比较低效（因为是直接在外层套`synchronize`），所以一般有线程安全问题考量的，都使用`ConcurrentHashMap`”

`ConcurrentHashMap`的底层数据结构是`数组+链表/红黑树`，它能支持高并发的访问和更新，是线程安全的。`ConcurrentHashMap`通过在**部分加锁**和**利用`CAS`算法**来实现同步，在`get`的时候没有加锁，`Node`都用了`volatile`给修饰。在扩容时，会给每个线程分配对应的**区间**，并且为了防止`putVal`导致数据不一致，会给线程的所负责的区间加锁。

## 遍历map

==在遍历前应先检查空引用，防止出现空指针异常`NullPointerException`。==

1. 在`for-each`循环中使用`entries`来遍历

这是最常见且在大多数情况下最可取的遍历方式。**在键值都需要时使用**。

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
 
for (Map.Entry<Integer, Integer> entry : map.entrySet()) {
 
    System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue());
 
}
```

2. 在`for-each`循环中遍历`keys`或`values`。

如果**只需要`map`中的键或者值**，可通过`keySet`或`values`来实现遍历，而不是用`entrySet`。该方法比`entrySet`遍历在性能上稍好（快了10%），而且代码更加干净。

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
 
//遍历map中的键
 
for (Integer key : map.keySet()) {
 
    System.out.println("Key = " + key);
 
}
//遍历map中的值
 
for (Integer value : map.values()) {
 
    System.out.println("Value = " + value);
}
```

3. 使用`Iterator`遍历

使用泛型：

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
 
Iterator<Map.Entry<Integer, Integer>> entries = map.entrySet().iterator();
 
while (entries.hasNext()) {
 
    Map.Entry<Integer, Integer> entry = entries.next();
 
    System.out.println("Key = " + entry.getKey() + ", Value = " + entry.getValue());
 
}
```

不使用泛型：

```java
Map map = new HashMap();
 
Iterator entries = map.entrySet().iterator();
 
while (entries.hasNext()) {
 
    Map.Entry entry = (Map.Entry) entries.next();
 
    Integer key = (Integer)entry.getKey();
 
    Integer value = (Integer)entry.getValue();
 
    System.out.println("Key = " + key + ", Value = " + value);
 
}
```

首先，在老版本`java`中这是惟一遍历`map`的方式。另一个好处是，可以在遍历时调用`iterator.remove()`来删除`entries`，另两个方法则不能。根据`javadoc`的说明，如果在`for-each`遍历中尝试使用此方法，结果是不可预测的。

从性能方面看，该方法类同于`for-each`遍历（方法二）的性能。

4. 通过键找值遍历（效率低）

```java
Map<Integer, Integer> map = new HashMap<Integer, Integer>();
 
for (Integer key : map.keySet()) {
 
    Integer value = map.get(key);
 
    System.out.println("Key = " + key + ", Value = " + value);
 
}
```

作为方法一的替代，这个代码看上去更加干净；但实际上它相当慢且无效率。因为从键取值是耗时的操作（与方法一相比，在不同的`Map`实现中该方法慢了`20%~200%`）。如果你安装了`FindBugs`，它会做出检查并警告你关于哪些是低效率的遍历。所以尽量避免使用。

# Set

> List和Set都是集合，一般来说：**如果我们需要保证集合的元素是唯一的，就应该想到用Set集合**
>
> Set集合实际**大都使用的是Map集合的put方法来添加元素**。

## 遍历set

1.迭代遍历

2.for循环遍历

## HashSet

**特点**

基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的

- 继承于 `AbstractSet `接口，实现了 `Set、Cloneable,、java.io.Serializable` 接口。

- 不保证迭代顺序， 不允许集合中出现重复的值。
- 允许元素为null
- **底层实际上是一个`HashMap`实例**
- 非同步
- 初始容量非常影响迭代性能
- 存储取出都比较快；
- 线程不安全，运行速度快；

`HashSet`实际上就是封装了`HashMap`，**操作`HashSet`元素实际上就是操作`HashMap`**。这也是面向对象的一种体现，**重用性非常高**！

>  `HashSet`是如何判断`Key`是重复的 ？

`HashSet`不能添加重复的元素，当调用`add(Object)`方法时候，首先会调用`Object`的`hashCode`方法判`hashCode`是否已经存在，如不存在则直接插入元素；

如果已存在则调用`Object`对象的`equals`方法判断是否返回`true`，如果为`true`则说明元素已经存在，如为`false`则插入元素。

> `HashSet`里的元素不能重复，在源码(`HashMap`)是这样体现的：

```java
// 1. 如果key 相等  
    if (p.hash == hash &&
        ((k = p.key) == key || (key != null && key.equals(k))))
        e = p;
  // 2. 修改对应的value
     if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
       }
```

添加元素的时候，如果`key`(也对应的`Set`集合的元素)相等，那么则修改`value`值。而在`Set`集合中，`value`值仅仅是一个`Object`对象罢了(**该对象对`Set`本身而言是无用的**)。

也就是说：`Set`集合如果添加的元素相同时，**是根本没有插入的(仅修改了一个无用的`value`值)**！从源码(`HashMap`)中也看出来，**==和equals()方法都有使用**！



## TreeSet

基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。

- 实现`NavigableSet`接口
- 可以实现排序功能
- **底层实际上是一个`TreeMap`实例**
- 不允许元素为null
- 非同步

## LinkedHashSet

具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。

- 迭代是有序的
- 允许为`null`
- **底层实际上是一个`HashMap+双向链表实例`(其实就是`LinkedHashMap`)...**
- 非同步
- 性能比`HashSet`差一丢丢，因为要维护一个双向链表
- 初始容量与迭代无关，`LinkedHashSet`迭代的是双向链表



# 区别

##ArrayList、Vector区别

**共同点：**

- 这两个类都实现了`List`接口，它们都是**有序**的集合(存储有序)，**底层是数组**。我们可以按位置索引号取出某个元素，**允许元素重复和为`null`**。

**区别：**

- **同步性：**
  - `ArrayList`是非同步的
  - `Vector`是同步的
  - 即便需要同步的时候，我们可以使用`Collections`工具类来构建出同步的`ArrayList`而不用`Vector`
- **扩容大小：**
  - `Vector`增长原来的一倍，`ArrayList`增长原来的`0.5`倍



## ArrayList,LinkedList区别

1. `LinkedList`和`ArrayList`的差别主要是由于数据结构的不同。`ArrayList`是基于数组实现的，`LinkedList`是基于双链表实现的。另外`LinkedList`类不仅是`List`接口的实现类，可以根据索引来随机访问集合中的元素，还实现了`Deque`接口，`Deque`接口是`Queue`接口的子接口，它代表一个双向队列，因此`LinkedList`可以作为双向队列 ，栈和`List`集合使用，功能强大。

2. 因为`Array`是基于索引`(index)`的数据结构，它使用索引在数组中搜索和读取数据是很快的，可以直接返回数组中`index`位置的元素，因此在随机访问集合元素上有较好的性能。`Array`获取数据的时间复杂度是`O(1)`,但是要插入、删除数据开销很大，因为这需要移动数组中插入位置之后的的所有元素。

3. 相对于`ArrayList`，`LinkedList`的随机访问集合元素时性能较差，因为需要在双向列表中找到`index`的位置，再返回；但在插入，删除操作是更快的。因为`LinkedList`不需要改变数组的大小，也不需要在数组装满的时候要将所有的数据重新装入一个新的数组，这是`ArrayList`最坏的一种情况，时间复杂度是`O(n)`，而`LinkedList`中插入或删除的时间复杂度仅为`O(1)`。`ArrayList`在插入数据时还需要更新索引（除了插入数组的尾部）。

4. `LinkedList`需要更多的内存，因为`ArrayList`的每个索引的位置是实际的数据，而`LinkedList`中的每个节点中存储的是实际的数据和前后节点的位置。

**使用场景：**

（1）如果==随机访问较多==，`ArrayList`对象要优于`LinkedList`对象；

  ( 2 ) 如果==插入或删除操作较多，随机访问较少==，`LinkedList`对象要优于`ArrayList`对象；

（3）不过`ArrayList`的插入，删除操作也不一定比`LinkedList`慢，如果在靠近末尾的地方插入，那么`ArrayList`只需要移动较少的数据，而`LinkedList`则需要一直查找到列表尾部，反而耗费较多时间，这时`ArrayList`就比`LinkedList`要快。

**存储性能和特性**

`ArrayList`的底层是数组，`LinkedList`的底层是双向链表。

- `ArrayList`它支持以角标位置进行索引出对应的元素(随机访问)，而`LinkedList`则需要遍历整个链表来获取对应的元素。因此**一般来说`ArrayList`的访问速度是要比`LinkedList`要快的**
- `ArrayList`由于是数组，对于删除和修改而言消耗是比较大(复制和移动数组实现)，`LinkedList`是双向链表删除和修改只需要修改对应的指针即可，消耗是很小的。因此**一般来说`LinkedList`的增删速度是要比`ArrayList`要快的**





## HashMap、Hashtable区别

**共同点：**

- 都是基于哈希表实现的，其内部每个元素都是 `key-value` 键值对
- 都实现了` Map、Cloneable、Serializable `接口。

**区别：**

- **线程安全性：**
  
  - `HashMap `不是线程安全的，如果多个外部操作同时修改 `HashMap `的数据结构比如 `add `或者是 `delete`，必须进行同步操作，仅仅对 `key `或者 `value `的修改不是改变数据结构的操作。而 `HashTable `本身就是线程安全的容器。
  
  - 需要线程安全时，可以选择 `Collections.synchronizedMap` 或者是 `ConcurrentHashMap`。[ConcurrentHashMap基于JDK1.8源码剖析](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484161&idx=1&sn=6f52fb1f714f3ffd2f96a5ee4ebab146&chksm=ebd74200dca0cb16288db11f566cb53cafc580e08fe1c570e0200058e78676f527c014ffef41#rd)
  
- **是否允许为`null`：**
  - `HashMap`允许`key `和 `value`为`null`，`HashMap `会把 `Null key` 当做普通的 `key `对待。不允许 `null key` 重复。
  - `Hashtable`不允许`key `和 `value`为`null`
  
- **contains方法**
  - `Hashtable`有`contains`方法
  - `HashMap`把`Hashtable`的`contains`方法去掉了，改成了`containsValue`和`containsKey`
  
- **父类不同：**

  - `HashMap `继承了 `AbstractMap` 类，而 `HashTable `继承了 `Dictionary` 类

    ```java
    HashMap<K,V> extends AbstractMap<K,V>
    public class Hashtable<K,V> extends Dictionary<K,V>
    ```

- **性能方面：**
  - 虽然 `HashMap `和 `HashTable `都是基于`单链表`的，但是 `HashMap `进行 `put `或者 `get`操作，可以达到常数时间的性能；
  -  `HashTable `的 `put `和 `get `操作都是加了 `synchronized` 锁的，所以效率很差。

- **初始容量不同：**
  - `HashTable `的初始长度是`11`，之后每次扩充容量变为之前的 `2n+1`（`n`为上一次的长度）
  - `HashMap `的初始长度为`16`，之后每次扩充变为原来的两倍。
  - 创建时，如果给定了容量初始值，那么`HashTable `会直接使用你给定的大小，而 `HashMap `会将其扩充为`2`的幂次方大小。



## List、Map区别

**共同点：**

- 都是`Java`常用的容器，都是接口

**不同点：**

- **存储结构不同**：
  - `List`是存储==单列的集合==
  - `Map`存储的是==key-value键值对的集合==
- **元素是否可重复**：
  - `List`允许元素重复
  - `Map`不允许`key`重复
- **是否有序**：
  - `List`集合是==有序==的(存储有序)
  - `Map`集合是==无序==的(存储无序)



## Collection、Collections区别

1. `Collection`是集合的上级**接口**，继承它的有`Set`和`List`接口
2. `Collections`是集合的**工具类**，提供了一系列的静态方法对集合的搜索、查找、同步等操作



## Enumeration和Iterator接口的区别

`Iterator`替代了`Enumeration`，`Enumeration`是一个旧的迭代器了。

与`Enumeration`相比，`Iterator`更加安全，**因为当一个集合正在被遍历的时候，它会阻止其它线程去修改集合**。

- 在做练习时迭代时会不会经常出错，抛出`ConcurrentModificationException`异常，说我们在遍历的时候还在修改元素。
- 这其实就是`fail-fast机制`~具体可参考博文：https://blog.csdn.net/panweiwei1994/article/details/77051261

**区别有三点：**

- `Iterator`的方法名比`Enumeration`更科学
- `Iterator`有`fail-fast机制`，比`Enumeration`更安全
- `Iterator`能够删除元素，`Enumeration`并不能删除元素



## 并发集合类是什么？

`Java1.5`并发包（`java.util.concurrent`）**包含线程安全集合类，允许在迭代时修改集合**。

- `Utils`包下的集合迭代器被设计为`fail-fast`的，会抛出`ConcurrentModificationException`。但`java.util.concurrent`的并不会
- 一部分类为：
  - `CopyOnWriteArrayList`
  - `ConcurrentHashMap`
  - `CopyOnWriteArraySet`